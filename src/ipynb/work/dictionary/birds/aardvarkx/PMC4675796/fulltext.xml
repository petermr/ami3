<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d2 20140930//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">Cognit Comput</journal-id><journal-id journal-id-type="iso-abbrev">Cognit Comput</journal-id><journal-title-group><journal-title>Cognitive Computation</journal-title></journal-title-group><issn pub-type="ppub">1866-9956</issn><issn pub-type="epub">1866-9964</issn><publisher><publisher-name>Springer US</publisher-name><publisher-loc>New York</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">9347</article-id><article-id pub-id-type="doi">10.1007/s12559-015-9347-7</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Sherlock: A Semi-automatic Framework for Quiz Generation Using a Hybrid Semantic Similarity Measure</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Lin</surname><given-names>Chenghua</given-names></name><address><email>chenghua.lin@abdn.ac.uk</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Dong</given-names></name><address><email>Dong.Liu@bbc.co.uk</email></address><xref ref-type="aff" rid="Aff2"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Pang</surname><given-names>Wei</given-names></name><address><email>pang.wei@abdn.ac.uk</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Zhe</given-names></name><address><email>wz2000@jlu.edu.cn</email></address><xref ref-type="aff" rid="Aff3"/></contrib><aff id="Aff1"><label/>Department of Computing Science, University of Aberdeen, Aberdeen, AB24 3UE UK </aff><aff id="Aff2"><label/>BBC Future Media and Technology - Knowledge and Learning, BBC Bridge House, MediaCityUK, Salford, M50 2QH UK </aff><aff id="Aff3"><label/>College of Computer Science and Technology, Jilin University, Changchun, 130012 China </aff></contrib-group><pub-date pub-type="epub"><day>4</day><month>8</month><year>2015</year></pub-date><pub-date pub-type="pmc-release"><day>4</day><month>8</month><year>2015</year></pub-date><pub-date pub-type="ppub"><year>2015</year></pub-date><volume>7</volume><issue>6</issue><fpage>667</fpage><lpage>679</lpage><history><date date-type="received"><day>24</day><month>8</month><year>2014</year></date><date date-type="accepted"><day>20</day><month>7</month><year>2015</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2015</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</license-p></license></permissions><abstract id="Abs1"><p>In this paper, we present a semi-automatic system (Sherlock) for quiz generation using linked data and textual descriptions of RDF resources.
Sherlock is distinguished from existing quiz generation systems in its generic framework for domain-independent quiz generation as well as in the ability of controlling the difficulty level of the generated quizzes. Difficulty scaling is non-trivial, and it is fundamentally related to cognitive science. We approach the problem with a new angle by perceiving the level of knowledge difficulty as a similarity measure problem and propose a novel hybrid semantic similarity measure using linked data. Extensive experiments show that the proposed semantic similarity measure outperforms four strong baselines with more than 47&#x000a0;% gain in clustering accuracy. In addition, we discovered in the human quiz test that the model accuracy indeed shows a strong correlation with the pairwise quiz similarity.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Quiz generation</kwd><kwd>Linked data</kwd><kwd>RDF</kwd><kwd>Educational games</kwd><kwd>Semantic similarity</kwd><kwd>Text analytics</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Science+Business Media New York 2015</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p>Big Data analytics is one of the areas of fast-growing importance as it provides ways in which one can make sense and effective use of data.
Among the Big Data landscape, one important territory is linked data which rise from the Semantic Web community [<xref ref-type="bibr" rid="CR14">14</xref>]. By interlinking heterogeneous data sources in a standardised format, linked data are highly structured and machine-readable and thus are suitable for the tasks involving knowledge representation and management such as interactive games [<xref ref-type="bibr" rid="CR5">5</xref>] and question answering [<xref ref-type="bibr" rid="CR30">30</xref>], to name a few. In particular, interactive games have been proven to be an effective way for facilitating knowledge exchange between humans and machines and have attracted great research interest intersecting the fields of computing science and cognitive science [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR16">16</xref>].</p><p>On the one hand, efforts have been made to design games with the purpose of semi-automating a wide range of knowledge transfer tasks by leveraging the wisdom of the crowd. For instance, symmetric and asymmetric verification games have been developed for assisting Semantic Web tasks such as ontology building, ontology alignment, content annotation and entity interlinking [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR26">26</xref>]. Likewise, quiz-like games have also been developed to rank, rate and clean up linked data [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR32">32</xref>]. In this way, factual knowledge is transferred from humans, especially domain experts, to computers.</p><p>On the other hand, work has also been done to unleash the potential of linked data in generating educational quizzes for aiding learners&#x02019; knowledge acquisition from a knowledge base [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR5">5</xref>]. When building a quiz generation system using linked data, existing approaches [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR5">5</xref>] are based on domain-specific templates and the creation of quiz templates relies on ontologists and linked data experts, preventing end-users from participating in quiz authoring. Without user participation, such systems potentially limit the diversity and variation of quizzes that the system may otherwise offer. Rey et al. [<xref ref-type="bibr" rid="CR25">25</xref>] moved one step forward regarding the domain-dependent issue by introducing a quiz generation mechanism that is applicable to different linked data repositories. Nevertheless, their system still lacks a generic linked data-enabled framework for semi-automatically creating quizzes related to different topics.</p><p>Moreover, a system that can generate quizzes with different difficulty levels will better serve users&#x02019; needs. From a cognitive science perspective, Aponte et al. [<xref ref-type="bibr" rid="CR2">2</xref>] argued that the difficulty of challenges greatly influences the aesthetics of a game and thus plays a central role in game design. However, such an important feature is rarely offered by existing systems. Waitelonis et al. [<xref ref-type="bibr" rid="CR31">31</xref>] determined the difficulty of a quiz by simply assessing the popularity of an RDF resource, without considering the fact that the difficulty level of a quiz is directly affected by the selection of wrong candidate answers. Also, the most common way of generating wrong candidate answers is to randomly select them from the results of querying linked data repositories and hence provides no means to control the difficulty level during the process of quiz generation. Furthermore, while different similarity measures have been widely used for measuring the degree of closeness or separation of target objects, the problem of how well similarity measures can be used to represent the degree of knowledge difficulty in terms of human perception still remains relatively unexplored.</p><p>In this paper, we propose a novel semi-automatic quiz generation system (Sherlock) empowered by semantic and machine learning technologies [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>]. Sherlock is distinguished from existing quiz generation systems in a few aspects: (1) a mechanism based on a novel hybrid semantic similarity measure is introduced for controlling the difficulty level of the generated quizzes; (2) Sherlock offers a generic framework for generating quizzes of multiple domains with minimum human effort; and (3) it provides a user-friendly interface allowing users to easily create customised quizzes.</p><p>In order to control the difficulty level of the generated quizzes, a novel linked data (LD)-based hybrid semantic similarity measure, called TF-IDF (LD), is proposed. To investigate how well the proposed algorithm can be used to represent difficulty levels (i.e. <italic>difficult</italic>, <italic>medium</italic> and <italic>easy</italic>) of knowledge, we evaluated the proposed TF-IDF (LD) algorithm on the BBC Wildlife dataset.<xref ref-type="fn" rid="Fn1">1</xref> We compare the performance of TF-IDF (LD) against four strong baselines, i.e. two knowledge-based and two text-based similarity measures. It was observed that the knowledge-based measures gave better performance when predicting the <italic>easy</italic> class compared with the text-based measures, but they are inferior in the prediction for the <italic>difficult</italic> and <italic>medium</italic> classes. Our proposed hybrid semantic measure TF-IDF (LD) outperforms four strong baselines (see section &#x0201c;<xref rid="Sec21" ref-type="sec">Experimental Results</xref>&#x0201d;) and gives at least 50&#x000a0;% gain in clustering accuracy for all the three classes. Furthermore, Sherlock also provides a generic framework for generating quizzes of multiple domains with minimum human effort, and its effectiveness has been evaluated on datasets from three different domains.</p><p>The rest of the paper is organised as follows. We first review the related work in section &#x0201c;<xref rid="Sec2" ref-type="sec">Related Work</xref>&#x0201d;, followed by the presentation of the Sherlock architecture in section &#x0201c;<xref rid="Sec7" ref-type="sec">The Sherlock Architecture</xref>&#x0201d;. The hybrid semantic similarity algorithm is detailed in section &#x0201c;<xref rid="Sec14" ref-type="sec">The Linked Data-Based TF-IDF Algorithm</xref>&#x0201d;. Experimental results are reported and discussed in section &#x0201c;<xref rid="Sec16" ref-type="sec">Experiment</xref>&#x0201d;, and we finally conclude the paper in section &#x0201c;<xref rid="Sec30" ref-type="sec">Conclusion and Future Work</xref>&#x0201d;.</p></sec><sec id="Sec2"><title>Related Work</title><sec id="Sec3"><title>Games with a Purpose and Educational Games</title><p>A series of symmetric and asymmetric verification games was presented in [<xref ref-type="bibr" rid="CR26">26</xref>] with the aim to motivate humans to contribute to building the Semantic Web. <italic>BetterRelations</italic> [<xref ref-type="bibr" rid="CR13">13</xref>] is a representative symmetric verification game built following the concepts of &#x0201c;games with a purpose&#x0201d;, which attempts to solve the problem of ranking RDF triples within the description of an entity. Other quiz-like games [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR32">32</xref>] focus on ranking, rating and cleansing linked data. The assumption underlying these games is that the frequency of a question being correctly answered implies the importance of the supporting linked data used to create the quiz. However, the focus of these games is to harness human intelligence to perform tasks that cannot be automated, rather than creating learning experiences for humans.</p><p>In contrast to games with a purpose, Damljanovic et al. [<xref ref-type="bibr" rid="CR5">5</xref>] presented a template-based method for generating educational quizzes. In addition, a conversational AI agent was introduced to guide the learners and dynamically select quizzes according to the learners&#x02019; needs. Linked Data Movie Quiz (LDMQ)<xref ref-type="fn" rid="Fn2">2</xref> is another representative work of using linked data for template-based quiz generation [<xref ref-type="bibr" rid="CR25">25</xref>]. LDMQ is able to generate quizzes related to a user-selected actor or actress, asking questions about the director, the release date or the characters of a film in which the actor or actress has appeared. The question and correct answers are directly derived from the results of SPARQL<xref ref-type="fn" rid="Fn3">3</xref> queries against the Linked Movie Data Base (LMDB) [<xref ref-type="bibr" rid="CR12">12</xref>], whereas the incorrect answers are randomly chosen from a set of candidates collected following some handcrafted rules.</p><p>One of the common limitations shared by existing quiz generation systems is the domain-dependent issue. That is when applying the template-based quiz generation method to a new domain, significant human efforts must be required on tasks such as creating new question templates, writing SPARQL queries according to a domain-specific ontology and defining rules for collecting wrong answers for a quiz. Again, these tasks are not trivial for non-domain experts such as teachers, content editors and mainstream web users.</p><p>In addition, most of the existing quiz generation systems endeavour to automate the quiz creation task to the largest extent without providing the functionality for manual quiz creation. However, allowing manual question authoring from end-users is important because it can increase both the level of user engagement and topic diversity of the generated quizzes. Moreover, creating quizzes offers the creator the opportunity of <italic>teaching someone else</italic>, which is the lowest level of the Learning Pyramid.<xref ref-type="fn" rid="Fn4">4</xref> It is also arguably true that quiz players tend to retain more knowledge during the process of creating their own quizzes.</p><p>Finally, quizzes with varying difficulty levels are important for formal learning. However, as stated in [<xref ref-type="bibr" rid="CR31">31</xref>], many quiz generation systems have the same limitation that the generated quizzes being either &#x0201c;too simple or too difficult&#x0201d;, largely due to the lack of quantitative analysis on the relationship between the wrong candidate answers and the correct one(s). This has in turn motivated us to develop a systematic way of measuring quiz difficulty level using semantic similarity measures.</p></sec><sec id="Sec4"><title>Similarity Measures</title><p>A similarity (distance) measure reflects the degree of closeness or separation of the target objects, and it must be determined before performing clustering. In this work, we tackle the research challenge of how to predict the difficulty levels of quizzes perceived by humans in terms of similarity measures, which to our knowledge, has not been studied in previous work. Therefore, we review some of the most representative similarity measures in the literature, which serve as the ground for our preliminary experiments.</p><sec id="Sec5"><title>Corpus-Based Approaches</title><p>Measures of text similarity have been used for a long time in natural language processing applications and related areas. Corpus-based measures aim to identify the degree of similarity between text units using statistical patterns of words derived from large corpora, where the most representative measures are cosine similarity, averaged Kullback&#x02013;Leibler divergence (KLD) and the squared Euclidean distance [<xref ref-type="bibr" rid="CR15">15</xref>].</p><p>Cosine similarity is one of the most popular similarity measures and has been widely used in information retrieval and text clustering applications [<xref ref-type="bibr" rid="CR15">15</xref>]. When text documents are represented as term vectors, the similarity of two documents corresponds to the inner product space of the two vectors, i.e. the cosine of the angle between them. The averaged Kullback&#x02013;Leibler divergence (KLD), rooted from information theory-based clustering, evaluates the differences between two probability distributions. By modelling a document as a probability distribution over terms, the similarity of two documents is then transformed as the distance between two corresponding probability distributions. Some more advanced approaches rely on word co-occurrence patterns derived from large corpus, which indicate the degree of statistical dependence between text units. Such statistical dependences can then be used for measuring text similarity. Representative approaches along this line include pointwise mutual information (PMI) [<xref ref-type="bibr" rid="CR29">29</xref>] and latent semantic analysis (LSA) [<xref ref-type="bibr" rid="CR18">18</xref>].</p></sec><sec id="Sec6"><title>Knowledge-Based Approaches</title><p>In contrast to corpus-based approaches that are purely oriented on statistical techniques, knowledge-based approaches rely on human-organised knowledge (e.g. Semantic Network, WordNet and Linked Open Data) to encode relations between a collection of concepts [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR23">23</xref>].</p><p>WordNet [<xref ref-type="bibr" rid="CR7">7</xref>] is a large English lexical knowledge database in which terms are grouped into different sets known as synsets with a list of synonyms. A number of measures have been developed based on the WordNet hierarchy such as accessing the semantic relatedness of words/entities [<xref ref-type="bibr" rid="CR33">33</xref>] and identifying word sense under different contexts [<xref ref-type="bibr" rid="CR19">19</xref>]. Wu and Palmer [<xref ref-type="bibr" rid="CR33">33</xref>] proposed to measure the semantic similarity of two concepts by considering the depth of these two concepts in the WordNet taxonomy as well as the depth of the least common subsumer (LCS). Similarly, Resnik [<xref ref-type="bibr" rid="CR24">24</xref>] measured semantic similarity between words by counting the shared edges between two concepts in the taxonomy.</p><p>The closest work to our proposed hybrid semantic similarity measure is the linked data semantic distance (LDSD) [<xref ref-type="bibr" rid="CR23">23</xref>], which also uses the graph information in RDF resources or semantic similarity measure and has been adopted by a music recommendation system [<xref ref-type="bibr" rid="CR22">22</xref>]. The similarity computation results of LDSD purely rely on statistics on the direct and indirect in and out connections among RDF resources of DBpedia. Working on top of DBpedia gives LDSD the possibility of covering many various domains. However, when comparing to our proposed hybrid semantic similarity measure, apart from providing no means to weigh the importance of different predicates, LDSD also cannot deal with literal values and textual descriptions in a RDF dataset.</p></sec></sec></sec><sec id="Sec7"><title>The Sherlock Architecture</title><p>In this section, we present the details of the architecture of our proposed Sherlock framework. Figure <xref rid="Fig1" ref-type="fig">1</xref> depicts an overview of the framework, in which the components are logically divided into two groups: online and offline. Within the Sherlock framework, different components can interact with each other via three shared databases that respectively containing information about: (1) user behaviours, (2) questions and answers of quizzes and (3) distractors (i.e. incorrect answers). The live Sherlock system can be accessed from <ext-link ext-link-type="uri" xlink:href="http://sentinet-mango.abdn.ac.uk/">http://sentinet-mango.abdn.ac.uk/</ext-link>.<fig id="Fig1"><label>Fig. 1</label><caption><p>Overall architecture of Sherlock</p></caption><graphic xlink:href="12559_2015_9347_Fig1_HTML" id="MO1"/></fig></p><sec id="Sec8"><title>Data Collection and Integration</title><p>We collected two different types of data: (1) structured RDF data published by DBpedia and the BBC and (2) unstructured text describing objects (entities) collected from the BBC website and Wikipedia. These datasets play two main roles, namely serving as the knowledge base for quiz generation and calculating the similarity scores between objects (entities). Detailed descriptions on dataset preparation are given in section &#x0201c;<xref rid="Sec18" ref-type="sec">Data</xref>&#x0201d;.</p></sec><sec id="Sec9"><title>Similarity Computation</title><p>The similarity computation module is the core of the offline part of Sherlock. The similarity computation module first accesses the RDF store and the text corpus, and it then calculates the similarity scores between each object/entity pair. In the second step, the module performs <italic>K</italic>-means clustering to partition the wrong candidate answers into different difficulty levels according to their similarity scores with respect to the correct answer of a quiz. Here, we empirically set <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K=3$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq1.gif"/></alternatives></inline-formula>, which corresponds to three predefined difficulty levels, i.e. &#x0201c;easy&#x0201d;, &#x0201c;medium&#x0201d; and &#x0201c;difficult&#x0201d;.</p></sec><sec id="Sec10"><title>Template-Based Question and Answer Generator</title><p>The quiz generator component adopts a template-based method similar to Linked Data Movie Quiz (LDMQ), which is able to boost up the system in the situation of cold start and/or coping with data from a new domain. For instance, a template &#x0201c;Which of the following animals is {?animal_name}?&#x0201d; can be instantiated by replacing the variable with rdfs:label of an animal.</p></sec><sec id="Sec11"><title>Quiz Renderer</title><p>The quiz renderer module realises the user interface through which users can interact with the system, as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The question and correct answer are retrieved from a dedicated database, whereas the wrong answer candidates are selected from the results calculated by the similarity computation module. It is worth noting that the foaf:depiction attribute in the RDF store provides links to the images used to render the quizzes.<fig id="Fig2"><label>Fig. 2</label><caption><p>User interface for playing quizzes. <bold>a</bold> User interface when an incorrect choice is made. <bold>b</bold> User interface when a correct choice is made</p></caption><graphic xlink:href="12559_2015_9347_Fig2_HTML" id="MO2"/></fig></p><p>To encourage the users to carry on their learning journeys, the &#x0201c;learn more&#x0201d; link on the bottom left of the interface points to a web page containing information about the correct answer as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. In addition, the system gives users changes to tune down (or up) the difficulty level of the next quiz, depending on whether a user fails a difficult quiz or succeeds in an easy one.</p></sec><sec id="Sec12"><title>Quiz Creator</title><p>We believe it is necessary to allow users to create their own questions and answers in order to make the game more attractive, engaging as well as making the topic of the quizzes more diverse. The quiz creator module allows users to create customised quizzes with their own questions and images. For instance, one can take a picture of several ingredients and let people guess what dish one is going to cook. More detailed discussion about the quiz creator module is given in section &#x0201c;<xref rid="Sec29" ref-type="sec">Customised Quiz Authoring</xref>&#x0201d;.</p></sec><sec id="Sec13"><title>User Behaviour Tracker</title><p>When a user is playing a quiz, the user behaviour tracker keeps records of the identification of the user, the ID and correct answer of the quiz, and the user-selected answer.</p></sec></sec><sec id="Sec14"><title>The Linked Data-Based TF-IDF Algorithm</title><p>In this section, we describe the main algorithm we have developed in Sherlock. As we recall, one of the key challenges in our work is to measure the difficulty levels of quizzes. To this end, we developed a hybrid similarity measure by combining a novel linked data-based TF-IDF scheme with the classical text-based cosine similarity measure, called TF-IDF (LD).</p><p>Typically, RDF datasets are formalised as graphs, and the direct and indirect distances in those graphs can be used to measure the similarity between RDF resources, as in the case of linked data semantic distance (LDSD) [<xref ref-type="bibr" rid="CR23">23</xref>]. While LDSD is reported to be effective on large-scale datasets such as DBpedia and Freebase, the importance of predicates in RDF resources is not considered, which limits the accuracy of LDSD. To address this issue, we propose a novel linked data-based TF-IDF scheme by mapping Named Graphs into vectors, which takes the predicate information into account. The resulting linked data-based TF-IDF vectors are then combined with the cosine similarity measure to calculate the semantic similarity between two RDF resources. Before describing the proposed algorithm, we first give formal definitions to the following technical terms: <italic>term</italic>, <italic>sentence</italic>, <italic>document</italic> and <italic>corpus</italic>.</p><sec id="FPar1"><title><bold>Definition 1</bold></title><p><italic>A sentence and a term</italic></p><p>An RDF statement, i.e. a tuple of <italic>(subject, predicate, object)</italic>, is defined as a <italic>sentence</italic>. A combination in the form of <italic>(subject, predicate)</italic> or <italic>(predicate, object)</italic> is regarded as a <italic>term</italic>.</p><p>For example, (_:Cheetah, wo:family, _:Felidae) is a sentence, whereas (_:Cheetah, wo:family) and (wo:family, _:Felidae) are two terms in the sentence. Here, wo is the namespace of BBC Wildlife Ontology.<xref ref-type="fn" rid="Fn5">5</xref></p></sec><sec id="FPar2"><title><bold>Definition 2</bold></title><p><italic>A document and a corpus</italic></p><p>A Named Graph that is related to an RDF resource, e.g. an animal, a recipe or a painting, is a <italic>document</italic>, which may contain multiple RDF statements. A collection of RDF documents is a <italic>corpus</italic>.</p><p>For example, the RDF statements shown in Listing 1 constitute a document. This document contains three sentences describing the animal cheetah.<graphic position="anchor" xlink:href="12559_2015_9347_Figa_HTML" id="MO3"/></p></sec><sec id="FPar3"><title><bold>Definition 3</bold></title><p><italic>The relation between a term, a sentence and a document</italic></p><p>If a document <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M4"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq2.gif"/></alternatives></inline-formula> contains a sentence <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(s, p, o)$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq3.gif"/></alternatives></inline-formula>, we then say terms <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(s, p)$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq4.gif"/></alternatives></inline-formula> and <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(p, o)$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq5.gif"/></alternatives></inline-formula> are <italic>in</italic> document <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M12"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq6.gif"/></alternatives></inline-formula>, i.e. <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(s, p) \in d $$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02208;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq7.gif"/></alternatives></inline-formula> and <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(p, o) \in d $$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02208;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq8.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec15"><title>The TF-IDF (LD) Algorithm</title><p>We now describe our TF-IDF (LD) algorithm. With the definitions above, the classical TF-IDF scheme can then be applied to the RDF datasets. That is given a term <italic>t</italic>, a document <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M18"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq9.gif"/></alternatives></inline-formula> and a corpus <italic>C</italic>, the <italic>Term Frequency (TF)</italic> and the <italic>Inverse Document Ffrequency (IDF)</italic> are calculated as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} tf(t, d)&#x00026;= {} \left\{ \begin{array}{ll} 1 &#x00026;{}  \text {if}\,t \in d\\ 0 &#x00026;{}  \text {if}\,t \notin d \end{array} \right. \end{aligned}$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mrow><mml:mtable columnspacing="0.5ex"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>t</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mrow/><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable columnspacing="0.5ex"><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mtext>if</mml:mtext><mml:mspace width="0.166667em"/><mml:mi>t</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mtext>if</mml:mtext><mml:mspace width="0.166667em"/><mml:mi>t</mml:mi><mml:mo>&#x02209;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12559_2015_9347_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ idf(t, C)= \log \frac{| C |}{| \{d \in C: t \in d\} |} $$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>log</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi>d</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>C</mml:mi><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">}</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12559_2015_9347_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p><p>In information retrieval (IR), a standard <italic>Term Frequency (TF)</italic> function calculates the number of times a term has appeared in a text document. In contrast, the <italic>Term Frequency</italic> function of our proposed TF-IDF (LD) algorithm, as shown in Eq. (<xref rid="Equ1" ref-type="">1</xref>), is a Boolean function as there is no term co-occurrences in an RDF document graph. This means if a term [e.g. (<italic>s</italic>,&#x000a0;<italic>p</italic>) or (<italic>p</italic>,&#x000a0;<italic>o</italic>)] has appeared in an RDF document, its term frequency is 1, and 0 otherwise. Equation (<xref rid="Equ2" ref-type="">2</xref>) calculates the <italic>Inverse Document Frequency (IDF)</italic>, where the numerator is the total number of RDF documents in corpus <italic>C</italic> and the denominator is the total number of RDF documents in <italic>C</italic> that contain term <italic>t</italic>. By applying Eqs. (<xref rid="Equ1" ref-type="">1</xref>) and (<xref rid="Equ2" ref-type="">2</xref>) to RDF documents <italic>a</italic> and <italic>b</italic>, they can be transformed to linked data-based TF-IDF vectors (e.g. <inline-formula id="IEq10"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {t}}_a$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq10.gif"/></alternatives></inline-formula> and <inline-formula id="IEq11"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {t}}_b$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq11.gif"/></alternatives></inline-formula>), based on which we can then calculate the semantic similarity between these two RDF documents using cosine similarity as shown in Eq. (<xref rid="Equ3" ref-type="">3</xref>).<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \text {SIM}_C ({\mathbf {t}}_a, {\mathbf {t}}_b) = \frac{{\mathbf {t}}_a \cdot {\mathbf {t}}_b}{\Vert {\mathbf {t}}_a \Vert \Vert {\mathbf {t}}_b \Vert }. $$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mrow><mml:msub><mml:mtext>SIM</mml:mtext><mml:mi>C</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">&#x02016;</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">&#x02016;</mml:mo><mml:mo stretchy="false">&#x02016;</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">&#x02016;</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="12559_2015_9347_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>A summary of the TF-IDF (LD) algorithm is given in Algorithm 1.<graphic position="anchor" xlink:href="12559_2015_9347_Figb_HTML" id="MO6"/></p></sec></sec><sec id="Sec16"><title>Experiment</title><p>In this section, we first explore how well similarity measures can be used to suggest quiz difficulty levels that match human perception. In another set of experiments, we further evaluate Sherlock as a generic framework for quiz generation by testing the system on datasets from three different domains. In particular, we aim to investigate the following two research questions:<list list-type="order"><list-item><p>Can similarity measure(s) be used as appropriate means for measuring quiz difficulty levels?</p></list-item><list-item><p>To what extend can the quiz difficulty level suggested by similarity measure(s) match human perception on knowledge difficulty level?</p></list-item></list></p><sec id="Sec17"><title>A Pilot Evaluation of Quiz Difficulty Level</title><p>We shall not try to give a general definition of difficulty covering a wide range of psychological aspects from emotional problems to intellectual and physical challenges. Instead, we consider the notion of difficulty in the sense used in quiz generation, the one that is built as combinations of predefined candidates. Of course the study of the overall difficulty for a given quiz involves multiple factors such as the intellectual level of knowledge covered in the quiz and users&#x02019; knowledge background. In the preliminary study, we address the problem in a less complicated scenario, in which the difficulty level of a quiz is directly driven by the semantic similarity between the correct answer and the wrong answers.</p><sec id="Sec18"><title>Data</title><p>We conducted the preliminary experiment for measuring quiz difficulty level based on the BBC Wildlife dataset. The choice of dataset for evaluation is based on the fact that (1) there is no readily available gold standard for benchmarking from the literature; (2) in the Wildlife dataset, each animal has been labelled under the biological classification system (i.e. family, order and class), which can be naturally used as the gold standard for evaluation; and (3) according to the statistics from the BBC, the BBC Wildlife website is one of the most frequently visited BBC websites, indicating a broad public interest in the Wildlife data. In particular, we have prepared two different versions of the BBC Wildlife<xref ref-type="fn" rid="Fn6">6</xref> dataset, i.e. one based on the structured RDF data and the other based on the unstructured textual data.</p><sec id="d30e1202"><title><italic>RDF Data</italic></title><p>As for the Wildlife dataset, DBpedia and the BBC Wildlife website have already published RDF data,<xref ref-type="fn" rid="Fn7">7</xref> so we harvested the structural data directly from these two data sources. In total, there are 49,897 RDF triples in the dataset.</p></sec><sec id="d30e1222"><title><italic>Textual Data</italic></title><p>In addition to the RDF data, we have also prepared a dataset by collecting textual descriptions for each entity (i.e. different animals) in the Wildlife dataset from the corresponding BBC and Wikipedia web page. Here, the textual datasets are mainly used for calculating the text-based similarity scores between entities for controlling the quiz difficulty levels. In the preprocessing, an HTML parser is used to extract contents from the HTML pages by discarding tags, contents from the navigation bar and advertisements. In the second step, we further remove wildcards, word tokens with non-alphanumeric characters and lower-case all word tokens in the dataset, followed by stop word removal and Porter stemming.<xref ref-type="fn" rid="Fn8">8</xref> The statistics of textual dataset are summarised in Table <xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Statistics of the Wildlife textual dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left"># of docs</th><th align="left">Avg. doc length<sup>&#x02020;</sup>
</th><th align="left">Avg. doc length*</th><th align="left">Vocab. size<sup>&#x02020;</sup>
</th><th align="left">Vocab. size*</th></tr></thead><tbody><tr><td align="left">Wildlife</td><td align="left">437</td><td align="left">1190</td><td align="left">652</td><td align="left">26,004</td><td align="left">18,237</td></tr></tbody></table><table-wrap-foot><p>
<inline-formula id="IEq14"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^\dag $$\end{document}</tex-math><mml:math id="M30"><mml:msup><mml:mrow/><mml:mo>&#x02020;</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq14.gif"/></alternatives></inline-formula>&#x000a0;Denotes before preprocessing and * denotes after preprocessing</p></table-wrap-foot></table-wrap></p></sec></sec><sec id="Sec21"><title>Experimental Results</title><p>To tackle the first research question, in the pilot evaluation, we formulate the problem of perceiving the difficulty level of knowledge as a similarity measure problem. The hypothesis is that if some objects (entities) share a lot of (semantically) similar properties, they tend to have higher degree of semantic relatedness with subtle difference, and hence, they are more difficult to disambiguate, and vice versa.</p><p>To derive the gold standard for the Wildlife dataset, one intuitive approach is to make use of the biological classification system. We define that if some animals have the same <italic>family</italic> label (e.g. Cheetah and Serval), these animals would be very similar to each other and hence <italic>difficult</italic> to be disambiguated. Likewise, if some animals have the same <italic>order</italic> label but from different <italic>families</italic>, they will be less similar and correspond to a <italic>medium</italic> difficulty level when generating a quiz. Similarly, quizzes generated based on animals with the same <italic>class</italic> label but different <italic>family</italic> and <italic>order</italic> labels will be most dissimilar and correspond to the <italic>easy</italic> level. An illustrative example of the gold standard is shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>.<fig id="Fig3"><label>Fig. 3</label><caption><p>Deriving the gold standard for the BBC Wildlife dataset using the biological classification system</p></caption><graphic xlink:href="12559_2015_9347_Fig3_HTML" id="MO8"/></fig></p><p>In the pilot evaluation, we tested the proposed TF-IDF (LD) algorithm against four strong baselines in the task of measuring quiz difficulty levels. The baselines are two knowledge-based similarity measures (i.e. LDSD [<xref ref-type="bibr" rid="CR23">23</xref>] and a WordNet-based measure called WUP [<xref ref-type="bibr" rid="CR33">33</xref>]) using the RDF dataset; and two text-based similarity measures (i.e. cosine similarity with traditional TF-IDF and KLD) using the textual dataset.</p><p>Table <xref rid="Tab2" ref-type="table">2</xref> shows that for the text-based similarity measure, KLD outperforms TF-IDF in predicting the <italic>difficult</italic> and <italic>easy</italic> clusters while have similar performance in predicting the <italic>medium</italic> cluster. The knowledge-based measures slightly outperform the text-based measure for about 3&#x000a0;% in overall. It was also found that compared with the text-based measures, the knowledge-based measures (i.e. LDSD and WUP) give much better performance in predicting the <italic>easy</italic> cluster (i.e. 30&#x000a0;% higher), but are inferior to the prediction of the <italic>difficult</italic> and <italic>medium</italic> clusters. The proposed hybrid semantic similarity algorithm, TF-IDF (LD), outperforms all the four strong baselines for all difficulty levels, with over 47&#x000a0;% improvement in terms of overall accuracy. This demonstrates the effectiveness of the proposed algorithm. One reason why the proposed TF-IDF (LD) algorithm significantly outperforms the baselines is likely due to the fact that by treating RDF graphs as documents and applying the classical TF-IDF method, the proposed algorithm can capture richer semantic information from data.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Clustering accuracy of different similarity measures for measuring quiz difficulty levels</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Dataset</th><th align="left">LDSD</th><th align="left">WUP</th><th align="left">KLD</th><th align="left">TF-IDF</th><th align="left">TF-IDF (LD)</th></tr><tr><th align="left">RDF</th><th align="left">RDF</th><th align="left">Text</th><th align="left">Text</th><th align="left">RDF</th></tr></thead><tbody><tr><td align="left">Difficult</td><td align="left">18.4</td><td char="." align="char">2.4</td><td char="." align="char">37.5</td><td char="." align="char">29.2</td><td char="." align="char">
<bold>85.7</bold>
</td></tr><tr><td align="left">Medium</td><td align="left">7.9</td><td char="." align="char">9.3</td><td char="." align="char">11.4</td><td char="." align="char">11.6</td><td char="." align="char">
<bold>66.2</bold>
</td></tr><tr><td align="left">Easy</td><td align="left">82</td><td char="." align="char">74.5</td><td char="." align="char">50.9</td><td char="." align="char">44.8</td><td char="." align="char">
<bold>99.3</bold>
</td></tr><tr><td align="left">Overall</td><td align="left">36.1</td><td char="." align="char">28.7</td><td char="." align="char">33.3</td><td char="." align="char">28.5</td><td char="." align="char">
<bold>83.7</bold>
</td></tr></tbody></table><table-wrap-foot><p>Unit in % and numbers in boldface denote the best result in their respective row</p></table-wrap-foot></table-wrap></p><p>To better compare and illustrate the clustering performance, Table <xref rid="Tab3" ref-type="table">3</xref> lists the top ten most similar animals to Cheetah<xref ref-type="fn" rid="Fn9">9</xref> found by different similarity algorithms. In this table, animals are listed in descending order based on their similarity to Cheetah, and the ones that are not in the same <italic>family</italic> as Cheetah are highlighted in bold. Table <xref rid="Tab3" ref-type="table">3</xref> shows that, among the four baselines, KLD performs best with three animals in the cluster not belonging to the same family as Cheetah; in contrast, WUP is least accurate with six outliers in the cluster. The TF-IDF (LD) algorithm again gives the best performance with only one outlier, i.e. <italic>Aardvark</italic>, being included.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Top 10 most similar animals to Cheetah found by different algorithms (inappropriate ones are highlighted in bold)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">WUP</th><th align="left">KLD</th><th align="left">TF-IDF</th><th align="left">LDSD</th><th align="left">TF-IDF (LD)</th></tr></thead><tbody><tr><td align="left">Jaguar</td><td align="left">Leopard</td><td align="left">Leopard</td><td align="left">Lion</td><td align="left">Serval</td></tr><tr><td align="left">Lion</td><td align="left">Lion</td><td align="left">
<bold>Blackbuck</bold>
</td><td align="left">
<bold>Stoat</bold>
</td><td align="left">Snow Leopard</td></tr><tr><td align="left">Serval</td><td align="left">Cougar</td><td align="left">Lion</td><td align="left">Leopard</td><td align="left">Lion</td></tr><tr><td align="left">Cougar</td><td align="left">Tiger</td><td align="left">Leopard Cat</td><td align="left">Tiger</td><td align="left">Leopard</td></tr><tr><td align="left">
<bold>Meerkat</bold>
</td><td align="left">Jaguar</td><td align="left">Cougar</td><td align="left">Serval</td><td align="left">Cougar</td></tr><tr><td align="left">
<bold>Aardvark</bold>
</td><td align="left">
<bold>Spotted Hyena</bold>
</td><td align="left">Asian Golden Cat</td><td align="left">Cougar</td><td align="left">Wildcat</td></tr><tr><td align="left">
<bold>Coyote</bold>
</td><td align="left">Leopard Cat</td><td align="left">
<bold>Grant&#x02019;s gazelle</bold>
</td><td align="left">
<bold>Gray Wolf</bold>
</td><td align="left">Jaguar</td></tr><tr><td align="left">
<bold>Capybara</bold>
</td><td align="left">Snow Leopard</td><td align="left">
<bold>Spotted Hyena</bold>
</td><td align="left">
<bold>Red Fox</bold>
</td><td align="left">Tiger</td></tr><tr><td align="left">
<bold>Stoat</bold>
</td><td align="left">
<bold>Bongo (antelope)</bold>
</td><td align="left">
<bold>Blue Wildebeest</bold>
</td><td align="left">
<bold>Meerkat</bold>
</td><td align="left">
<bold>Aardvark</bold>
</td></tr><tr><td align="left">
<bold>Indri</bold>
</td><td align="left">
<bold>Fossa</bold>
</td><td align="left">Snow Leopard</td><td align="left">
<bold>Human</bold>
</td><td align="left">Eurasian Lynx</td></tr></tbody></table></table-wrap></p></sec></sec><sec id="Sec22"><title>Using Human Judgements to Examine Quiz Difficulty Levels</title><p>Although the previous pilot experiment shows that similarity measures, especially the proposed TF-IDF (LD) algorithm, are potentially good means for measuring quiz difficulty levels, this study is still based on a synthetic gold standard without human evaluation. Therefore, it is necessary to verify whether the difficulty levels captured by similarity measures are indeed in line with human perception, and if so how well the correlation could be.</p><sec id="Sec23"><title>Task Description of Human Evaluation</title><p>To investigate the second research question, we propose a task that creates a formal setting for assessing how human perceive knowledge difficulty levels, called the quiz game task. Basically, the task involves playing quiz games, in which the subject is presented with quizzes produced using three selected similarity measures, namely LDSD, TF-IDF and TF-IDF(LD), with five quizzes generated for each difficulty level per measure. Therefore, there are altogether 45 quizzes generated based on the Wildlife dataset using the three different similarity measures. The rationales of using a subset of the baselines are mainly based on the following two considerations: 1) those four baselines performed very similar in the pilot study and 2) more importantly, four baselines plus the proposed algorithm will involved 75 test quizzes, requiring more than 15 min for a subject to complete. It was reported by Szalma et al. [<xref ref-type="bibr" rid="CR28">28</xref>] that human evaluation test taking more than 15 min will result in the participants being less focused and more likely to be interrupted.</p><p>The above described tasks were offered on Amazon Mechanical Turk,<xref ref-type="fn" rid="Fn10">10</xref> which has been successfully used in the past to develop gold-standard data for various tasks such as natural language processing [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR27">27</xref>] and images labelling [<xref ref-type="bibr" rid="CR6">6</xref>]. We presented each subject with jobs containing 45 quiz tasks. Each job (i.e. a quiz) was performed by 30 separate subjects.</p><p>For each job, we record the answer picked by the subject. Also, to reduce the randomness of human evaluation, the subjects are instructed to choose an additional option &#x0201c;I don&#x02019;t know&#x0201d;, if one is not sure about the answer of a quiz. Such a selection will be automatically categorised as an incorrect answer.</p></sec><sec id="Sec24"><title>Model Accuracy</title><p>To quantify the difficulty levels perceived by users in the human evaluation task, we introduced the concept of <italic>model accuracy</italic>, which indicates the percentage of times users have chosen the correct answer of the quizzes generated by a model. Here, the model refers to a particular similarity measure (e.g. LDSD or TF-IDF ). Let <inline-formula id="IEq15"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q_k^s$$\end{document}</tex-math><mml:math id="M32"><mml:msubsup><mml:mi>q</mml:mi><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq15.gif"/></alternatives></inline-formula> be the answer selected by the <italic>s</italic>th subject for the <italic>k</italic>th quiz; <inline-formula id="IEq16"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_k$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq16.gif"/></alternatives></inline-formula> be the correct answer for the <italic>k</italic>th quiz and <italic>S</italic> denotes the number of subjects, and the accuracy of the <italic>k</italic>th quiz is calculated as follows:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} A_k = \sum _{s} ( q_{k}^s= c_k) / S. \end{aligned}$$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mrow><mml:mtable columnspacing="0.5ex"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>s</mml:mi></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">/</mml:mo><mml:mi>S</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12559_2015_9347_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>Finally, we are interested in calculating the model accuracy <inline-formula id="IEq17"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_m^l $$\end{document}</tex-math><mml:math id="M38"><mml:msubsup><mml:mi>M</mml:mi><mml:mi>m</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq17.gif"/></alternatives></inline-formula>, which encodes the percentage of times users have chosen the correct answer for the test quizzes of difficulty level <italic>l</italic> generated by model <italic>m</italic>. The derivation of <inline-formula id="IEq18"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_m^l $$\end{document}</tex-math><mml:math id="M40"><mml:msubsup><mml:mi>M</mml:mi><mml:mi>m</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq18.gif"/></alternatives></inline-formula> is formalised in Eq. (<xref rid="Equ5" ref-type="">5</xref>)<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} M_{m}^{l} = \sum _{k} A_{k} / D, \end{aligned}$$\end{document}</tex-math><mml:math id="M42" display="block"><mml:mrow><mml:mtable columnspacing="0.5ex"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:msub><mml:mi>A</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:mi>D</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12559_2015_9347_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <italic>D</italic> is the total number of quizzes with difficulty level <italic>l</italic> generated by model <italic>m</italic>.</p></sec><sec id="Sec25"><title>Correlation Between Model Accuracy and Similarity Distribution</title><p>In another set of experiments, we investigated the correlation between the difficulty levels suggested by similarity measures and those perceived by human as encoded in the <italic>model accuracy</italic>. Our hypothesis is that if the difficulty levels suggested by similarity measures are in line with human perception, the <italic>pairwise similarity</italic> of the quizzes should have correlations with the <italic>model accuracy</italic> to certain degree. Here, the <italic>averaged pairwise similarity</italic> of each quiz is calculated by averaging out the similarity scores between the correct answer and distractors (i.e. incorrect answers) of that quiz.</p><p>In the human evaluation task, 30 subjects were presented with 45 test quizzes generated by Sherlock, i.e. 5 quizzes per difficulty level of each similarity measure (i.e. LDSD, TF-IDF and TF-IDF (LD)). Completing the whole test takes approximately 12 min for each subject on average. Next the averaged pairwise similarity of each test quiz was computed, as shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>.<fig id="Fig4"><label>Fig. 4</label><caption><p>Averaged quiz similarity based on different similarity measures on the Wildlife domain dataset. <bold>a</bold> LDSD. <bold>b</bold> TF-IDF. <bold>c</bold> TF-IDF (LD)</p></caption><graphic xlink:href="12559_2015_9347_Fig4_HTML" id="MO11"/></fig></p><p>Figure <xref rid="Fig4" ref-type="fig">4</xref> shows that the pairwise quiz similarities based on LDSD are quite flat, with less than 0.06 difference between the highest and lowest value points. This is likely due to the fact that LDSD relies on the direct and indirect connections between the RDF resources, which are relatively sparse in the Wildlife RDF dataset. As a result, LDSD produces similarity values with very subtle difference. On the other hand, the classic TF-IDF scheme produces quite skewed similarity distribution, with the <italic>easy</italic> and <italic>medium</italic> classes having very small similarity values and the <italic>difficult</italic> class having much higher similarity scores. In contrast, the similarity distributions for each difficulty level obtained using the proposed TF-IDF (LD) algorithm are much more balanced and well spread.</p><p>Figure <xref rid="Fig5" ref-type="fig">5</xref> shows the Pearson&#x02019;s correlation between the model accuracy and the pairwise similarity of quizzes generated from the same model, in which all the data points are the averaged value over five quizzes per difficulty level. It can be seen that for all the three tested models, model accuracy derived from human evaluation indeed shows a negative correlation with the pairwise quiz similarity. In addition, the proposed TF-IDF (LD) shows stronger correlation than both LDSD and TF-IDF in terms of the <italic>r</italic> value. Furthermore, for the significance test, TF-IDF (LD) is the only measure with <inline-formula id="IEq19"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \,&#x0003c;\, 0.05$$\end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:mi>p</mml:mi><mml:mspace width="0.166667em"/><mml:mo>&#x0003c;</mml:mo><mml:mspace width="0.166667em"/><mml:mn>0.05</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq19.gif"/></alternatives></inline-formula> (cf. <inline-formula id="IEq20"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p = 0.156$$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.156</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq20.gif"/></alternatives></inline-formula> for LDSD, <inline-formula id="IEq21"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p = 0.266$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.266</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq21.gif"/></alternatives></inline-formula> for TF-IDF). The human evaluation results are in line with the observations in the pilot study based on the gold standard derived from the biological classification system. Therefore, we conclude that similarity measures are good means for measuring quiz difficulty levels and that the proposed TF-IDF (LD) algorithm is superior to the baselines in the task of controlling the difficulty levels of quizzes in quiz generation.<fig id="Fig5"><label>Fig. 5</label><caption><p>Pearson&#x02019;s correlation between the model accuracy and the pairwise similarity of quizzes. <bold>a</bold> LDSD (<inline-formula id="IEq22"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r=-0.97, p=0.156$$\end{document}</tex-math><mml:math id="M50"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mn>0.97</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.156</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq22.gif"/></alternatives></inline-formula>). <bold>b</bold> TF-IDF (<inline-formula id="IEq23"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r=-0.91, p=0.266$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mn>0.91</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.266</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq23.gif"/></alternatives></inline-formula>). <bold>c</bold> TF-IDF (LD) (<inline-formula id="IEq24"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r=-0.99, p=0.0307$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mn>0.99</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0307</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq24.gif"/></alternatives></inline-formula>)</p></caption><graphic xlink:href="12559_2015_9347_Fig5_HTML" id="MO12"/></fig></p></sec></sec><sec id="Sec26"><title>Domain-Independent Quiz Generation</title><p>Another key contribution of this paper is that we developed a generic framework for semi-automatic quiz generation, which can be reused in different domains with minimum human efforts. To test the framework, apart from the Wildlife domain data, we have also applied Sherlock to generate quizzes in two other domains, namely BBC Food and BBC YourPaintings.</p><sec id="Sec27"><title>Data</title><p>Different from the Wildlife domain data, the Food<xref ref-type="fn" rid="Fn11">11</xref> and YourPaintings<xref ref-type="fn" rid="Fn12">12</xref> domains only have HTML pages available. Therefore, we first extracted information from those HTML pages and then converted it into the RDF format using two manually constructed lightweight ontologies, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. In addition, for the purpose of incorporating the DBpedia data about painting artists into a coherent RDF store, the DBpeida Lookup API<xref ref-type="fn" rid="Fn13">13</xref> was invoked to find out the DBpedia URI for each artist, and the results were interlinked via owl:sameAs. The statistics of the RDF dataset are summarised in Table <xref rid="Tab4" ref-type="table">4</xref>.<fig id="Fig6"><label>Fig. 6</label><caption><p>
<bold>a</bold> Ontologies for food recipes and <bold>b</bold> paintings and artists. <italic>Note</italic> widely used predicates such as rdfs:label and rdfs:comment are omitted for making the figures more concise</p></caption><graphic xlink:href="12559_2015_9347_Fig6_HTML" id="MO13"/></fig><table-wrap id="Tab4"><label>Table 4</label><caption><p>Statistics of the RDF datasets from three different domain</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">RDF triples</th><th align="left">Number of species</th><th align="left">RDF triples per recipe</th><th align="left">Distinct objects shared by at least two recipes</th><th align="left">Distinct subjects shared by at least two recipes</th></tr></thead><tbody><tr><td align="left">Wildlife</td><td char="." align="char">49,897</td><td char="." align="char">886</td><td char="." align="char">16.1</td><td char="." align="char">323</td><td char="." align="char">74</td></tr><tr><td align="left">Food</td><td char="." align="char">55,006</td><td char="." align="char">5412</td><td char="." align="char">9.3</td><td char="." align="char">2419</td><td char="." align="char">0</td></tr><tr><td align="left">YourPaintings</td><td char="." align="char">25,314</td><td char="." align="char">41</td><td char="." align="char">197.9</td><td char="." align="char">252</td><td char="." align="char">39</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec28"><title>Quiz Generation</title><p>When generating quizzes for a new domain, the existing template-based methods [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR5">5</xref>] require sophisticated rules or SPARQL queries for collecting wrong answers. In contrast, the Sherlock system, benefiting from the domain-independent similarity measures, is more flexible as there is no need to manually define rules or write SPARQL queries when applying to a new domain. To test the system, we have applied Sherlock to generate quizzes of three different domains, namely BBC Wildlife, BBC Food and BBC YourPaintings, with 321, 991 and 2315 quizzes being automatically generated for each domain, respectively.</p></sec><sec id="Sec29"><title>Customised Quiz Authoring</title><p>Sherlock allows users to create their own quizzes and share with others, which is an important functionality not offered by other systems. Quiz authoring can not only complement automatic quiz generation for generating quizzes with more diverse topics, but also allow collaborative learning, i.e. users teach each other and learn together. We have collaborated with the editorial team in BBC Knowledge and Learning division to investigate whether it is appropriate for creating quizzes for formal learning and the outcome turned out to be very positive.</p><p>Figure <xref rid="Fig7" ref-type="fig">7</xref> depicts the quiz creator module.<xref ref-type="fn" rid="Fn14">14</xref> Quiz authoring involves three simple steps: (1) write a question; (2) set the correct answer (distractors are suggested by the Sherlock system automatically); and (3) preview and submit. Another advantage of the Sherlock system is that the created quizzes will not be presented exactly the same every time when they are being played, because the candidate answers are dynamically retrieved from the similarity computation component.<fig id="Fig7"><label>Fig. 7</label><caption><p>User interface for creating a quiz</p></caption><graphic xlink:href="12559_2015_9347_Fig7_HTML" id="MO14"/></fig></p></sec></sec></sec><sec id="Sec30"><title>Conclusion and Future Work</title><p>One of the key challenges in analysing and making effective use of Big Data is to deal with the unstructured text and natural language. Linked data, as an essential part of the Big Data landscape, interlinks heterogeneous data sources in a standardised structured format. These features make linked data easy to be consumed by machines and are particularly suitable for tasks related to knowledge engineering.</p><p>In this paper, we presented Sherlock, a generic framework for generating educational quizzes using linked data. Inspired by cognitive science studies [<xref ref-type="bibr" rid="CR2">2</xref>], Sherlock also provides a mechanism for scaling the difficulty levels of the generated quizzes. Such a feature is deemed to have fundamental influences on the attractiveness of a game to users [<xref ref-type="bibr" rid="CR2">2</xref>]. In summary, Sherlock offers two distinctive features compared to existing systems: (1) it provides a generic framework for generating quizzes of multiple domains with minimum human effort and (2) it introduces a mechanism for controlling the difficulty level of the generated quizzes based on a novel hybrid semantic similarity measure TF-IDF (LD). Extensive experiments show that the proposed TF-IDF (LD) algorithm outperforms four strong baselines with more than 50&#x000a0;% gain in predicting the difficulty level of quizzes, where similar observations have been observed in the human evaluation task.</p><p>As for future work, we first plan to carry out more comprehensive user testing and evaluation to further explore the relationship between quiz difficulty and semantic similarity. Second, it would be useful to extend the Sherlock system with natural language generation (NLG) capability to create more complicated quizzes. Third, we will consider deploying our system on the cloud by using privacy preserving approaches [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR34">34</xref>]. Finally, apart from the K-means clustering algorithm used for clustering quizzes of different difficulty levels, we will consider using more advanced clustering [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR35">35</xref>] and classification algorithms [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>] to perform better online learning of the quiz difficulty levels based on real-time user feedbacks.</p></sec></body><back><fn-group><fn id="Fn1"><label>1</label><p><ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/nature/wildlife/">http://www.bbc.co.uk/nature/wildlife/</ext-link>.</p></fn><fn id="Fn2"><label>2</label><p><ext-link ext-link-type="uri" xlink:href="http://lamboratory.com/hacks/ldmq/">http://lamboratory.com/hacks/ldmq/</ext-link>.</p></fn><fn id="Fn3"><label>3</label><p><ext-link ext-link-type="uri" xlink:href="http://www.w3.org/TR/rdf-sparql-query/">http://www.w3.org/TR/rdf-sparql-query/</ext-link>.</p></fn><fn id="Fn4"><label>4</label><p><ext-link ext-link-type="uri" xlink:href="http://homepages.gold.ac.uk/polovina/learnpyramid/about.htm">http://homepages.gold.ac.uk/polovina/learnpyramid/about.htm</ext-link>.</p></fn><fn id="Fn5"><label>5</label><p><ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/ontologies/wildlife/2010-02-22.shtml">http://www.bbc.co.uk/ontologies/wildlife/2010-02-22.shtml</ext-link>.</p></fn><fn id="Fn6"><label>6</label><p><ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/nature/wildlife/">http://www.bbc.co.uk/nature/wildlife/</ext-link>.</p></fn><fn id="Fn7"><label>7</label><p>The corresponding ontology can be found at: <ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/ontologies/wildlife">http://www.bbc.co.uk/ontologies/wildlife</ext-link>. e.g. <ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/nature/life/Cheetah.rdf">http://www.bbc.co.uk/nature/life/Cheetah.rdf</ext-link> returns RDF statements describing cheetah.</p></fn><fn id="Fn8"><label>8</label><p><ext-link ext-link-type="uri" xlink:href="http://ldc.usb.ve/~vdaniel/porter.pm">http://ldc.usb.ve/~vdaniel/porter.pm</ext-link>.</p></fn><fn id="Fn9"><label>9</label><p><ext-link ext-link-type="uri" xlink:href="http://bbc.co.uk/nature/life/Cheetah">http://bbc.co.uk/nature/life/Cheetah</ext-link>.</p></fn><fn id="Fn10"><label>10</label><p><ext-link ext-link-type="uri" xlink:href="http://www.mturk.com">http://www.mturk.com</ext-link>.</p></fn><fn id="Fn11"><label>11</label><p><ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/food/">http://www.bbc.co.uk/food/</ext-link>.</p></fn><fn id="Fn12"><label>12</label><p><ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/arts/yourpaintings/">http://www.bbc.co.uk/arts/yourpaintings/</ext-link>.</p></fn><fn id="Fn13"><label>13</label><p><ext-link ext-link-type="uri" xlink:href="http://wiki.dbpedia.org/lookup/">http://wiki.dbpedia.org/lookup/</ext-link>.</p></fn><fn id="Fn14"><label>14</label><p>The quiz creator interface can be accessed from <ext-link ext-link-type="uri" xlink:href="http://sentinet-mango.abdn.ac.uk/#/quiz/create">http://sentinet-mango.abdn.ac.uk/#/quiz/create</ext-link>.</p></fn></fn-group><ack><p>This work is supported by the BBC Connected Studio programme (<ext-link ext-link-type="uri" xlink:href="http://www.bbc.co.uk/partnersandsuppliers/connectedstudio/">http://www.bbc.co.uk/partnersandsuppliers/connectedstudio/</ext-link>), the award made by the RCUK Digital Economy theme to the dot.rural Digital Economy Hub; award reference EP/G066051/1, the award made by UK Economic &#x00026; Social Research Council (ESRC); award reference ES/M001628/1, National Natural Science Foundation of China (NSFC) under Grant No. 61373051, and the China National Science and Technology Pillar Program (Grant No. 2013BAH07F05). The authors would like to thank Ryan Hussey for the work on the user interface design and Tom Cass and James Ruston for the help in developing the Sherlock application. We are also grateful to Herm Baskerville for creating the editorial quizzes and Nava Tintarev for many helpful discussions on the human evaluation.</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">&#x000c1;lvaro G, &#x000c1;lvaro J. A linked data movie quiz: the answers are out there, and so are the questions [blog post]. 2010. <ext-link ext-link-type="uri" xlink:href="http://bit.ly/linkedmovies">http://bit.ly/linkedmovies</ext-link>.</mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">Aponte MV, Levieux G, Natkin S. Scaling the level of difficulty in single player video games. In: Entertainment computing&#x02013;ICEC, pp. 24&#x02013;35. Springer; 2009.</mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Bostan B, &#x000d6;&#x0011f;&#x000fc;t S. Game challenges and difficulty levels: lessons learned from rpgs. In: International simulation and gaming association conference. 2009.</mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">Chang J, Gerrish S, Wang C, Boyd-graber JL, Blei DM. Reading tea leaves: how humans interpret topic models. In: Advances in neural information processing systems. 2009. pp. 288&#x02013;296.</mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">Damljanovic D, Miller D, O&#x02019;Sullivan D. Learning from quizzes using intelligent learning companions. In: Proceedings of the world wide web conference (WWW). 2013. pp. 435&#x02013;438.</mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Deng J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L. Imagenet: a large-scale hierarchical image database. In: IEEE conference on computer vision and pattern recognition (CVPR). 2009. pp. 248&#x02013;255.</mixed-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="book"><person-group person-group-type="editor"><name><surname>Fellbaum</surname><given-names>C</given-names></name></person-group><source>WordNet: an electronic lexical database</source><year>1998</year><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Z</given-names></name><name><surname>Sun</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Zhou</surname><given-names>L</given-names></name><name><surname>Shu</surname><given-names>J</given-names></name></person-group><article-title>Achieving efficient cloud search services: multi-keyword ranked search over encrypted cloud data supporting parallel computing</article-title><source>IEICE Trans Commun</source><year>2015</year><volume>E98&#x02013;B</volume><issue>1</issue><fpage>190</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1587/transcom.E98.B.190</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Steyvers</surname><given-names>M</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name></person-group><article-title>Topics in semantic representation</article-title><source>Psychol Rev</source><year>2007</year><volume>114</volume><issue>2</issue><fpage>211</fpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.2.211</pub-id><?supplied-pmid 17500626?><pub-id pub-id-type="pmid">17500626</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>B</given-names></name><name><surname>Sheng</surname><given-names>VS</given-names></name><name><surname>Tay</surname><given-names>KY</given-names></name><name><surname>Romano</surname><given-names>W</given-names></name><name><surname>Li</surname><given-names>S</given-names></name></person-group><article-title>Incremental support vector learning for ordinal regression</article-title><source>IEEE Trans Neural Netw Learn Syst</source><year>2015</year><volume>26</volume><issue>7</issue><fpage>1403</fpage><lpage>1416</lpage><pub-id pub-id-type="doi">10.1109/TNNLS.2014.2342533</pub-id><?supplied-pmid 25134094?><pub-id pub-id-type="pmid">25134094</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>B</given-names></name><name><surname>Sheng</surname><given-names>VS</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Ho</surname><given-names>D</given-names></name><name><surname>Osman</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>S</given-names></name></person-group><article-title>Incremental learning for <inline-formula id="IEq26"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\nu $$\end{document}</tex-math><mml:math id="M56"><mml:mi mathvariant="italic">&#x003bd;</mml:mi></mml:math><inline-graphic xlink:href="12559_2015_9347_Article_IEq26.gif"/></alternatives></inline-formula>-support vector regression</article-title><source>Neural Netw</source><year>2015</year><volume>67</volume><fpage>140</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2015.03.013</pub-id><?supplied-pmid 25933108?><pub-id pub-id-type="pmid">25933108</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Hassanzadeh O, Consens M. Linked movie data base. In: Proceedings of the linked data on the web workshop (LDOW). 2009.</mixed-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hees</surname><given-names>J</given-names></name><name><surname>Roth-Berghofer</surname><given-names>T</given-names></name><name><surname>Biedert</surname><given-names>R</given-names></name><name><surname>Adrian</surname><given-names>B</given-names></name><name><surname>Dengel</surname><given-names>A</given-names></name></person-group><article-title>Betterrelations: collecting association strengths for linked data triples with a game</article-title><source>Search Comput LNCS</source><year>2012</year><volume>7538</volume><fpage>223</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-34213-4_15</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hitzler</surname><given-names>P</given-names></name><name><surname>Janowicz</surname><given-names>K</given-names></name></person-group><article-title>Linked data, big data, and the 4th paradigm</article-title><source>Semant Web</source><year>2013</year><volume>4</volume><issue>3</issue><fpage>233</fpage><lpage>235</lpage></element-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Huang A. Similarity measures for text document clustering. In: Proceedings of the New Zealand computer science research student conference (NZCSRSC). 2008. pp. 49&#x02013;56.</mixed-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hurwitz</surname><given-names>J</given-names></name><name><surname>Kaufman</surname><given-names>M</given-names></name><name><surname>Bowles</surname><given-names>A</given-names></name></person-group><source>Cognitive computing and big data analytics</source><year>2015</year><publisher-loc>Hoboken</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>J</given-names></name><name><surname>Pang</surname><given-names>W</given-names></name><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Ma</surname><given-names>Z</given-names></name></person-group><article-title>A novel artificial bee colony based clustering algorithm for categorical data</article-title><source>PLoS ONE</source><year>2015</year><volume>10</volume><issue>5</issue><fpage>e0127,125</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0127125</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landauer</surname><given-names>TK</given-names></name><name><surname>Foltz</surname><given-names>PW</given-names></name><name><surname>Laham</surname><given-names>D</given-names></name></person-group><article-title>An introduction to latent semantic analysis</article-title><source>Discourse Process</source><year>1998</year><volume>25</volume><issue>2&#x02013;3</issue><fpage>259</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1080/01638539809545028</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leacock</surname><given-names>C</given-names></name><name><surname>Chodorow</surname><given-names>M</given-names></name></person-group><article-title>Combining local context and wordnet similarity for word sense identification</article-title><source>WordNet Electron Lex Database</source><year>1998</year><volume>49</volume><issue>2</issue><fpage>265</fpage><lpage>283</lpage></element-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Lin C, Liu D, Pang W, Apeh E. Predicting quiz difficulty level using a hybrid semantic similarity measure. In: Proceedings of The 8th International Conference on Knowledge Capture (K-Cap), ACM. 2015.</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Liu D, Lin C. Sherlock: a semi-automatic quiz generation system using linked data. In: Proceedings of the international semantic web conference (ISWC), LNCS. 2014.</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Passant A. dbrec&#x02014;music recommendations using dbpedia. In: Proceedings of the international semantic web conference (ISWC), LNCS, vol. 6497, 2010. pp. 209&#x02013;224.</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Passant A. Measuring semantic distance on linking data and using it for resources recommendations. In: AAAI spring symposium: linked data meets artificial intelligence. 2010.</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Resnik P. Using information content to evaluate semantic similarity in a taxonomy. In: In Proceedings of the 14th international joint conference on artificial intelligence. 1995. pp. 448&#x02013;453.</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Rey G&#x000c1;, Celino I, Alexopoulos P, Damljanovic D, Damova M, Li N, Devedzic V. Semi-automatic generation of quizzes and learning artifacts from linked data. In: 2nd international workshop on learning and education with the web of data at the world wide web conference (WWW). 2012.</mixed-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siorpaes</surname><given-names>K</given-names></name><name><surname>Hepp</surname><given-names>M</given-names></name></person-group><article-title>Games with a purpose for the semantic web</article-title><source>IEEE Intell Syst</source><year>2008</year><volume>23</volume><issue>3</issue><fpage>50</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1109/MIS.2008.45</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Snow R, O&#x02019;Connor B, Jurafsky D, Ng AY. Cheap and fast&#x02014;but is it good?: evaluating non-expert annotations for natural language tasks. In: Proceedings of the conference on empirical methods in natural language processing (EMNLP), pp. 254&#x02013;263. Association for Computational Linguistics. 2008.</mixed-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szalma</surname><given-names>JL</given-names></name><name><surname>Warm</surname><given-names>JS</given-names></name><name><surname>Matthews</surname><given-names>G</given-names></name><name><surname>Dember</surname><given-names>WN</given-names></name><name><surname>Weiler</surname><given-names>EM</given-names></name><name><surname>Meier</surname><given-names>A</given-names></name><name><surname>Eggemeier</surname><given-names>FT</given-names></name></person-group><article-title>Effects of sensory modality and task duration on performance, workload, and stress in sustained attention</article-title><source>J Hum Fact Ergon Soc</source><year>2004</year><volume>46</volume><issue>2</issue><fpage>219</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1518/hfes.46.2.219.37334</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Turney PD. Mining the web for synonyms: PMI-IR versus LSA on TOEFL. In: Proceedings of the 12th European conference on machine learning (ECML), London, UK. 2001. pp. 491&#x02013;502.</mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Unger C, B&#x000fc;hmann L, Lehmann J, Ngonga Ngomo AC, Gerber D, Cimiano P. Template-based question answering over rdf data. In: Proceedings of the 21st international conference on World Wide Web, ACM. 2012. pp. 639&#x02013;648.</mixed-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waitelonis</surname><given-names>J</given-names></name><name><surname>Ludwig</surname><given-names>N</given-names></name><name><surname>Knuth</surname><given-names>M</given-names></name><name><surname>Sack</surname><given-names>H</given-names></name></person-group><article-title>WhoKnows? Evaluating linked data heuristics with a quiz that cleans up dbpedia</article-title><source>ITSE</source><year>2011</year><volume>8</volume><fpage>236</fpage><lpage>248</lpage></element-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Wolf L, Knuth M, Osterhoff J, Sack H. Risq! Renowned individuals semantic quiz: a jeopardy like quiz game for ranking facts. In: Proceedings of the 7th international conference on semantic systems, I-semantics &#x02019;11, 2011. pp. 71&#x02013;78.</mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Wu Z, Palmer M. Verbs semantics and lexical selection. In: Proceedings of the 32nd annual meeting on association for computational linguistics (ACL), 1994. pp. 133&#x02013;138.</mixed-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Sun</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name></person-group><article-title>A secure and dynamic multi-keyword ranked search scheme over encrypted cloud data</article-title><source>IEEE Trans Parallel Distrib Syst</source><year>2015</year></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Jeon</surname><given-names>B</given-names></name><name><surname>Xu</surname><given-names>D</given-names></name><name><surname>Wu</surname><given-names>Q</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name></person-group><article-title>Image segmentation by generalized hierarchical fuzzy c-means algorithm</article-title><source>J Intell Fuzzy Syst Appl Eng Technol</source><year>2015</year><volume>28</volume><issue>2</issue><fpage>961</fpage><lpage>973</lpage></element-citation></ref></ref-list></back></article>