<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.3389/fpsyg.2013.00537</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research Article</subject></subj-group></subj-group></article-categories><title-group><article-title>People can understand descriptions of motion without activating visual motion brain regions</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Dravida</surname><given-names>Swethasri</given-names></name></contrib><contrib contrib-type="author"><name><surname>Saxe</surname><given-names>Rebecca</given-names></name></contrib><contrib contrib-type="author"><name><surname>Bedny</surname><given-names>Marina</given-names></name><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref></contrib></contrib-group><aff><institution>Saxe Lab for Social Cognitive Neuroscience, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology</institution><country>Cambridge, MA, USA</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Gina Kuperberg, Tufts University, USA</p></fn><fn fn-type="edited-by"><p>Reviewed by: David Kemmerer, Purdue University, USA; Vicky T. Lai, Max Planck Institute for Psycholinguistics, Netherlands</p></fn><corresp id="fn001">*Correspondence: Marina Bedny, Saxe Lab for Social Cognitive Neuroscience, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, 43 Vassar St., Room 46-4021, Cambridge, MA 02139, USA e-mail: <email xlink:type="simple">mbedny@mit.edu</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Language Sciences, a section of the journal Frontiers in Psychology.</p></fn></author-notes><pub-date pub-type="epub"><day>28</day><month>8</month><year>2013</year></pub-date><pub-date pub-type="collection"><year>2013</year></pub-date><volume>4</volume><elocation-id>537</elocation-id><history><date date-type="received"><day>01</day><month>11</month><year>2012</year></date><date date-type="accepted"><day>30</day><month>7</month><year>2013</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2013 Dravida, Saxe and Bedny.</copyright-statement><copyright-year>2013</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>What is the relationship between our perceptual and linguistic neural representations of the same event? We approached this question by asking whether visual perception of motion and understanding linguistic depictions of motion rely on the same neural architecture. The same group of participants took part in two language tasks and one visual task. In task 1, participants made semantic similarity judgments with high motion (e.g., &#x0201c;to bounce&#x0201d;) and low motion (e.g., &#x0201c;to look&#x0201d;) words. In task 2, participants made plausibility judgments for passages describing movement (&#x0201c;A centaur hurled a spear &#x02026; &#x0201d;) or cognitive events (&#x0201c;A gentleman loved cheese &#x02026;&#x0201d;). Task 3 was a visual motion localizer in which participants viewed animations of point-light walkers, randomly moving dots, and stationary dots changing in luminance. Based on the visual motion localizer we identified classic visual motion areas of the temporal (MT/MST and STS) and parietal cortex (inferior and superior parietal lobules). We find that these visual cortical areas are largely distinct from neural responses to linguistic depictions of motion. Motion words did not activate any part of the visual motion system. Motion passages produced a small response in the right superior parietal lobule, but none of the temporal motion regions. These results suggest that (1) as compared to words, rich language stimuli such as passages are more likely to evoke mental imagery and more likely to affect perceptual circuits and (2) effects of language on the visual system are more likely in secondary perceptual areas as compared to early sensory areas. We conclude that language and visual perception constitute distinct but interacting systems.</p></abstract><kwd-group><kwd>language</kwd><kwd>motion</kwd><kwd>embodiment</kwd><kwd>simulation</kwd><kwd>MT/MST</kwd><kwd>right superior temporal sulcus</kwd><kwd>inferior parietal lobule</kwd><kwd>superior parietal lobule</kwd></kwd-group><counts><fig-count count="4"/><table-count count="4"/><equation-count count="0"/><ref-count count="57"/><page-count count="14"/><word-count count="10955"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>What is the relationship between sensory perception and concepts? Cognitive neuroscience offers one approach to this question: We can ask whether sensory perception and language depend on the same neural machinery. Does understanding the sentence &#x0201c;The man jumped out of the car&#x0201d; depend on the same neural circuits as visually perceiving men, cars, and jumping? Words and sentences that describe motion offer a particularly good opportunity to test this hypothesis, because of the long history of studying the neural representation of visually perceived motion. In the current study, we examine possible links between language and perception by comparing the neural mechanisms underlying comprehension of language describing motion and actual visual perception of motion.</p><p>Visual perception of motion is supported by a network of temporal and parietal brain regions. The earliest cortical area that selectively responds to motion is the middle temporal complex (MT/MST) of posterior lateral temporal cortex (Tootell et al., <xref ref-type="bibr" rid="B47">1995</xref>; Born and Bradley, <xref ref-type="bibr" rid="B5">2005</xref>). Individual neurons in MT/MST are tuned to specific directions and speeds of motion (Dubner and Zeki, <xref ref-type="bibr" rid="B12">1971</xref>). Damage to MT/MST in humans results in akinotopsia, a selective deficits in motion vision. Severely akinotopsic patients fail to perceive moving objects as traversing smoothly through space; for example an approaching car appears to jump from a far away location to close up (Zeki, <xref ref-type="bibr" rid="B53">1991</xref>). By contrast, the same patients have near normal color and form vision and have no apparent deficits in auditory or tactile motion perception. In sum, MT/MST is a motion selective region driven primarily by inputs from the visual modality.</p><p>In addition to MT/MST, higher-order areas in the temporal and parietal lobes also contribute to visual motion perception. While MT/MST responds to both random and coherent motion of any kind, a right-lateralized region along the superior temporal suclus (RSTS) is involved in perceiving only certain kind of motion: namely, biological human and animal motion (Grossman et al., <xref ref-type="bibr" rid="B18">2000</xref>; Grossman and Blake, <xref ref-type="bibr" rid="B19">2002</xref>; Saygin, <xref ref-type="bibr" rid="B41">2007</xref>; Grosbras et al., <xref ref-type="bibr" rid="B17">2012</xref>; Gilaie-Dotan et al., <xref ref-type="bibr" rid="B15">2013</xref>). Transiently disrupting RSTS activity, using TMS, selectively impairs visual perception of biological but not similar non-biological motion (Grossman et al., <xref ref-type="bibr" rid="B20">2005</xref>). Several regions in the parietal lobe, including the intra parietal sulcus (IPS) and right inferior parietal lobule (IPL) also contribute to higher-order aspects of motion perception. Unlike the selective response to <italic>visual</italic> motion in MT/MST, these parietal regions respond to visual, tactile, and auditory motion alike (Griffiths et al., <xref ref-type="bibr" rid="B16">1998</xref>; Lewis et al., <xref ref-type="bibr" rid="B28">2000</xref>; Bremmer et al., <xref ref-type="bibr" rid="B6">2001</xref>). The parietal cortex contributes to the perception of complex and ambiguous motion, including apparent motion (Battelli et al., <xref ref-type="bibr" rid="B3">2003</xref>). Responses to motion in the parietal cortex are closely related to an animal's subjective percept, rather then to the physical properties of the visual stimulus. For example, parietal neurons respond to the likely future direction of motion (Williams et al., <xref ref-type="bibr" rid="B52">2003</xref>).</p><p>In this paper we leverage existing knowledge of the visual motion system to gain insight into the link between sensory perception and language. We ask: what is the role of these visual motion regions in comprehension of language that describes motion? We can distinguish between three hypotheses about the relationship of language and perception that predict different patterns of results. First, understanding concrete language could depend on simulation of modality-specific experiences. If so, comprehension of a phrase such as &#x0201c;the man jumped onto the windowsill&#x0201d; should require activation in all of the regions that would be recruited while watching a man jumping, including MT/MST, STS, IPS, and IPL. Perception should permeate all aspects of language processing, including the retrieval of individual word meanings.</p><p>Second, a more limited hypothesis we will call optional interactivity, is that linguistic depictions of events optionally recruit some areas in common with sensory perception. For example, perceptual neural representations might be activated as a result of spontaneous imagery during language comprehension. On this view, visual motion areas might be more likely to respond to linguistic descriptions that elicit such imagery e.g., passages but not single words. These responses would occur via top-down influence of linguistic neural representations on visual motion circuits, and should therefore be more likely in higher-order rather than early perceptual areas. Specifically, parietal multi-modal motion neural representations might be evoked by linguistic stimuli, while early modality-specific neural representations in regions like MT/MST might require direct visual perception.</p><p>Finally, a third hypothesis is that comprehension of linguistic descriptions of motion never recruits perceptual neural representations. This could be due to the modularity of the language system, modularity of perceptual systems or both (Fodor, <xref ref-type="bibr" rid="B13">1983</xref>). Activity would occur in perceptual regions only when participants are viewing or intentionally imaging actual visual motion.</p><p>A number of prior studies asked whether brain areas that respond to visual movement also respond to language that describes motion. Initial investigations along these lines appeared to support a strong link between vision and language. Several neuroimaging studies observed responses near MT/MST to action verbs (e.g., to jump) as compared to names of object or animals (Martin et al., <xref ref-type="bibr" rid="B30">1995</xref>; Damasio et al., <xref ref-type="bibr" rid="B9">2001</xref>). These data were taken as evidence that the meanings of action verbs are represented in part as visual motion schema. Understanding a word such as &#x0201c;to jump&#x0201d; obligatorily involves retrieving past visual experiences of seeing jumping.</p><p>Subsequent experiments showed, however, that lateral temporal responses to action verbs lie anterior and superior to visual motion responses in MT/MST, in the posterior aspect of the left middle temporal gyrus (pLMTG; Kable et al., <xref ref-type="bibr" rid="B23">2002</xref>, <xref ref-type="bibr" rid="B22">2005</xref>; Bedny et al., <xref ref-type="bibr" rid="B4">2008</xref>; see also Wallentin et al., <xref ref-type="bibr" rid="B51">2011</xref> for similar findings in the context of a story comprehension task). The functional profile of the action-verb-responsive area is distinct from the motion-selective profile of its perceptual neighbors. The pLMTG responds not only to motion verbs such as &#x0201c;to run&#x0201d; but also to verbs such as &#x0201c;to think&#x0201d; which lack any motion information. Nor is the development of pLMTG dependent on visual motion experience. Individuals who have never seen jumping or running due to congenital blindness, show normal responses to action verbs in the pLMTG (Noppeney et al., <xref ref-type="bibr" rid="B34">2003</xref>; Bedny et al., <xref ref-type="bibr" rid="B4">2008</xref>). These findings suggest that pLMTG responses to motion verbs are driven by their semantic or linguistic properties, rather than by their motion associations. In sum, there is little evidence that MT/MST neural representations of visual motion are evoked automatically during comprehension of action verbs.</p><p>On the other hand, it remains possible that multi-modal parietal regions can be recruited both by actual visual motion and by words that describe motion, as suggested by the optional interactivity hypothesis. Several studies have reported larger responses to motion words than non-motion words in parietal regions (Noppeney et al., <xref ref-type="bibr" rid="B35">2005</xref>; Mahon et al., <xref ref-type="bibr" rid="B29">2007</xref>; Pobric et al., <xref ref-type="bibr" rid="B37">2010</xref>; Van Dam et al., <xref ref-type="bibr" rid="B48">2010</xref>). For example, a parietal region responded more to action verbs that describe an action of the body (&#x0201c;to wipe,&#x0201d; &#x0201c;to wave&#x0201d;) than abstract verbs (&#x0201c;to appreciate,&#x0201d; &#x0201c;to judge&#x0201d;; Van Dam et al., <xref ref-type="bibr" rid="B48">2010</xref>). However, no study has yet investigated whether the parietal regions recruited by motion words are the <italic>same</italic> parietal regions that respond to visual motion. The parietal cortex also contains regions that are responsive specifically to linguistic information, and regions that are sensitive to abstract properties of actions (Catani and Jones, <xref ref-type="bibr" rid="B56">2005</xref>; Fogassi et al., <xref ref-type="bibr" rid="B57">2005</xref>). It is possible that in parietal cortex, as in temporal cortex, visual motion and linguistic responses occur in neighboring but distinct patches.</p><p>Another key open question is whether richer or more vivid linguistic descriptions of motion are more likely to evoke responses in perceptual circuits. Some recent studies have found responses to sentences and passages describing motion events in MT/MST and the right STS (Tettamanti et al., <xref ref-type="bibr" rid="B46">2005</xref>; Saygin et al., <xref ref-type="bibr" rid="B42">2009</xref>; Deen and McCarthy, <xref ref-type="bibr" rid="B10">2010</xref>; McCullough et al., <xref ref-type="bibr" rid="B32">2012</xref>). These data raise the possibly that even early visual motion areas respond to rich motion language such as sentences and passages, but not to single words with motion features. As compared to single words, passages are better stimuli for eliciting spontaneous imagery. Unlike words, which refer to general categories, passages can describe specific instances of motion. For example, the word &#x0201c;to roll&#x0201d; refers to a class of rolling motion. A ball rolling down the street and a pig rolling in the mud describe two visually different events. If passages but not words elicit responses in visual motion areas, this could provide insights into the cognitive role of perceptual responses to language. However, no prior study has directly compared responses to passages and words in visual motion areas, leaving open the possibility that conflicting findings from prior literature are due to other methodological factors.</p><p>The goals of the present study were to ask (1) whether motion language is more likely to elicit responses in secondary than early sensory areas and (2) whether passages are more likely to activate perceptual motion areas than single words. We asked the same group of participants to perform three tasks. In task 1, participants read passages consisting of four sentences. Half of the passages contained action verbs and were high in visual motion features, whereas the other half contained cognitive verbs and were low in visual motion features. To ensure attention to text content, participants made semantic plausibility judgments for each sentence in a passage. In task 2, participants made semantic similarity judgments about words that were either high (e.g., to roll) or low (e.g., to smell) in visual motion features. Subsequent to the language tasks, participants saw a visual motion localizer (task 3) with three conditions: biological motion, random motion and luminance change. We localized lateral temporal (MT/MST and STS) and parietal (IPS and IPL) motion areas in each individual participant and asked whether these regions showed responses to either high motion words or high motion passages.</p></sec><sec sec-type="materials|methods" id="s2"><title>Materials and methods</title><sec><title>Participants</title><p>Eighteen adults (seven males) took part in three experimental tasks during a single fMRI session: motion word-comprehension, motion sentence-comprehension, and visual motion perception. Data from the passage comprehension task were excluded for one participant because they were discovered to have participated in a behavioral pilot study with the same stimuli. All participants were native English speakers and the average age of participants was 23 years (<italic>SD</italic> = 3.3, range 18&#x02013;30). Participants had no known psychiatric or neurological disabilities and were not currently taking any psychoactive medications. All participants gave informed consent prior to taking part in the study and were compensated $30 per hour.</p></sec><sec><title>Visual motion survey procedure</title><p>Words and passages were rated by a separate group of participants on the degree to which they elicit visual motion imagery (scale of 1&#x02013;7, 7 being high in visual motion; See Appendix for Instructions). The instructions for both surveys were identical except for the examples used (words vs. passages). Participants rated whole passages from task 1 and single words from task 2. Motion ratings were collected through Amazon Mechanical Turk, an online survey system. Participants were screened to be native English speakers through self-report. All participants completed a demographic survey and were asked what language they learned first. If they answered anything other than English, their data were dropped from further analyses. Two separate groups of participants rated the passages (<italic>n</italic> = 73, 34 females, mean age = 31 years, <italic>SD</italic> = 9.8, range 18&#x02013;61) and words (<italic>n</italic> = 22, 12 females, mean age = 28 years, <italic>SD</italic> = 11.2, range 18&#x02013;60). Participants were paid $1.50 for rating the passages and $0.25 for rating the words.</p></sec><sec><title>Stimuli</title><sec><title>Passage stimuli</title><p>Passages consisted of four short sentences each. Sentences were in active voice and consisted of a subject (singular noun), transitive verb followed by an object. Half of the passages contained high motion verbs (&#x0201c;A juror kicked a stool &#x02026; &#x0201d;), and half contained low motion cognitive verbs (&#x0201c;An accountant described a painting &#x02026; &#x0201d;). The high motion passages were rated as bringing to mind more visual motion than the low motion passages [<italic>t</italic><sub>(72)</sub> = 12.71, <italic>P</italic> &#x0003c; 0.0001; See Table <xref ref-type="table" rid="T1">1B</xref> for example of passage stimuli]. Average visual motion survey ratings for high and low motion passages are presented in Figure <xref ref-type="fig" rid="F1">1A</xref>.</p><table-wrap-group id="T1" position="float"><label>Table 1</label><caption><p><bold>List of stimuli</bold>.</p></caption><table-wrap id="d35e335" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="8" rowspan="1"><bold>(A) ALL WORD STIMULI</bold></th></tr></thead><tbody><tr><td align="left" colspan="8" rowspan="1"><bold>HIGH MOTION NOUNS</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">the aardvark</td><td align="left" rowspan="1" colspan="1">2.86</td><td align="left" rowspan="1" colspan="1">the coyote</td><td align="left" rowspan="1" colspan="1">4.27</td><td align="left" rowspan="1" colspan="1">the incident</td><td align="left" rowspan="1" colspan="1">3.14</td><td align="left" rowspan="1" colspan="1">the prom</td><td align="left" rowspan="1" colspan="1">4.59</td></tr><tr><td align="left" rowspan="1" colspan="1">the accident</td><td align="left" rowspan="1" colspan="1">4.18</td><td align="left" rowspan="1" colspan="1">the crane</td><td align="left" rowspan="1" colspan="1">3.23</td><td align="left" rowspan="1" colspan="1">the lemur</td><td align="left" rowspan="1" colspan="1">3.59</td><td align="left" rowspan="1" colspan="1">the quest</td><td align="left" rowspan="1" colspan="1">4.23</td></tr><tr><td align="left" rowspan="1" colspan="1">the adventure</td><td align="left" rowspan="1" colspan="1">4.45</td><td align="left" rowspan="1" colspan="1">the cyclone</td><td align="left" rowspan="1" colspan="1">5.59</td><td align="left" rowspan="1" colspan="1">the lesson</td><td align="left" rowspan="1" colspan="1">2.50</td><td align="left" rowspan="1" colspan="1">the reunion</td><td align="left" rowspan="1" colspan="1">3.32</td></tr><tr><td align="left" rowspan="1" colspan="1">the alligator</td><td align="left" rowspan="1" colspan="1">3.32</td><td align="left" rowspan="1" colspan="1">the dinner</td><td align="left" rowspan="1" colspan="1">3.18</td><td align="left" rowspan="1" colspan="1">the lizard</td><td align="left" rowspan="1" colspan="1">3.36</td><td align="left" rowspan="1" colspan="1">the rhinoceros</td><td align="left" rowspan="1" colspan="1">3.45</td></tr><tr><td align="left" rowspan="1" colspan="1">the alpaca</td><td align="left" rowspan="1" colspan="1">3.18</td><td align="left" rowspan="1" colspan="1">the drought</td><td align="left" rowspan="1" colspan="1">2.50</td><td align="left" rowspan="1" colspan="1">the llama</td><td align="left" rowspan="1" colspan="1">3.68</td><td align="left" rowspan="1" colspan="1">the robbery</td><td align="left" rowspan="1" colspan="1">4.41</td></tr><tr><td align="left" rowspan="1" colspan="1">the antelope</td><td align="left" rowspan="1" colspan="1">4.05</td><td align="left" rowspan="1" colspan="1">the elephant</td><td align="left" rowspan="1" colspan="1">3.77</td><td align="left" rowspan="1" colspan="1">the luncheon</td><td align="left" rowspan="1" colspan="1">2.81</td><td align="left" rowspan="1" colspan="1">the rodeo</td><td align="left" rowspan="1" colspan="1">3.91</td></tr><tr><td align="left" rowspan="1" colspan="1">the armadillo</td><td align="left" rowspan="1" colspan="1">2.86</td><td align="left" rowspan="1" colspan="1">the episode</td><td align="left" rowspan="1" colspan="1">3.09</td><td align="left" rowspan="1" colspan="1">the marathon</td><td align="left" rowspan="1" colspan="1">5.23</td><td align="left" rowspan="1" colspan="1">the salamander</td><td align="left" rowspan="1" colspan="1">3.27</td></tr><tr><td align="left" rowspan="1" colspan="1">the avalanche</td><td align="left" rowspan="1" colspan="1">5.27</td><td align="left" rowspan="1" colspan="1">the exam</td><td align="left" rowspan="1" colspan="1">3.36</td><td align="left" rowspan="1" colspan="1">the meerkat</td><td align="left" rowspan="1" colspan="1">3.41</td><td align="left" rowspan="1" colspan="1">the seminar</td><td align="left" rowspan="1" colspan="1">2.95</td></tr><tr><td align="left" rowspan="1" colspan="1">the banquet</td><td align="left" rowspan="1" colspan="1">3.41</td><td align="left" rowspan="1" colspan="1">the excursion</td><td align="left" rowspan="1" colspan="1">3.82</td><td align="left" rowspan="1" colspan="1">the mongoose</td><td align="left" rowspan="1" colspan="1">3.36</td><td align="left" rowspan="1" colspan="1">the sermon</td><td align="left" rowspan="1" colspan="1">2.41</td></tr><tr><td align="left" rowspan="1" colspan="1">the beaver</td><td align="left" rowspan="1" colspan="1">3.50</td><td align="left" rowspan="1" colspan="1">the falcon</td><td align="left" rowspan="1" colspan="1">3.86</td><td align="left" rowspan="1" colspan="1">the mosquito</td><td align="left" rowspan="1" colspan="1">4.23</td><td align="left" rowspan="1" colspan="1">the session</td><td align="left" rowspan="1" colspan="1">2.50</td></tr><tr><td align="left" rowspan="1" colspan="1">the blizzard</td><td align="left" rowspan="1" colspan="1">4.32</td><td align="left" rowspan="1" colspan="1">the famine</td><td align="left" rowspan="1" colspan="1">2.91</td><td align="left" rowspan="1" colspan="1">the movie</td><td align="left" rowspan="1" colspan="1">3.91</td><td align="left" rowspan="1" colspan="1">the shark</td><td align="left" rowspan="1" colspan="1">4.73</td></tr><tr><td align="left" rowspan="1" colspan="1">the brunch</td><td align="left" rowspan="1" colspan="1">2.95</td><td align="left" rowspan="1" colspan="1">the festival</td><td align="left" rowspan="1" colspan="1">4.45</td><td align="left" rowspan="1" colspan="1">the muskrat</td><td align="left" rowspan="1" colspan="1">3.73</td><td align="left" rowspan="1" colspan="1">the shindig</td><td align="left" rowspan="1" colspan="1">3.27</td></tr><tr><td align="left" rowspan="1" colspan="1">the burglary</td><td align="left" rowspan="1" colspan="1">4.00</td><td align="left" rowspan="1" colspan="1">the funeral</td><td align="left" rowspan="1" colspan="1">2.68</td><td align="left" rowspan="1" colspan="1">the nightmare</td><td align="left" rowspan="1" colspan="1">3.27</td><td align="left" rowspan="1" colspan="1">the speech</td><td align="left" rowspan="1" colspan="1">3.59</td></tr><tr><td align="left" rowspan="1" colspan="1">the butterfly</td><td align="left" rowspan="1" colspan="1">3.91</td><td align="left" rowspan="1" colspan="1">the gala</td><td align="left" rowspan="1" colspan="1">3.45</td><td align="left" rowspan="1" colspan="1">the octopus</td><td align="left" rowspan="1" colspan="1">4.00</td><td align="left" rowspan="1" colspan="1">the spider</td><td align="left" rowspan="1" colspan="1">3.91</td></tr><tr><td align="left" rowspan="1" colspan="1">the camel</td><td align="left" rowspan="1" colspan="1">3.32</td><td align="left" rowspan="1" colspan="1">the gazelle</td><td align="left" rowspan="1" colspan="1">4.91</td><td align="left" rowspan="1" colspan="1">the orangutan</td><td align="left" rowspan="1" colspan="1">4.05</td><td align="left" rowspan="1" colspan="1">the storm</td><td align="left" rowspan="1" colspan="1">4.76</td></tr><tr><td align="left" rowspan="1" colspan="1">the carnival</td><td align="left" rowspan="1" colspan="1">4.14</td><td align="left" rowspan="1" colspan="1">the giraffe</td><td align="left" rowspan="1" colspan="1">4.09</td><td align="left" rowspan="1" colspan="1">the ostrich</td><td align="left" rowspan="1" colspan="1">3.95</td><td align="left" rowspan="1" colspan="1">the supper</td><td align="left" rowspan="1" colspan="1">2.95</td></tr><tr><td align="left" rowspan="1" colspan="1">the caterpillar</td><td align="left" rowspan="1" colspan="1">2.86</td><td align="left" rowspan="1" colspan="1">the gopher</td><td align="left" rowspan="1" colspan="1">3.05</td><td align="left" rowspan="1" colspan="1">the pageant</td><td align="left" rowspan="1" colspan="1">3.52</td><td align="left" rowspan="1" colspan="1">the surgery</td><td align="left" rowspan="1" colspan="1">3.82</td></tr><tr><td align="left" rowspan="1" colspan="1">the ceremony</td><td align="left" rowspan="1" colspan="1">3.95</td><td align="left" rowspan="1" colspan="1">the gorilla</td><td align="left" rowspan="1" colspan="1">4.14</td><td align="left" rowspan="1" colspan="1">the parakeet</td><td align="left" rowspan="1" colspan="1">3.14</td><td align="left" rowspan="1" colspan="1">the tornado</td><td align="left" rowspan="1" colspan="1">5.82</td></tr><tr><td align="left" rowspan="1" colspan="1">the chameleon</td><td align="left" rowspan="1" colspan="1">3.27</td><td align="left" rowspan="1" colspan="1">the hamster</td><td align="left" rowspan="1" colspan="1">3.73</td><td align="left" rowspan="1" colspan="1">the peacock</td><td align="left" rowspan="1" colspan="1">3.68</td><td align="left" rowspan="1" colspan="1">the tournament</td><td align="left" rowspan="1" colspan="1">4.50</td></tr><tr><td align="left" rowspan="1" colspan="1">the chinchilla</td><td align="left" rowspan="1" colspan="1">2.73</td><td align="left" rowspan="1" colspan="1">the hedgehog</td><td align="left" rowspan="1" colspan="1">3.23</td><td align="left" rowspan="1" colspan="1">the pelican</td><td align="left" rowspan="1" colspan="1">3.73</td><td align="left" rowspan="1" colspan="1">the trial</td><td align="left" rowspan="1" colspan="1">3.23</td></tr><tr><td align="left" rowspan="1" colspan="1">the cockroach</td><td align="left" rowspan="1" colspan="1">3.59</td><td align="left" rowspan="1" colspan="1">the heron</td><td align="left" rowspan="1" colspan="1">3.27</td><td align="left" rowspan="1" colspan="1">the pigeon</td><td align="left" rowspan="1" colspan="1">3.86</td><td align="left" rowspan="1" colspan="1">the vacation</td><td align="left" rowspan="1" colspan="1">4.00</td></tr><tr><td align="left" rowspan="1" colspan="1">the concert</td><td align="left" rowspan="1" colspan="1">4.18</td><td align="left" rowspan="1" colspan="1">the holiday</td><td align="left" rowspan="1" colspan="1">3.36</td><td align="left" rowspan="1" colspan="1">the platypus</td><td align="left" rowspan="1" colspan="1">3.09</td><td align="left" rowspan="1" colspan="1">the vulture</td><td align="left" rowspan="1" colspan="1">4.41</td></tr><tr><td align="left" rowspan="1" colspan="1">the contest</td><td align="left" rowspan="1" colspan="1">3.00</td><td align="left" rowspan="1" colspan="1">the hurricane</td><td align="left" rowspan="1" colspan="1">5.45</td><td align="left" rowspan="1" colspan="1">the porcupine</td><td align="left" rowspan="1" colspan="1">3.41</td><td align="left" rowspan="1" colspan="1">the warthog</td><td align="left" rowspan="1" colspan="1">2.95</td></tr><tr><td align="left" rowspan="1" colspan="1">the coronation</td><td align="left" rowspan="1" colspan="1">2.73</td><td align="left" rowspan="1" colspan="1">the hyena</td><td align="left" rowspan="1" colspan="1">4.14</td><td align="left" rowspan="1" colspan="1">the porpoise</td><td align="left" rowspan="1" colspan="1">3.55</td><td align="left" rowspan="1" colspan="1">the wedding</td><td align="left" rowspan="1" colspan="1">3.91</td></tr><tr><td align="left" rowspan="1" colspan="1">the cougar</td><td align="left" rowspan="1" colspan="1">3.86</td><td align="left" rowspan="1" colspan="1">the iguana</td><td align="left" rowspan="1" colspan="1">2.91</td><td align="left" rowspan="1" colspan="1">the prank</td><td align="left" rowspan="1" colspan="1">3.32</td><td align="left" rowspan="1" colspan="1">the whale</td><td align="left" rowspan="1" colspan="1">3.95</td></tr><tr><td align="left" colspan="8" rowspan="1"><bold>LOW MOTION NOUNS</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">the acorn</td><td align="left" rowspan="1" colspan="1">2.55</td><td align="left" rowspan="1" colspan="1">the chrysanthemum</td><td align="left" rowspan="1" colspan="1">2.59</td><td align="left" rowspan="1" colspan="1">the maple</td><td align="left" rowspan="1" colspan="1">2.32</td><td align="left" rowspan="1" colspan="1">the shrub</td><td align="left" rowspan="1" colspan="1">2.27</td></tr><tr><td align="left" rowspan="1" colspan="1">the almond</td><td align="left" rowspan="1" colspan="1">2.23</td><td align="left" rowspan="1" colspan="1">the clementine</td><td align="left" rowspan="1" colspan="1">2.50</td><td align="left" rowspan="1" colspan="1">the mushroom</td><td align="left" rowspan="1" colspan="1">2.45</td><td align="left" rowspan="1" colspan="1">the soybean</td><td align="left" rowspan="1" colspan="1">2.32</td></tr><tr><td align="left" rowspan="1" colspan="1">the apricot</td><td align="left" rowspan="1" colspan="1">2.91</td><td align="left" rowspan="1" colspan="1">the clover</td><td align="left" rowspan="1" colspan="1">2.86</td><td align="left" rowspan="1" colspan="1">the oak</td><td align="left" rowspan="1" colspan="1">3.00</td><td align="left" rowspan="1" colspan="1">the sycamore</td><td align="left" rowspan="1" colspan="1">2.57</td></tr><tr><td align="left" rowspan="1" colspan="1">the artichoke</td><td align="left" rowspan="1" colspan="1">2.73</td><td align="left" rowspan="1" colspan="1">the coconut</td><td align="left" rowspan="1" colspan="1">2.77</td><td align="left" rowspan="1" colspan="1">the orange</td><td align="left" rowspan="1" colspan="1">2.55</td><td align="left" rowspan="1" colspan="1">the tangerine</td><td align="left" rowspan="1" colspan="1">2.36</td></tr><tr><td align="left" rowspan="1" colspan="1">the asparagus</td><td align="left" rowspan="1" colspan="1">2.32</td><td align="left" rowspan="1" colspan="1">the daffodil</td><td align="left" rowspan="1" colspan="1">2.68</td><td align="left" rowspan="1" colspan="1">the papaya</td><td align="left" rowspan="1" colspan="1">2.50</td><td align="left" rowspan="1" colspan="1">the turnip</td><td align="left" rowspan="1" colspan="1">2.36</td></tr><tr><td align="left" rowspan="1" colspan="1">the birch</td><td align="left" rowspan="1" colspan="1">2.27</td><td align="left" rowspan="1" colspan="1">the dandelion</td><td align="left" rowspan="1" colspan="1">2.55</td><td align="left" rowspan="1" colspan="1">the parsnip</td><td align="left" rowspan="1" colspan="1">2.18</td><td align="left" rowspan="1" colspan="1">the twig</td><td align="left" rowspan="1" colspan="1">2.32</td></tr><tr><td align="left" rowspan="1" colspan="1">the branch</td><td align="left" rowspan="1" colspan="1">3.23</td><td align="left" rowspan="1" colspan="1">the date</td><td align="left" rowspan="1" colspan="1">3.59</td><td align="left" rowspan="1" colspan="1">the pistachio</td><td align="left" rowspan="1" colspan="1">2.00</td><td align="left" rowspan="1" colspan="1">the vine</td><td align="left" rowspan="1" colspan="1">2.50</td></tr><tr><td align="left" rowspan="1" colspan="1">the bush</td><td align="left" rowspan="1" colspan="1">2.77</td><td align="left" rowspan="1" colspan="1">the evergreen</td><td align="left" rowspan="1" colspan="1">2.68</td><td align="left" rowspan="1" colspan="1">the pomegranate</td><td align="left" rowspan="1" colspan="1">2.27</td><td align="left" rowspan="1" colspan="1">the watercress</td><td align="left" rowspan="1" colspan="1">2.45</td></tr><tr><td align="left" rowspan="1" colspan="1">the cactus</td><td align="left" rowspan="1" colspan="1">2.32</td><td align="left" rowspan="1" colspan="1">the fern</td><td align="left" rowspan="1" colspan="1">2.41</td><td align="left" rowspan="1" colspan="1">the radish</td><td align="left" rowspan="1" colspan="1">2.05</td><td align="left" rowspan="1" colspan="1">the weed</td><td align="left" rowspan="1" colspan="1">2.45</td></tr><tr><td align="left" rowspan="1" colspan="1">the cantaloupe</td><td align="left" rowspan="1" colspan="1">2.55</td><td align="left" rowspan="1" colspan="1">the gourd</td><td align="left" rowspan="1" colspan="1">2.14</td><td align="left" rowspan="1" colspan="1">the rhubarb</td><td align="left" rowspan="1" colspan="1">2.45</td><td align="left" rowspan="1" colspan="1">the yam</td><td align="left" rowspan="1" colspan="1">2.23</td></tr><tr><td align="left" rowspan="1" colspan="1">the carnation</td><td align="left" rowspan="1" colspan="1">2.77</td><td align="left" rowspan="1" colspan="1">the grape</td><td align="left" rowspan="1" colspan="1">2.73</td><td align="left" rowspan="1" colspan="1">the root</td><td align="left" rowspan="1" colspan="1">2.36</td><td align="left" rowspan="1" colspan="1">the zucchini</td><td align="left" rowspan="1" colspan="1">2.45</td></tr><tr><td align="left" rowspan="1" colspan="1">the cashew</td><td align="left" rowspan="1" colspan="1">2.23</td><td align="left" rowspan="1" colspan="1">the herb</td><td align="left" rowspan="1" colspan="1">2.23</td><td align="left" rowspan="1" colspan="1">the rutabaga</td><td align="left" rowspan="1" colspan="1">2.09</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">the cedar</td><td align="left" rowspan="1" colspan="1">2.50</td><td align="left" rowspan="1" colspan="1">the kiwi</td><td align="left" rowspan="1" colspan="1">3.09</td><td align="left" rowspan="1" colspan="1">the seed</td><td align="left" rowspan="1" colspan="1">2.41</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td align="left" colspan="8" rowspan="1"><bold>HIGH MOTION VERBS</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">to bounce</td><td align="left" rowspan="1" colspan="1">4.82</td><td align="left" rowspan="1" colspan="1">to leap</td><td align="left" rowspan="1" colspan="1">4.36</td><td align="left" rowspan="1" colspan="1">to scoot</td><td align="left" rowspan="1" colspan="1">3.45</td><td align="left" rowspan="1" colspan="1">to swing</td><td align="left" rowspan="1" colspan="1">4.64</td></tr><tr><td align="left" rowspan="1" colspan="1">to climb</td><td align="left" rowspan="1" colspan="1">4.32</td><td align="left" rowspan="1" colspan="1">to limp</td><td align="left" rowspan="1" colspan="1">3.23</td><td align="left" rowspan="1" colspan="1">to scurry</td><td align="left" rowspan="1" colspan="1">3.82</td><td align="left" rowspan="1" colspan="1">to trek</td><td align="left" rowspan="1" colspan="1">4.18</td></tr><tr><td align="left" rowspan="1" colspan="1">to crawl</td><td align="left" rowspan="1" colspan="1">3.36</td><td align="left" rowspan="1" colspan="1">to meander</td><td align="left" rowspan="1" colspan="1">2.68</td><td align="left" rowspan="1" colspan="1">to skip</td><td align="left" rowspan="1" colspan="1">4.91</td><td align="left" rowspan="1" colspan="1">to trot</td><td align="left" rowspan="1" colspan="1">4.00</td></tr><tr><td align="left" rowspan="1" colspan="1">to dance</td><td align="left" rowspan="1" colspan="1">5.18</td><td align="left" rowspan="1" colspan="1">to paddle</td><td align="left" rowspan="1" colspan="1">4.27</td><td align="left" rowspan="1" colspan="1">to slide</td><td align="left" rowspan="1" colspan="1">4.55</td><td align="left" rowspan="1" colspan="1">to twirl</td><td align="left" rowspan="1" colspan="1">4.24</td></tr><tr><td align="left" rowspan="1" colspan="1">to drift</td><td align="left" rowspan="1" colspan="1">3.00</td><td align="left" rowspan="1" colspan="1">to prance</td><td align="left" rowspan="1" colspan="1">3.86</td><td align="left" rowspan="1" colspan="1">to slither</td><td align="left" rowspan="1" colspan="1">3.55</td><td align="left" rowspan="1" colspan="1">to twist</td><td align="left" rowspan="1" colspan="1">4.36</td></tr><tr><td align="left" rowspan="1" colspan="1">to drop</td><td align="left" rowspan="1" colspan="1">4.00</td><td align="left" rowspan="1" colspan="1">to prowl</td><td align="left" rowspan="1" colspan="1">3.41</td><td align="left" rowspan="1" colspan="1">to sneak</td><td align="left" rowspan="1" colspan="1">3.36</td><td align="left" rowspan="1" colspan="1">to waddle</td><td align="left" rowspan="1" colspan="1">3.18</td></tr><tr><td align="left" rowspan="1" colspan="1">to float</td><td align="left" rowspan="1" colspan="1">3.14</td><td align="left" rowspan="1" colspan="1">to revolve</td><td align="left" rowspan="1" colspan="1">4.68</td><td align="left" rowspan="1" colspan="1">to spin</td><td align="left" rowspan="1" colspan="1">4.77</td><td align="left" rowspan="1" colspan="1">to wade</td><td align="left" rowspan="1" colspan="1">3.18</td></tr><tr><td align="left" rowspan="1" colspan="1">to frolic</td><td align="left" rowspan="1" colspan="1">3.55</td><td align="left" rowspan="1" colspan="1">to ride</td><td align="left" rowspan="1" colspan="1">4.95</td><td align="left" rowspan="1" colspan="1">to stagger</td><td align="left" rowspan="1" colspan="1">3.27</td><td align="left" rowspan="1" colspan="1">to walk</td><td align="left" rowspan="1" colspan="1">4.27</td></tr><tr><td align="left" rowspan="1" colspan="1">to gallop</td><td align="left" rowspan="1" colspan="1">4.95</td><td align="left" rowspan="1" colspan="1">to roam</td><td align="left" rowspan="1" colspan="1">3.55</td><td align="left" rowspan="1" colspan="1">to stomp</td><td align="left" rowspan="1" colspan="1">3.73</td><td align="left" rowspan="1" colspan="1">to wander</td><td align="left" rowspan="1" colspan="1">3.82</td></tr><tr><td align="left" rowspan="1" colspan="1">to glide</td><td align="left" rowspan="1" colspan="1">4.41</td><td align="left" rowspan="1" colspan="1">to roll</td><td align="left" rowspan="1" colspan="1">4.55</td><td align="left" rowspan="1" colspan="1">to stroll</td><td align="left" rowspan="1" colspan="1">3.18</td><td align="left" rowspan="1" colspan="1">to whirl</td><td align="left" rowspan="1" colspan="1">4.24</td></tr><tr><td align="left" rowspan="1" colspan="1">to hike</td><td align="left" rowspan="1" colspan="1">4.41</td><td align="left" rowspan="1" colspan="1">to rotate</td><td align="left" rowspan="1" colspan="1">4.86</td><td align="left" rowspan="1" colspan="1">to strut</td><td align="left" rowspan="1" colspan="1">3.50</td><td align="left" rowspan="1" colspan="1">to zigzag</td><td align="left" rowspan="1" colspan="1">4.55</td></tr><tr><td align="left" rowspan="1" colspan="1">to hobble</td><td align="left" rowspan="1" colspan="1">3.33</td><td align="left" rowspan="1" colspan="1">to saunter</td><td align="left" rowspan="1" colspan="1">2.67</td><td align="left" rowspan="1" colspan="1">to stumble</td><td align="left" rowspan="1" colspan="1">3.68</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">to jump</td><td align="left" rowspan="1" colspan="1">5.27</td><td align="left" rowspan="1" colspan="1">to scamper</td><td align="left" rowspan="1" colspan="1">3.55</td><td align="left" rowspan="1" colspan="1">to swim</td><td align="left" rowspan="1" colspan="1">4.86</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td align="left" colspan="8" rowspan="1"><bold>LOW MOTION VERBS</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">to admire</td><td align="left" rowspan="1" colspan="1">3.09</td><td align="left" rowspan="1" colspan="1">to flare</td><td align="left" rowspan="1" colspan="1">2.77</td><td align="left" rowspan="1" colspan="1">to moan</td><td align="left" rowspan="1" colspan="1">2.55</td><td align="left" rowspan="1" colspan="1">to sense</td><td align="left" rowspan="1" colspan="1">2.82</td></tr><tr><td align="left" rowspan="1" colspan="1">to ascertain</td><td align="left" rowspan="1" colspan="1">3.05</td><td align="left" rowspan="1" colspan="1">to flash</td><td align="left" rowspan="1" colspan="1">3.59</td><td align="left" rowspan="1" colspan="1">to mumble</td><td align="left" rowspan="1" colspan="1">2.55</td><td align="left" rowspan="1" colspan="1">to shimmer</td><td align="left" rowspan="1" colspan="1">3.27</td></tr><tr><td align="left" rowspan="1" colspan="1">to babble</td><td align="left" rowspan="1" colspan="1">2.81</td><td align="left" rowspan="1" colspan="1">to flicker</td><td align="left" rowspan="1" colspan="1">2.73</td><td align="left" rowspan="1" colspan="1">to notice</td><td align="left" rowspan="1" colspan="1">2.68</td><td align="left" rowspan="1" colspan="1">to shine</td><td align="left" rowspan="1" colspan="1">3.05</td></tr><tr><td align="left" rowspan="1" colspan="1">to behold</td><td align="left" rowspan="1" colspan="1">3.00</td><td align="left" rowspan="1" colspan="1">to frisk</td><td align="left" rowspan="1" colspan="1">3.09</td><td align="left" rowspan="1" colspan="1">to observe</td><td align="left" rowspan="1" colspan="1">3.00</td><td align="left" rowspan="1" colspan="1">to shriek</td><td align="left" rowspan="1" colspan="1">3.05</td></tr><tr><td align="left" rowspan="1" colspan="1">to bellow</td><td align="left" rowspan="1" colspan="1">3.48</td><td align="left" rowspan="1" colspan="1">to gape</td><td align="left" rowspan="1" colspan="1">3.05</td><td align="left" rowspan="1" colspan="1">to ogle</td><td align="left" rowspan="1" colspan="1">2.32</td><td align="left" rowspan="1" colspan="1">to sing</td><td align="left" rowspan="1" colspan="1">3.55</td></tr><tr><td align="left" rowspan="1" colspan="1">to blare</td><td align="left" rowspan="1" colspan="1">2.86</td><td align="left" rowspan="1" colspan="1">to gawk</td><td align="left" rowspan="1" colspan="1">2.82</td><td align="left" rowspan="1" colspan="1">to overhear</td><td align="left" rowspan="1" colspan="1">2.64</td><td align="left" rowspan="1" colspan="1">to smell</td><td align="left" rowspan="1" colspan="1">2.77</td></tr><tr><td align="left" rowspan="1" colspan="1">to blaze</td><td align="left" rowspan="1" colspan="1">3.27</td><td align="left" rowspan="1" colspan="1">to gaze</td><td align="left" rowspan="1" colspan="1">2.27</td><td align="left" rowspan="1" colspan="1">to overlook</td><td align="left" rowspan="1" colspan="1">2.91</td><td align="left" rowspan="1" colspan="1">to sniff</td><td align="left" rowspan="1" colspan="1">3.09</td></tr><tr><td align="left" rowspan="1" colspan="1">to buzz</td><td align="left" rowspan="1" colspan="1">3.41</td><td align="left" rowspan="1" colspan="1">to glance</td><td align="left" rowspan="1" colspan="1">2.86</td><td align="left" rowspan="1" colspan="1">to peek</td><td align="left" rowspan="1" colspan="1">3.32</td><td align="left" rowspan="1" colspan="1">to snoop</td><td align="left" rowspan="1" colspan="1">3.05</td></tr><tr><td align="left" rowspan="1" colspan="1">to caress</td><td align="left" rowspan="1" colspan="1">3.55</td><td align="left" rowspan="1" colspan="1">to gleam</td><td align="left" rowspan="1" colspan="1">2.41</td><td align="left" rowspan="1" colspan="1">to peep</td><td align="left" rowspan="1" colspan="1">2.91</td><td align="left" rowspan="1" colspan="1">to sparkle</td><td align="left" rowspan="1" colspan="1">3.41</td></tr><tr><td align="left" rowspan="1" colspan="1">to chant</td><td align="left" rowspan="1" colspan="1">2.45</td><td align="left" rowspan="1" colspan="1">to glimpse</td><td align="left" rowspan="1" colspan="1">2.91</td><td align="left" rowspan="1" colspan="1">to peer</td><td align="left" rowspan="1" colspan="1">3.19</td><td align="left" rowspan="1" colspan="1">to spy</td><td align="left" rowspan="1" colspan="1">3.55</td></tr><tr><td align="left" rowspan="1" colspan="1">to chatter</td><td align="left" rowspan="1" colspan="1">3.14</td><td align="left" rowspan="1" colspan="1">to glisten</td><td align="left" rowspan="1" colspan="1">2.64</td><td align="left" rowspan="1" colspan="1">to perceive</td><td align="left" rowspan="1" colspan="1">2.55</td><td align="left" rowspan="1" colspan="1">to squawk</td><td align="left" rowspan="1" colspan="1">2.91</td></tr><tr><td align="left" rowspan="1" colspan="1">to chime</td><td align="left" rowspan="1" colspan="1">2.68</td><td align="left" rowspan="1" colspan="1">to glow</td><td align="left" rowspan="1" colspan="1">3.05</td><td align="left" rowspan="1" colspan="1">to peruse</td><td align="left" rowspan="1" colspan="1">2.86</td><td align="left" rowspan="1" colspan="1">to squeak</td><td align="left" rowspan="1" colspan="1">3.05</td></tr><tr><td align="left" rowspan="1" colspan="1">to chuckle</td><td align="left" rowspan="1" colspan="1">2.82</td><td align="left" rowspan="1" colspan="1">to groan</td><td align="left" rowspan="1" colspan="1">2.59</td><td align="left" rowspan="1" colspan="1">to pet</td><td align="left" rowspan="1" colspan="1">3.50</td><td align="left" rowspan="1" colspan="1">to squeal</td><td align="left" rowspan="1" colspan="1">2.77</td></tr><tr><td align="left" rowspan="1" colspan="1">to clang</td><td align="left" rowspan="1" colspan="1">3.23</td><td align="left" rowspan="1" colspan="1">to growl</td><td align="left" rowspan="1" colspan="1">2.82</td><td align="left" rowspan="1" colspan="1">to probe</td><td align="left" rowspan="1" colspan="1">3.32</td><td align="left" rowspan="1" colspan="1">to stare</td><td align="left" rowspan="1" colspan="1">2.95</td></tr><tr><td align="left" rowspan="1" colspan="1">to click</td><td align="left" rowspan="1" colspan="1">3.09</td><td align="left" rowspan="1" colspan="1">to grunt</td><td align="left" rowspan="1" colspan="1">2.64</td><td align="left" rowspan="1" colspan="1">to prod</td><td align="left" rowspan="1" colspan="1">3.00</td><td align="left" rowspan="1" colspan="1">to stink</td><td align="left" rowspan="1" colspan="1">2.41</td></tr><tr><td align="left" rowspan="1" colspan="1">to crackle</td><td align="left" rowspan="1" colspan="1">3.32</td><td align="left" rowspan="1" colspan="1">to hiss</td><td align="left" rowspan="1" colspan="1">2.64</td><td align="left" rowspan="1" colspan="1">to purr</td><td align="left" rowspan="1" colspan="1">2.71</td><td align="left" rowspan="1" colspan="1">to stroke</td><td align="left" rowspan="1" colspan="1">3.68</td></tr><tr><td align="left" rowspan="1" colspan="1">to creak</td><td align="left" rowspan="1" colspan="1">2.64</td><td align="left" rowspan="1" colspan="1">to hoot</td><td align="left" rowspan="1" colspan="1">3.18</td><td align="left" rowspan="1" colspan="1">to recognize</td><td align="left" rowspan="1" colspan="1">2.23</td><td align="left" rowspan="1" colspan="1">to tap</td><td align="left" rowspan="1" colspan="1">4.14</td></tr><tr><td align="left" rowspan="1" colspan="1">to cry</td><td align="left" rowspan="1" colspan="1">3.45</td><td align="left" rowspan="1" colspan="1">to howl</td><td align="left" rowspan="1" colspan="1">3.27</td><td align="left" rowspan="1" colspan="1">to reek</td><td align="left" rowspan="1" colspan="1">2.23</td><td align="left" rowspan="1" colspan="1">to taste</td><td align="left" rowspan="1" colspan="1">3.18</td></tr><tr><td align="left" rowspan="1" colspan="1">to detect</td><td align="left" rowspan="1" colspan="1">3.23</td><td align="left" rowspan="1" colspan="1">to hum</td><td align="left" rowspan="1" colspan="1">2.59</td><td align="left" rowspan="1" colspan="1">to ring</td><td align="left" rowspan="1" colspan="1">3.55</td><td align="left" rowspan="1" colspan="1">to thud</td><td align="left" rowspan="1" colspan="1">2.91</td></tr><tr><td align="left" rowspan="1" colspan="1">to discern</td><td align="left" rowspan="1" colspan="1">2.50</td><td align="left" rowspan="1" colspan="1">to identify</td><td align="left" rowspan="1" colspan="1">2.82</td><td align="left" rowspan="1" colspan="1">to roar</td><td align="left" rowspan="1" colspan="1">3.71</td><td align="left" rowspan="1" colspan="1">to twinkle</td><td align="left" rowspan="1" colspan="1">3.00</td></tr><tr><td align="left" rowspan="1" colspan="1">to discover</td><td align="left" rowspan="1" colspan="1">3.73</td><td align="left" rowspan="1" colspan="1">to inspect</td><td align="left" rowspan="1" colspan="1">2.95</td><td align="left" rowspan="1" colspan="1">to rub</td><td align="left" rowspan="1" colspan="1">3.36</td><td align="left" rowspan="1" colspan="1">to view</td><td align="left" rowspan="1" colspan="1">2.77</td></tr><tr><td align="left" rowspan="1" colspan="1">to eavesdrop</td><td align="left" rowspan="1" colspan="1">2.41</td><td align="left" rowspan="1" colspan="1">to investigate</td><td align="left" rowspan="1" colspan="1">3.59</td><td align="left" rowspan="1" colspan="1">to rumble</td><td align="left" rowspan="1" colspan="1">3.82</td><td align="left" rowspan="1" colspan="1">to wail</td><td align="left" rowspan="1" colspan="1">3.05</td></tr><tr><td align="left" rowspan="1" colspan="1">to evaluate</td><td align="left" rowspan="1" colspan="1">2.68</td><td align="left" rowspan="1" colspan="1">to jingle</td><td align="left" rowspan="1" colspan="1">3.41</td><td align="left" rowspan="1" colspan="1">to rustle</td><td align="left" rowspan="1" colspan="1">2.86</td><td align="left" rowspan="1" colspan="1">to whine</td><td align="left" rowspan="1" colspan="1">3.00</td></tr><tr><td align="left" rowspan="1" colspan="1">to examine</td><td align="left" rowspan="1" colspan="1">3.14</td><td align="left" rowspan="1" colspan="1">to leer</td><td align="left" rowspan="1" colspan="1">2.50</td><td align="left" rowspan="1" colspan="1">to scan</td><td align="left" rowspan="1" colspan="1">2.82</td><td align="left" rowspan="1" colspan="1">to whisper</td><td align="left" rowspan="1" colspan="1">2.59</td></tr><tr><td align="left" rowspan="1" colspan="1">to explore</td><td align="left" rowspan="1" colspan="1">4.86</td><td align="left" rowspan="1" colspan="1">to lick</td><td align="left" rowspan="1" colspan="1">3.91</td><td align="left" rowspan="1" colspan="1">to scrutinize</td><td align="left" rowspan="1" colspan="1">2.77</td><td align="left" rowspan="1" colspan="1">to witness</td><td align="left" rowspan="1" colspan="1">2.38</td></tr></tbody></table></table-wrap><table-wrap id="d35e1650" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="4" rowspan="1"><bold>(B) SAMPLE PASSAGE STIMULI</bold></th></tr></thead><tbody><tr><td align="left" colspan="4" rowspan="1"><bold>HIGH MOTION PASSAGES</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">A physicist assassinated his nephew</td><td align="left" rowspan="1" colspan="1">5.59</td><td align="left" rowspan="1" colspan="1">A lunatic juggled oranges</td><td align="left" rowspan="1" colspan="1">5.41</td></tr><tr><td align="left" rowspan="1" colspan="1">Then a client lifted a prostitute</td><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Then a clown squished tires</td><td rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Then a stewardess stabbed a pilot</td><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Then an elephant bumped a barrel</td><td rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Then a waitress whacked a bachelor</td><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Then a monkey twirled a baton</td><td rowspan="1" colspan="1"/></tr><tr><td align="left" colspan="4" rowspan="1"><bold>LOW MOTION PASSAGES</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">A cameraman detested a slave</td><td align="left" rowspan="1" colspan="1">2.13</td><td align="left" rowspan="1" colspan="1">A freshman praised a sculpture</td><td align="left" rowspan="1" colspan="1">2.76</td></tr><tr><td align="left" rowspan="1" colspan="1">Then an eagle surprised a kitten</td><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Then a jury judged a gymnast</td><td rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Then a clergyman mocked a pessimist</td><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Then a president calmed a baby</td><td rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Then a vampire thrilled a cardiologist</td><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Then an enthusiast pleased a scholar</td><td rowspan="1" colspan="1"/></tr></tbody></table><table-wrap-foot><p><italic>Average motion ratings obtained from Amazon Turk surveys are presented next to the stimuli</italic>.</p></table-wrap-foot></table-wrap></table-wrap-group><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Visual motion ratings and neural responses to motion passages and words in visual motion ROIs. (A)</bold> Visual motion ratings <bold>(B)</bold> Percentage signal change in visual motion regions of interest during passage and word comprehension. Error bars throughout figure represent standard error of the mean. Asterisks indicate a significant difference between the high and low motion conditions (<italic>P</italic> &#x0003c; 0.05).</p></caption><graphic xlink:href="fpsyg-04-00537-g0001"/></fig></sec><sec><title>Word-comprehension stimuli</title><p>Words consisted of manner of motion verbs (&#x0201c;to bounce&#x0201d; <italic>n</italic> = 50), emission verbs (&#x0201c;to clang&#x0201d; <italic>n</italic> = 50), perception verbs (&#x0201c;to stare&#x0201d; <italic>n</italic> = 50), animal nouns (&#x0201c;the giraffe&#x0201d; <italic>n</italic> = 50), event nouns (&#x0201c;the hurricane&#x0201d; <italic>n</italic> = 50), and plant nouns (&#x0201c;the cactus&#x0201d; <italic>n</italic> = 50). See Table <xref ref-type="table" rid="T1">1A</xref> for all word stimuli.</p><p>Among verbs, manner of motion verbs were rated significantly higher than emission [<italic>t</italic><sub>(21)</sub> = 4.95, <italic>P</italic> &#x0003c; 0.0001] and perception verbs [<italic>t</italic><sub>(21)</sub> = 4.27, <italic>P</italic> &#x0003c; 0.0001]. Emission and perception verbs did not differ from each other [<italic>t</italic><sub>(21)</sub> = 0.44, <italic>P</italic> = 0.66]. Among nouns, both animals and events had significantly higher visual motion ratings than the plant nouns [animals vs. plants, <italic>t</italic><sub>(21)</sub> = 4.86, <italic>P</italic> &#x0003c; 0.0001; events vs. plants, <italic>t</italic><sub>(21)</sub> = 5.63, <italic>P</italic> &#x0003c; 0.0001]. Animals and event nouns did not differ from each other [<italic>t</italic><sub>(21)</sub> = 0.75, <italic>P</italic> = 0.46].</p><p>Based on the ratings, words were grouped into high motion verbs (manner of motion verbs), low motion verbs (perception and emission verbs), high motion nouns (animals and events), and low motion nouns (plants). Average visual motion survey ratings for high and low motion verbs and nouns are presented in Figure <xref ref-type="fig" rid="F1">1A</xref>. According to information obtained using the Celex database (Baayen et al., <xref ref-type="bibr" rid="B1">1995</xref>), high and low motion words did not differ in frequency [<italic>t</italic><sub>(149)</sub> = 1.27, <italic>P</italic> = 0.21 nouns, <italic>t</italic><sub>(149)</sub> = 0.34, <italic>P</italic> = 0.73 verbs] or number of syllables [<italic>t</italic><sub>(149)</sub> = 1.73, <italic>P</italic> = 0.09 nouns, <italic>t</italic><sub>(149)</sub> = 1.49, <italic>P</italic> = 0.14 verbs]. Syllable lengths, frequencies, and visual motion ratings by category are listed in Table <xref ref-type="table" rid="T2">2</xref>.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Behavioral data from the word comprehension experiment and the sentence comprehension experiment</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="left" valign="top" rowspan="1" colspan="1"><bold>Number of syllables</bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold>Frequency</bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold>Visual motion ratings</bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold>Similarity/plausibility ratings</bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold>Reaction time (ms)</bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">High motion verbs</td><td align="char" char="." rowspan="1" colspan="1">1.34 (0.52)</td><td align="char" char="." rowspan="1" colspan="1">1.03 (0.60)</td><td align="char" char="." rowspan="1" colspan="1">4.00 (0.69)</td><td align="char" char="." rowspan="1" colspan="1">2.08 (0.97)</td><td align="left" rowspan="1" colspan="1">1676 (431)</td></tr><tr><td align="left" rowspan="1" colspan="1">Low motion verbs</td><td align="char" char="." rowspan="1" colspan="1">1.52 (0.77)</td><td align="char" char="." rowspan="1" colspan="1">1.00 (0.52)</td><td align="char" char="." rowspan="1" colspan="1">3.01 (1.25)</td><td align="char" char="." rowspan="1" colspan="1">2.16 (1.03)</td><td align="left" rowspan="1" colspan="1">1722 (445)</td></tr><tr><td align="left" rowspan="1" colspan="1">High motion nouns</td><td align="char" char="." rowspan="1" colspan="1">2.42 (0.79)</td><td align="char" char="." rowspan="1" colspan="1">0.68 (0.58)</td><td align="char" char="." rowspan="1" colspan="1">3.67 (1.10)</td><td align="char" char="." rowspan="1" colspan="1">2.22 (1.00)</td><td align="left" rowspan="1" colspan="1">1650 (432)</td></tr><tr><td align="left" rowspan="1" colspan="1">Low motion nouns</td><td align="char" char="." rowspan="1" colspan="1">2.16 (1.00)</td><td align="char" char="." rowspan="1" colspan="1">0.55 (0.57)</td><td align="char" char="." rowspan="1" colspan="1">2.50 (1.39)</td><td align="char" char="." rowspan="1" colspan="1">2.20 (0.92)</td><td align="left" rowspan="1" colspan="1">1651 (428)</td></tr><tr><td align="left" rowspan="1" colspan="1">Low motion passages</td><td align="left" rowspan="1" colspan="1">n/a</td><td align="left" rowspan="1" colspan="1">n/a</td><td align="char" char="." rowspan="1" colspan="1">4.85 (0.95)</td><td align="char" char="." rowspan="1" colspan="1">1.36 (0.17)</td><td align="char" char="." rowspan="1" colspan="1">1785 (250)</td></tr><tr><td align="left" rowspan="1" colspan="1">High motion passages</td><td align="left" rowspan="1" colspan="1">n/a</td><td align="left" rowspan="1" colspan="1">n/a</td><td align="char" char="." rowspan="1" colspan="1">2.65 (1.38)</td><td align="char" char="." rowspan="1" colspan="1">1.29 (0.13)</td><td align="char" char="." rowspan="1" colspan="1">1831 (248)</td></tr></tbody></table><table-wrap-foot><p><italic>Means and standard deviations of behavioral data of all conceptual categories. Standard deviations are presented in parentheses next to the mean</italic>.</p></table-wrap-foot></table-wrap></sec></sec><sec><title>Tasks</title><sec><title>Passage-comprehension task</title><p>Participants read passages consisting of four sentences and rated each sentence in the passage on semantic plausibility. Passages were presented visually, one sentence at a time. Participants rated each sentence as either 1 plausible, 2 possible but unlikely, or 3 impossible. Eighty of the sentences were intentionally constructed to be semantically impossible (e.g., &#x0201c;An optimist snipped a sky&#x0201d;). Impossible sentences were equally likely to occur in either high motion or low motion passages, with only one sentence per passage being impossible. Participants were told before the scan that some sentences would be obviously impossible, but that there were no correct answers. Prior to the scan each participant practiced by rating 64 sentences from 16 passages that were not included in the actual fMRI experiment (32 high motion sentences and 32 low motion sentences). Participants indicated their responses on an MRI-compatible button pad. Each passage constituted one 12-s block of the task with each sentences presented for 3 s. Passages were separated by 10 s of fixation. The task was completed in six 6-min and 2-s runs with 20 passages per run. Blocks alternated between the high motion and low motion conditions and condition order was counterbalanced across all runs and across participants. Block order was randomized across participants.</p></sec><sec><title>Word-comprehension task</title><p>Participants next completed 3&#x02013;4 runs of a word comprehension task. To ensure that participants were attending to the meanings of the words, they performed a meaning similarity judgment task during the MRI scan. Participants heard pairs of words and rated them on similarity in meaning on a scale of 1&#x02013;4 (1 being very similar and 4 being very dissimilar). Each of the 300 words was presented twice during the experiment, each time paired with a different word. During each run 14 blocks were presented, and each block consisted of five word pairs of one word-type (animals, plants, manner of motion verbs, etc.). Each block was 18 s long (with each word pair presented for 3.6 s) and blocks were separated by 14 s of fixation. The order of the blocks was counterbalanced across participants. Participants also heard pairs of non-meaningful sounds (backwards speech) and judged sound similarity. Non-meaningful sounds were added as a baseline for a separate study and were not included in the analyses of the present paper. Words and sounds were presented over headphones and participants responded by pushing keys on an MRI-compatible button pad.</p></sec><sec><title>Visual motion localizer</title><p>After the sentence and word-comprehension tasks, participants saw 1&#x02013;2 runs of visual motion localizer. Participants performed a 1-back task while viewing point-light animations in three conditions. The biological motion condition consisted of point-light walkers: light-points marked joint positions and their motion resembled human actions such as (walking, running, or jumping rope). For the random motion condition, the same points of light began motion from scrambled positions leading to a percept that did not resemble human actions (Grossman et al., <xref ref-type="bibr" rid="B18">2000</xref>). In a third non-motion condition, the points remained in the same position on the screen and changed in luminance by fading in and out. The animations were blocked by condition; each block lasted 12 s (1.5 s per animation) separated by 12 s of fixation. Each run lasted 7 min and 24 s.</p></sec><sec><title>Functional magnetic resonance imaging data acquisition and analysis</title><p>Structural and functional data were collected on a 3 Tesla Siemens scanner at the Athinoula A. Martinos Imaging Center at the McGovern Institute for Brain Research at the Massachusetts Institute of Technology. T1-weighted structural images were collected in 128 axial slices with 1.33 mm isotropic voxels [repetition time (TR) = 2 ms; echo time (TE) = 3.39 ms]. Functional, blood oxygenation level-dependent (BOLD) data were acquired in 3 by 3 by 4 mm voxels (<italic>TR</italic> = 2 s; <italic>TE</italic> = 30 ms) in 30 near-axial slices. The first 4 s of each run were excluded to allow for steady-state magnetization.</p><p>Data analysis was performed using SPM8 and in-house software. The data were realigned, smoothed with a 5 mm smoothing kernel, and normalized to a standard template in Montreal Neurological Institute space. The modified-linear model was used to analyze BOLD activity of each subject as a function of condition. Covariates of interest were convolved with a standard hemodynamic response function (HRF). Nuisance covariates included run effects, an intercept term, and global signal. Time-series data were subjected to a high-pass filter (0.008 Hz).</p><p>BOLD signal differences between conditions were evaluated through second level, random-effects analysis. In whole-brain analyses, the false positive rate was controlled at <italic>P</italic> &#x0003c; 0.05 (corrected) by performing Monte Carlo permutation tests on the data (using a cluster size threshold with a primary threshold of 3; Nichols and Holmes, <xref ref-type="bibr" rid="B58">2002</xref>; Hayasaka and Nichols, <xref ref-type="bibr" rid="B59">2004</xref>).</p><p>Orthogonal functional ROIs were identified in individual subjects. Search spaces were defined based on the whole-brain group results, and individual ROIs were defined by taking all active voxels within a sphere around individual peaks in the search space. From the visual motion perception task, basic visual motion perception ROIs were defined based on the random motion &#x0003e; luminance change contrasts (bilateral MT/MST, IPL, and SPL). Bilateral biological motion ROI were also defined based on the biological motion &#x0003e; random motion contrast in the left and right STS (Grossman et al., <xref ref-type="bibr" rid="B18">2000</xref>). With the exception of the LSTS, contrasts were thresholded in individual subjects at <italic>p</italic> = 0.001, <italic>k</italic> = 10 for the purposes of defining ROIs. If no voxels were observed at this threshold, the subject was excluded from the analysis. For left STS ROIs, contrasts were thresholded at <italic>p</italic> = 0.01, <italic>k</italic> = 10 because no ROIs could be defined at the higher threshold in most participants. This procedure resulted in the following number of subjects per ROI: LMT 15, RMT 15, LIPL 12, RIPL 13, LSPL 12, RSPL 13, RSTS 14, and LSTS 14.</p><p>We also defined an action-verb selective ROI along the pLMTG. As in prior work the pLMTG was defined based on the motion verbs &#x0003e; animals contrast from the word-comprehension task (Martin et al., <xref ref-type="bibr" rid="B30">1995</xref>; Kable et al., <xref ref-type="bibr" rid="B23">2002</xref>, <xref ref-type="bibr" rid="B22">2005</xref>; Bedny et al., <xref ref-type="bibr" rid="B4">2008</xref>). This resulted in 16 subjects with the ROI.</p><p>Region-of-interest (ROI) analyses were performed on the average of percentage signal change (PSC) relative to a resting baseline (for examples of similar analyses, see Saxe et al., <xref ref-type="bibr" rid="B60">2006</xref>; Baker et al., <xref ref-type="bibr" rid="B61">2007</xref>). For the data from the word comprehension task, we examined the PSC from TR 6 through 18; for the sentence comprehension task, the PSC was averaged from TR 4 to 16; for the visual motion perception task, PSC was averaged from TR 8 to 18. Tests carried out in the ROI analyses were not corrected for multiple comparisons.</p></sec></sec></sec><sec sec-type="results" id="s3"><title>Results</title><sec><title>Behavioral results</title><sec><title>Passage comprehension</title><p>Participants responded faster to the sentences in the high motion passages than to the sentences in the low motion passages [high motion <italic>M</italic> = 1.79 s, <italic>SD</italic> = 0.25 s, low motion passages <italic>M</italic> = 1.83 s, <italic>SD</italic> = 0.25 s; <italic>t</italic><sub>(16)</sub> = 3.23, <italic>P</italic> = 0.005]. High motion sentences were also rated as less plausible [high motion <italic>M</italic> = 1.36, <italic>SD</italic> = 0.17, low motion <italic>M</italic> = 1.29, <italic>SD</italic> = 0.13; <italic>t</italic><sub>(16)</sub> = 3.85, <italic>P</italic> = 0.001; Table <xref ref-type="table" rid="T2">2</xref>]. The sentences that were intentionally constructed to be &#x0201c;impossible&#x0201d; received an average rating of 2.63 (<italic>SD</italic> = 0.30; with a rating of 3 for an impossible sentence). The average for the impossible sentences was significantly higher than the other sentences, which received an average rating of 1.26 [<italic>SD</italic> = 0.15; <italic>t</italic><sub>(16)</sub> = 17.87, <italic>P</italic> = 0.0001], indicating that participants were attending to the meanings of the sentences.</p></sec><sec><title>Word comprehension</title><p>There was no difference in reaction time between the low motion nouns and the high motion nouns [<italic>t</italic><sub>(13)</sub> = 0.14, <italic>P</italic> = 0.90]. The low motion verbs took longer than the high motion verbs [<italic>t</italic><sub>(13)</sub> = 2.70, <italic>P</italic> = 0.02]. There were no differences in the average within-category similarity ratings for high vs. low motion nouns [<italic>t</italic><sub>(13)</sub> = 0.45, <italic>P</italic> = 0.67] or high vs. low motion verbs [<italic>t</italic><sub>(13)</sub> = 1.41, <italic>P</italic> = 0.18; Table <xref ref-type="table" rid="T2">2</xref>].</p></sec><sec><title>Visual motion localizer</title><p>Participants correctly detected repeating animations in 87% (<italic>SD</italic> = 18%) of the biological motion animations, in 86% (<italic>SD</italic> = 18%) of the random motion animations, and in 89% (<italic>SD</italic> = 19%) of static luminance change animations. Participants were faster at responding to static luminance (<italic>M</italic> = 0.85 s, <italic>SD</italic> = 0.27 s) than responding to random motion [<italic>M</italic> = 1.08 s, <italic>SD</italic> = 0.30 s; <italic>t</italic><sub>(15)</sub> = 2.81, <italic>P</italic> = 0.03] or biological motion animations [<italic>M</italic> = 1.07 s, <italic>SD</italic> = 0.26 s; <italic>t</italic><sub>(15)</sub> = 3.19, <italic>P</italic> = 0.006]. There was no significant difference between the two motion conditions [<italic>t</italic><sub>(16)</sub> = 0.61, <italic>P</italic> = 0.55].</p></sec></sec><sec><title>fMRI results</title><sec><title>Visual motion localizer</title><p>Based on the random motion &#x0003e; luminance contrast, we defined the following ROIs in individual subjects (with average peak voxels): left IPL [&#x02212;48 &#x02212;40 21], right IPL [56 &#x02212;38 23], left SPL [&#x02212;29 &#x02212;49 62], right SPL [30 &#x02212;44 54], left MT/MST [&#x02212;49 &#x02212;72 4], and right MT/MST [49 &#x02212;67 5]. Based on the biological motion &#x0003e; random motion contrast, we defined a right and left STS ROI in individual subjects, with average peaks voxels [&#x02212;52 &#x02212;62 6] and [57 &#x02212;47 10], respectively.</p><p>A whole-brain analysis of the random motion &#x0003e; luminance contrast revealed activity in traditional visual motion areas including bilateral MT/MST, bilateral SPL along the IPS and bilateral IPL (Table <xref ref-type="table" rid="T3">3</xref>, Figure <xref ref-type="fig" rid="F2">2</xref>). The biological motion &#x0003e; random motion contrast revealed activity in the posterior aspect the RSTS (Table <xref ref-type="table" rid="T3">3</xref>, Figure <xref ref-type="fig" rid="F2">2</xref>). At a lower threshold of <italic>P</italic> &#x0003c; 0.1 (corrected for multiple comparisons), activity was also observed in the posterior aspect of the left STS.</p><table-wrap id="T3" position="float"><label>Table 3</label><caption><p><bold>Results of whole-brain random effects analyses <italic>P</italic> &#x0003c; 0.05 (corrected)</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1"><bold>Contrast group</bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold><italic>k</italic></bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold><italic>w</italic></bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold><italic>P</italic><sub>combo</sub></bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold>Voxel peak <italic>t</italic></bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold><italic>x</italic></bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold><italic>y</italic></bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold><italic>z</italic></bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold>Brain area (Brodmann area)</bold></th></tr></thead><tbody><tr><td align="left" colspan="9" rowspan="1"><bold>BIOLOGICAL MOTION &#x0003e; RANDOM MOTION</bold></td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">2308</td><td align="left" rowspan="1" colspan="1">8.82</td><td align="left" rowspan="1" colspan="1">0.0008</td><td align="left" rowspan="1" colspan="1">9.81</td><td align="left" rowspan="1" colspan="1">56</td><td align="left" rowspan="1" colspan="1">&#x02212;50</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">Right superior temporal gyrus (22)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">7.02</td><td align="left" rowspan="1" colspan="1">48</td><td align="left" rowspan="1" colspan="1">&#x02212;62</td><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">Right middle temporal gyrus (39)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">6.51</td><td align="left" rowspan="1" colspan="1">62</td><td align="left" rowspan="1" colspan="1">&#x02212;46</td><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">Right middle temporal gyrus (22)</td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>RANDOM MOTION &#x0003e; STATIC LUMINANCE</bold></td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">2202</td><td align="left" rowspan="1" colspan="1">8.82</td><td align="left" rowspan="1" colspan="1">0.0006</td><td align="left" rowspan="1" colspan="1">7.46</td><td align="left" rowspan="1" colspan="1">48</td><td align="left" rowspan="1" colspan="1">&#x02212;64</td><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">Right middle temporal gyrus (37)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">5.83</td><td align="left" rowspan="1" colspan="1">46</td><td align="left" rowspan="1" colspan="1">&#x02212;56</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">Right superior temporal gyrus (39)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">5.79</td><td align="left" rowspan="1" colspan="1">58</td><td align="left" rowspan="1" colspan="1">&#x02212;46</td><td align="left" rowspan="1" colspan="1">14</td><td align="left" rowspan="1" colspan="1">Right superior temporal gyrus (22)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">1714</td><td align="left" rowspan="1" colspan="1">7.12</td><td align="left" rowspan="1" colspan="1">0.0032</td><td align="left" rowspan="1" colspan="1">7.16</td><td align="left" rowspan="1" colspan="1">&#x02212;42</td><td align="left" rowspan="1" colspan="1">&#x02212;64</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">Left middle temporal gyrus (19/37)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">6.80</td><td align="left" rowspan="1" colspan="1">&#x02212;50</td><td align="left" rowspan="1" colspan="1">&#x02212;70</td><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">Left middle occipital gyrus (19)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">5.26</td><td align="left" rowspan="1" colspan="1">&#x02212;44</td><td align="left" rowspan="1" colspan="1">&#x02212;40</td><td align="left" rowspan="1" colspan="1">24</td><td align="left" rowspan="1" colspan="1">Left inferior parietal lobule (13)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">3670</td><td align="left" rowspan="1" colspan="1">7.32</td><td align="left" rowspan="1" colspan="1">0.0026</td><td align="left" rowspan="1" colspan="1">6.36</td><td align="left" rowspan="1" colspan="1">&#x02212;30</td><td align="left" rowspan="1" colspan="1">&#x02212;52</td><td align="left" rowspan="1" colspan="1">60</td><td align="left" rowspan="1" colspan="1">Left superior parietal lobule (7)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">5.79</td><td align="left" rowspan="1" colspan="1">&#x02212;22</td><td align="left" rowspan="1" colspan="1">&#x02212;86</td><td align="left" rowspan="1" colspan="1">20</td><td align="left" rowspan="1" colspan="1">Left cuneus (18)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">5.73</td><td align="left" rowspan="1" colspan="1">26</td><td align="left" rowspan="1" colspan="1">&#x02212;78</td><td align="left" rowspan="1" colspan="1">38</td><td align="left" rowspan="1" colspan="1">Right precuneus (19/7)</td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>HIGH MOTION PASSAGES &#x0003e; LOW MOTION PASSAGES</bold></td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">361</td><td align="left" rowspan="1" colspan="1">8.82</td><td align="left" rowspan="1" colspan="1">0.0006</td><td align="left" rowspan="1" colspan="1">7.82</td><td align="left" rowspan="1" colspan="1">0</td><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">38</td><td align="left" rowspan="1" colspan="1">Cingulate gyrus</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">284</td><td align="left" rowspan="1" colspan="1">8.82</td><td align="left" rowspan="1" colspan="1">0.0006</td><td align="left" rowspan="1" colspan="1">7.80</td><td align="left" rowspan="1" colspan="1">&#x02212;26</td><td align="left" rowspan="1" colspan="1">32</td><td align="left" rowspan="1" colspan="1">&#x02212;16</td><td align="left" rowspan="1" colspan="1">Left middle frontal gyrus (11)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">785</td><td align="left" rowspan="1" colspan="1">7.44</td><td align="left" rowspan="1" colspan="1">0.0028</td><td align="left" rowspan="1" colspan="1">6.81</td><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">&#x02212;40</td><td align="left" rowspan="1" colspan="1">44</td><td align="left" rowspan="1" colspan="1">Right cingulate gyrus (31)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">6.38</td><td align="left" rowspan="1" colspan="1">&#x02212;4</td><td align="left" rowspan="1" colspan="1">&#x02212;32</td><td align="left" rowspan="1" colspan="1">46</td><td align="left" rowspan="1" colspan="1">Left paracentral lobule (31)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">3.46</td><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">&#x02212;20</td><td align="left" rowspan="1" colspan="1">48</td><td align="left" rowspan="1" colspan="1">Right paracentral lobule (31)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">258</td><td align="left" rowspan="1" colspan="1">7.03</td><td align="left" rowspan="1" colspan="1">0.0036</td><td align="left" rowspan="1" colspan="1">6.74</td><td align="left" rowspan="1" colspan="1">24</td><td align="left" rowspan="1" colspan="1">30</td><td align="left" rowspan="1" colspan="1">&#x02212;18</td><td align="left" rowspan="1" colspan="1">Right middle frontal gyrus (11)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">3.30</td><td align="left" rowspan="1" colspan="1">40</td><td align="left" rowspan="1" colspan="1">32</td><td align="left" rowspan="1" colspan="1">&#x02212;20</td><td align="left" rowspan="1" colspan="1">Right inferior frontal gyrus (47)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">3.05</td><td align="left" rowspan="1" colspan="1">38</td><td align="left" rowspan="1" colspan="1">22</td><td align="left" rowspan="1" colspan="1">&#x02212;20</td><td align="left" rowspan="1" colspan="1">Right inferior frontal gyrus (47)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">977</td><td align="left" rowspan="1" colspan="1">7.03</td><td align="left" rowspan="1" colspan="1">0.0036</td><td align="left" rowspan="1" colspan="1">6.41</td><td align="left" rowspan="1" colspan="1">28</td><td align="left" rowspan="1" colspan="1">64</td><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">Right superior frontal gyrus (10)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">6.38</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">44</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">Right middle frontal gyrus</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">4.22</td><td align="left" rowspan="1" colspan="1">36</td><td align="left" rowspan="1" colspan="1">34</td><td align="left" rowspan="1" colspan="1">44</td><td align="left" rowspan="1" colspan="1">Right middle frontal gyrus (8/9)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">317</td><td align="left" rowspan="1" colspan="1">5.63</td><td align="left" rowspan="1" colspan="1">0.0148</td><td align="left" rowspan="1" colspan="1">6.17</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">&#x02212;34</td><td align="left" rowspan="1" colspan="1">&#x02212;22</td><td align="left" rowspan="1" colspan="1">Right inferior temporal gyrus (20)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">3.43</td><td align="left" rowspan="1" colspan="1">62</td><td align="left" rowspan="1" colspan="1">&#x02212;40</td><td align="left" rowspan="1" colspan="1">&#x02212;16</td><td align="left" rowspan="1" colspan="1">Right middle temporal gyrus (21)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">773</td><td align="left" rowspan="1" colspan="1">6.15</td><td align="left" rowspan="1" colspan="1">0.0086</td><td align="left" rowspan="1" colspan="1">5.98</td><td align="left" rowspan="1" colspan="1">&#x02212;60</td><td align="left" rowspan="1" colspan="1">&#x02212;36</td><td align="left" rowspan="1" colspan="1">46</td><td align="left" rowspan="1" colspan="1">Left supramarginal gyrus (40)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">4.88</td><td align="left" rowspan="1" colspan="1">&#x02212;66</td><td align="left" rowspan="1" colspan="1">&#x02212;26</td><td align="left" rowspan="1" colspan="1">26</td><td align="left" rowspan="1" colspan="1">Left supramarginal gyrus (40)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">4.83</td><td align="left" rowspan="1" colspan="1">&#x02212;64</td><td align="left" rowspan="1" colspan="1">&#x02212;34</td><td align="left" rowspan="1" colspan="1">28</td><td align="left" rowspan="1" colspan="1">Left supramarginal gyrus (40)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">350</td><td align="left" rowspan="1" colspan="1">4.95</td><td align="left" rowspan="1" colspan="1">0.0274</td><td align="left" rowspan="1" colspan="1">5.64</td><td align="left" rowspan="1" colspan="1">&#x02212;8</td><td align="left" rowspan="1" colspan="1">&#x02212;66</td><td align="left" rowspan="1" colspan="1">62</td><td align="left" rowspan="1" colspan="1">Left precuneus (7)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">300</td><td align="left" rowspan="1" colspan="1">4.77</td><td align="left" rowspan="1" colspan="1">0.0322</td><td align="left" rowspan="1" colspan="1">5.63</td><td align="left" rowspan="1" colspan="1">&#x02212;30</td><td align="left" rowspan="1" colspan="1">&#x02212;40</td><td align="left" rowspan="1" colspan="1">&#x02212;18</td><td align="left" rowspan="1" colspan="1">Left fusiform gyrus (20)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">5.26</td><td align="left" rowspan="1" colspan="1">&#x02212;30</td><td align="left" rowspan="1" colspan="1">&#x02212;34</td><td align="left" rowspan="1" colspan="1">&#x02212;26</td><td align="left" rowspan="1" colspan="1">Left fusiform gyrus (20)</td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>HIGH MOTION NOUNS &#x0003e; LOW MOTION NOUNS</bold></td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">378</td><td align="left" rowspan="1" colspan="1">6.95</td><td align="left" rowspan="1" colspan="1">0.0042</td><td align="left" rowspan="1" colspan="1">6.59</td><td align="left" rowspan="1" colspan="1">52</td><td align="left" rowspan="1" colspan="1">&#x02212;62</td><td align="left" rowspan="1" colspan="1">32</td><td align="left" rowspan="1" colspan="1">Right angular gyrus (39)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">5.10</td><td align="left" rowspan="1" colspan="1">46</td><td align="left" rowspan="1" colspan="1">&#x02212;64</td><td align="left" rowspan="1" colspan="1">26</td><td align="left" rowspan="1" colspan="1">Right middle temporal gyrus (39)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">16</td><td align="left" rowspan="1" colspan="1">4.53</td><td align="left" rowspan="1" colspan="1">0.0424</td><td align="left" rowspan="1" colspan="1">5.71</td><td align="left" rowspan="1" colspan="1">&#x02212;56</td><td align="left" rowspan="1" colspan="1">&#x02212;16</td><td align="left" rowspan="1" colspan="1">&#x02212;32</td><td align="left" rowspan="1" colspan="1">Left fusiform gyrus (20)</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">549</td><td align="left" rowspan="1" colspan="1">5.06</td><td align="left" rowspan="1" colspan="1">0.0256</td><td align="left" rowspan="1" colspan="1">5.62</td><td align="left" rowspan="1" colspan="1">&#x02212;46</td><td align="left" rowspan="1" colspan="1">&#x02212;60</td><td align="left" rowspan="1" colspan="1">26</td><td align="left" rowspan="1" colspan="1">Left superior temporal gyrus (39)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">4.56</td><td align="left" rowspan="1" colspan="1">&#x02212;52</td><td align="left" rowspan="1" colspan="1">&#x02212;62</td><td align="left" rowspan="1" colspan="1">20</td><td align="left" rowspan="1" colspan="1">Left superior temporal gyrus (39)</td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>HIGH MOTION VERBS &#x0003e; LOW MOTION VERBS</bold></td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">237</td><td align="left" rowspan="1" colspan="1">5.09</td><td align="left" rowspan="1" colspan="1">0.0244</td><td align="left" rowspan="1" colspan="1">5.98</td><td align="left" rowspan="1" colspan="1">&#x02212;36</td><td align="left" rowspan="1" colspan="1">&#x02212;86</td><td align="left" rowspan="1" colspan="1">32</td><td align="left" rowspan="1" colspan="1">Left superior occipital gyrus (19)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">4.14</td><td align="left" rowspan="1" colspan="1">&#x02212;50</td><td align="left" rowspan="1" colspan="1">&#x02212;74</td><td align="left" rowspan="1" colspan="1">14</td><td align="left" rowspan="1" colspan="1">Left angular gyrus (19/39)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">3.79</td><td align="left" rowspan="1" colspan="1">&#x02212;44</td><td align="left" rowspan="1" colspan="1">&#x02212;82</td><td align="left" rowspan="1" colspan="1">24</td><td align="left" rowspan="1" colspan="1">Left superior occipital gyrus (19)</td></tr></tbody></table></table-wrap><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Results of the whole brain analyses for Motion passages &#x0003e; Non-motion passages (Red), Biological motion &#x0003e; Static luminance (Green), and Random motion &#x0003e; Static luminance (Purple).</bold> Results are thresholded at <italic>p</italic> &#x0003c; 0.05 (corrected for multiple comparisons) and displayed on a normalized template brain.</p></caption><graphic xlink:href="fpsyg-04-00537-g0002"/></fig></sec><sec><title>Do visual motion brain regions respond to motion words?</title><p>We first asked whether visual motion areas (bilateral MT/MST, IPL, SPL, and STS) are sensitive to motion features of words. High motion nouns were compared to low motion nouns and high motion verbs to low motion verbs. (Verbs and nouns were compared separately because previous work has shown higher responses to verbs than nouns in nearby regions of the temporal and parietal cortex.) None of the visual motion ROIs in either temporal or parietal cortices showed significantly higher activity for high-motion verbs than low-motion verbs, or for high motion nouns than low motion nouns on average over the entire block (<italic>t</italic>'s &#x0003c; 2, <italic>P</italic>'<italic>s</italic> &#x0003e; 0.05; See Figure <xref ref-type="fig" rid="F1">1B</xref>, Table <xref ref-type="table" rid="T4">4</xref> for details).</p><table-wrap id="T4" position="float"><label>Table 4</label><caption><p><bold>Differences between high and low motion nouns and verbs in the visual motion regions of interest (not corrected for multiple comparisons)</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="left" valign="top" rowspan="1" colspan="1"><bold>High &#x0003e; Low motion nouns</bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold>High &#x0003e; Low motion verbs</bold></th><th align="left" valign="top" rowspan="1" colspan="1"><bold>High &#x0003e; Low motion passages</bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">LIPL</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(11)</sub> = &#x02212;0.38, <italic>P</italic> = 0.71</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(11)</sub> = 0.21, <italic>P</italic> = 0.84</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(11)</sub> = 0.02, <italic>P</italic> = 0.98</td></tr><tr><td align="left" rowspan="1" colspan="1">RIPL</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(12)</sub> = 0.24, <italic>P</italic> = 0.81</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(12)</sub> = 1.80, <italic>P</italic> = 0.10</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(11)</sub> = 0.001, <italic>P</italic> = 0.99</td></tr><tr><td align="left" rowspan="1" colspan="1">LSPL</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(11)</sub> = 1.23, <italic>P</italic> = 0.25</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(11)</sub> = &#x02212;0.21, <italic>P</italic> = 0.83</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(11)</sub> = 1.66, <italic>P</italic> = 0.12</td></tr><tr><td align="left" rowspan="1" colspan="1">RSPL</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(12)</sub> = 1.04, <italic>P</italic> = 0.32</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(12)</sub> = 0.94, <italic>P</italic> = 0.37</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(11)</sub> = 2.43, <italic>P</italic> = 0.03<sup>*</sup></td></tr><tr><td align="left" rowspan="1" colspan="1">LMT</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(14)</sub> = 0.15, <italic>P</italic> = 0.88</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(14)</sub> = 0.17, <italic>P</italic> = 0.86</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(13)</sub> = 0.95, <italic>P</italic> = 0.36</td></tr><tr><td align="left" rowspan="1" colspan="1">RMT</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(14)</sub> = &#x02212;0.30, <italic>P</italic> = 0.77</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(14)</sub> = 1.84, <italic>P</italic> = 0.09</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(13)</sub> = 0.31, <italic>P</italic> = 0.76</td></tr><tr><td align="left" rowspan="1" colspan="1">LSTS</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(13)</sub> = 1.33, <italic>P</italic> = 0.21</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(13)</sub> = &#x02212;0.35, <italic>P</italic> = 0.73</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(12)</sub> = &#x02212;0.38, <italic>P</italic> = 0.71</td></tr><tr><td align="left" rowspan="1" colspan="1">RSTS</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(13)</sub> = &#x02212;1.35, <italic>P</italic> = 0.20</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(13)</sub> = 0.17, <italic>P</italic> = 0.87</td><td align="left" rowspan="1" colspan="1"><italic>t</italic><sub>(13)</sub> = 1.13, <italic>P</italic> = 0.28</td></tr></tbody></table><table-wrap-foot><p><italic>Positive t-values indicate the mean for the high motion words was greater than that of the low motion words. Asterisks indicate a significant difference between the high and low motion conditions (P &#x0003c; 0.05)</italic>.</p></table-wrap-foot></table-wrap><p>In whole-brain analysis, high motion verbs lead to higher BOLD response than low motion verbs in the left superior occipital gyrus (&#x02212;36, &#x02212;86, 32, BA 19) and the posterior aspect of the left angular gyrus (&#x02212;50, &#x02212;74, 14, BA 39). High motion nouns compared to low motion nouns lead to higher response in the right middle temporal gyrus (46, &#x02212;64, 26, BA 39), the right angular gyrus (52, &#x02212;62, 32, BA 39), the left fusiform gyrus (&#x02212;46, &#x02212;60, 26, BA 20), and the left superior temporal gyrus (&#x02212;52, &#x02212;62, 20, BA 39). High motion noun and high motion verb responses did not overlap with each other, or with random motion or the biological motion contrasts from the visual motion localizer.</p></sec><sec><title>Do visual motion brain regions respond to motion passages?</title><p>The right SPL showed a small, but reliable increase in activity for high motion passages (<italic>PSC</italic> = &#x02212;0.15) as compared to low motion passages [<italic>PSC</italic> = &#x02212;0.17; <italic>t</italic><sub>(11)</sub> = 2.43, <italic>P</italic> = 0.03]. In the left SPL, the effect was in the same direction (higher for high motion sentences), but it was not significant [<italic>t</italic><sub>(11)</sub> = 1.66, <italic>P</italic> = 0.12].</p><p>There were no differences between the high and low motion passages in any of the other motion-responsive regions [right IPL <italic>t</italic><sub>(11)</sub> = 0.001, <italic>P</italic> = 0.99; left IPL <italic>t</italic><sub>(11)</sub> = 0.02, <italic>P</italic> = 0.98; right MT/MST <italic>t</italic><sub>(13)</sub> = 0.31, <italic>P</italic> = 0.76: left MT/MST <italic>t</italic><sub>(13)</sub> = 0.95, <italic>P</italic> = 0.36; right STS <italic>t</italic><sub>(13)</sub> = 1.13, <italic>P</italic> = 0.28: or left STS <italic>t</italic><sub>(12)</sub> = 0.38, <italic>P</italic> = 0.71] (see Figure <xref ref-type="fig" rid="F1">1B</xref>). Whole-brain analysis revealed higher signal for the high motion passages than the low motion passages in several regions in the temporal and parietal lobes (see Table <xref ref-type="table" rid="T3">3</xref> for full list of regions). However, none of these areas of activation overlapped with responses to random or biological motion, or with responses to high motion words (see Figure <xref ref-type="fig" rid="F2">2</xref>).</p><p>One concern is that we might have missed possible responses to motion language by averaging activity over an entire block. Responses to high motion language could either attenuate over the duration of the block due to repetition suppression or increase due to build up. We therefore looked separately at responses to high and low motion language during the first and last two TRs of the block from each task. Note that the results of these analyses should be viewed as exploratory since there are a number of statistical comparisons and the analyses were not planned at the outset of the study. None of the visual motion ROIs showed a significant effect for both high &#x0003e; low motion nouns and high &#x0003e; low motion verbs in either the first two TRs or the last two TRs (Figure <xref ref-type="fig" rid="F3">3</xref>). Only the left SPL, which showed a trend in the block averaging analysis, also showed higher activity for the high motion than low motion sentences during the last two TR's of the block [<italic>t</italic><sub>(11)</sub> = 2.44, <italic>P</italic> = 0.03; Figure <xref ref-type="fig" rid="F3">3</xref>].</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Percent signal change over the time in the visual motion ROIs.</bold> The first and last two TRs are marked. <bold>(A)</bold> Percent signal change of the high and low motion nouns and verbs. Analyses were averaged from TR 6 to18. <bold>(B)</bold> Percent signal change of the high and low motion passages. Analyses were averaged from TR 4 to16. Asterisks indicate a significant difference between the high and low motion conditions (<italic>P</italic> &#x0003c; 0.05).</p></caption><graphic xlink:href="fpsyg-04-00537-g0003"/></fig></sec><sec><title>Does the pLMTG motion-verb area respond to perceptual visual motion?</title><p>As in previous studies, we observed a left middle temporal gyrus area that responds more to motion verbs than to object nouns (animals or plants; <italic>P</italic> &#x0003c; 0.05, corrected; Perani et al., <xref ref-type="bibr" rid="B36">1999</xref>; Kable et al., <xref ref-type="bibr" rid="B23">2002</xref>, <xref ref-type="bibr" rid="B22">2005</xref>; Bedny et al., <xref ref-type="bibr" rid="B4">2008</xref>). We defined the pLMTG ROI in individual subjects using the motion verbs &#x0003e; animals contrast, with average peak voxels [&#x02212;52 &#x02212;51 8]. The peak voxels from the whole brain analysis of this contrast were [&#x02212;62 &#x02212;52 8, BA22]. This pLMTG region did not respond to actual random [<italic>t</italic><sub>(12)</sub> = 0.24, <italic>P</italic> = 0.81, relative to static luminance] or biological motion [<italic>t</italic><sub>(12)</sub> = 0.15, <italic>P</italic> = 0.89, relative to random motion]. The pLMTG region also responded equally to high motion verbs and low motion verbs [<italic>t</italic><sub>(15)</sub> = 0.98, <italic>P</italic> = 0.33], high motion nouns and low motion nouns [<italic>t</italic><sub>(15)</sub> = &#x02212;1.04, <italic>P</italic> = 0.32], and high motion passages and low motion passages [<italic>t</italic><sub>(14)</sub> = &#x02212;1.56, <italic>P</italic> = 0.14; Figure <xref ref-type="fig" rid="F4">4</xref>].</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Neural response in the pLMTG ROI to biological motion, random motion, static luminance, motion and non-motion passages, and high and low motion words</bold>. Error bars represent a standard error of the mean.</p></caption><graphic xlink:href="fpsyg-04-00537-g0004"/></fig></sec></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>The results of this study yield three main findings. First, we find that temporal lobe responses during comprehension of motion words and motion perception are distinct. Visual motion areas in the temporal cortex (i.e., MT/MST and the RSTS) show no response to single words with motion features or to passages that contain action verbs (see also Kable et al., <xref ref-type="bibr" rid="B23">2002</xref>, <xref ref-type="bibr" rid="B22">2005</xref>; Bedny et al., <xref ref-type="bibr" rid="B4">2008</xref>). Conversely, a lateral temporal area that responds to action verbs (pLMTG) is insensitive to actual visual motion and does not distinguish between high and low motion words, or high and low motion passages. Second, parietal lobe areas engaged during visual motion perception are distinct from parietal regions that respond to motion words. Third, we find that passages are more effective than words at activating higher-order perceptual regions in the parietal lobe. Passages, but not words, activated the right SPL visual motion area. Since the plausibility task was easier for the high motion passages (reflected in faster reaction times), it seems unlikely that the SPL motion response reflects general processing difficulty or plausibility (despite the lower plausibility ratings for the motion passages). Notably the SPL response to language is small relative to neural responses to visual motion (<italic>PSC</italic> = 0.02), consistent with the possibility that it reflects spontaneous imagery. In sum, responses to linguistic depictions of motion are more likely for passages than for single words, and more likely in polymodal parietal areas than in modality-specific temporal areas. On the whole, however, neural responses to visually perceived motion and to linguistically described motion were largely distinct.</p><p>What do our findings reveal about the relationship of language and sensory perception? Consistent with many prior studies we find that language can influence activity in perceptual circuits (Meteyard et al., <xref ref-type="bibr" rid="B33">2008</xref>; McCullough et al., <xref ref-type="bibr" rid="B32">2012</xref>). Such observations argue against models of language and perception that assume modularity (Fodor, <xref ref-type="bibr" rid="B13">1983</xref>). However, we also find that perceptual responses to language constitute a tiny fraction of the neural operations that are involved in language comprehension. Responses to language in the perceptual circuits are also distinct from responses during visual perception itself. Language effects are more pronounced in higher-order polymodal sensory areas than in early sensory areas. Even in these secondary perceptual regions, responses to language are weak relative to neural responses during vision.</p><p>By contrast to the current findings, some prior studies have reported responses to motion sentences in MT/MST and in the RSTS (Saygin et al., <xref ref-type="bibr" rid="B42">2009</xref>; Deen and McCarthy, <xref ref-type="bibr" rid="B10">2010</xref>; Humphreys et al., <xref ref-type="bibr" rid="B21">2013</xref>). Why do some studies observe such effects while others (e.g., Wallentin et al., <xref ref-type="bibr" rid="B50">2005</xref>) including the current study, fail to do so? We suggest that these differences may stem from the degree to which the stimuli promote spontaneous imagery. Just as imagery itself is a heterogeneous phenomenon (Kosslyn et al., <xref ref-type="bibr" rid="B24">2001</xref>), so too perceptual responses during language processing vary depending on the details of the linguistic stimuli and task.</p><p>We hypothesize that linguistic stimuli that elicit specific and highly vivid visual images are required to activating early visual areas. In the present study neither the word nor the passage stimuli were likely to elicit such imagery. It seems unlikely that we did not pick the correct words to elicit high visual motion as our high motion verbs consisted of words describing manner of motion (ex: &#x0201c;to roll&#x0201d;). It is possible that words alone, out of context, are not enough to spontaneously elicit visual imagery even the passage stimuli in our study were not vivid enough to activate perceptual regions. The sequences of four sentences in the current study did not describe a single motion event, but rather a series of four different events (e.g., &#x0201c;The juror kicked a stool. Then a criminal jabbed a Dalmatian. Then a kid shut a door. Then a spaniel bounced a toy.&#x0201d;). By contrast, some previous studies used more extended, more coherent and more descriptive passages (e.g., Deen and McCarthy, <xref ref-type="bibr" rid="B10">2010</xref>). Consistent with the possibility that long passages are better at eliciting imagery, a recent behavioral study found that effects of motion language on behavioral measures of motion perception increase with story length. Visual motion aftereffects grew as participants heard more sentences in a story, with no effects on perception for the first few sentences. Furthermore, effects of language on motion perception were higher for individuals who were better at generating vivid visual imagery (Dils and Boroditsky, <xref ref-type="bibr" rid="B11">2010</xref>). Together, these results suggest that language is more likely to affect the visual system when the linguistic stimuli are sufficiently vivid to elicit spontaneous imagery.</p><p>Prior work also suggests that the emotional and motivational relevance of stimuli influences the likelihood of vivid mental imagery. One study found that MT/MST responds to sentences that describe motion toward the reader (e.g., &#x0201c;The car drives toward you&#x0201d;), but not to the same motion away from the reader (&#x0201c;The car drives away from you&#x0201d;; Rueschemeyer et al., <xref ref-type="bibr" rid="B39">2010</xref>). Sentences describing motion toward the self also activated midline structures involved in motivational and emotional processing, suggesting that they had greater emotional salience. Descriptions of motion toward the self may encourage participants to anticipate possible visual motion events. For example, a sentence such as &#x0201c;Look out, a bicycle is heading right for you!&#x0201d; might prime visual motion and object perception circuits. Further research is necessary to test this claim.</p><p>There are also a number of ways in which task differences could influence whether linguistic stimuli activate visual motion regions. On the one hand, one might worry that some tasks could favor superficial encoding and thus artificially suppress activation of visual motion areas by language. We think that this explanation is unlikely, at least for the current tasks. Semantic similarity and plausibility judgments focus participants' attention on the meaning of the words and sentences. We have found that semantic similarity ratings of the kind collected here are highly systematic across participants, but are not well-explained by co-occurrence frequencies in corpus data (Koster-Hale et al., submitted). More generally, there is considerable evidence that word meanings are retrieved automatically, even when the task requires that participants ignore word meanings (e.g., the Stroop task; Stroop, <xref ref-type="bibr" rid="B44">1935</xref>). Similarly, assessing sentence plausibility in the current task required not only retrieval of word meanings but integration of lexical and syntactic information to generate compositional meaning. Rather than being highly artificial, we suggest that the current tasks require deep semantic encoding and tap into processes typically involved in comprehension of words and sentences. Deep semantic encoding does not appear to be sufficient to activate perceptual circuits.</p><p>On the other hand, as with stimulus differences, some tasks may be more likely to activate perceptual areas because they are more likely to evoke vivid imagery. For example, spontaneous imagery might occur when linguistic information is relevant to visual perception, or when language elicits recall of specific episodic experiences, such as when hearing the sentence &#x0201c;Remember the way her dress swayed in the wind as she stood by the window?&#x0201d; We suggest that the extensive behavioral and neuroimaging literature on visual imagery is likely to provide a fruitful hypothesis space for studying interactions between language and perception (Kreiman et al., <xref ref-type="bibr" rid="B27">2000</xref>; Kosslyn et al., <xref ref-type="bibr" rid="B24">2001</xref>; Cui et al., <xref ref-type="bibr" rid="B8">2007</xref>).</p><p>An interesting third possibility is that linguistic stimuli evoke responses in early visual motion areas only when participants are simultaneously engaged in perception of visual motion. Consistent with this idea, the two previous studies that observed responses to language in MT/MST involved simultaneously hearing motion language and seeing moving visual stimuli. Saygin and colleagues measured responses to motion sentences while participants were viewing videos of speakers (Saygin et al., <xref ref-type="bibr" rid="B42">2009</xref>). Similarly, McCullough et al. reported responses in MT/MST to motion sentences while participants viewed videos of American Sign Language (McCullough et al., <xref ref-type="bibr" rid="B32">2012</xref>). Parallel to these neuroimaging studies, a number of behavioral experiments have shown effects of language on visual perception in simultaneous visual and linguistic tasks (Meteyard et al., <xref ref-type="bibr" rid="B33">2008</xref>). Together these findings suggest that linguistic descriptions of motion can modify ongoing MT/MST responses to visually perceived motion. A similar pattern has been observed with auditory motion: motion sounds by themselves do not drive responses to MT/MST, but they do modify MT/MST responses to visual motion (Sadaghiani et al., <xref ref-type="bibr" rid="B40">2009</xref>).</p><p>In summary, the present data suggest that temporal and parietal responses to language and perception are largely non-overlapping. When language does evoke activity in perceptual areas, (1) rich linguistic stimuli such as passages are more likely to do so than single words and (2) effects are more likely to occur in higher-order polymodal areas than early visual areas.</p><sec><title>Implications for the relationship of perception and language</title><p>According to some versions of the embodiment hypothesis, concepts are solely comprised of perceptual schemas (Barsalou, <xref ref-type="bibr" rid="B2">1999</xref>; Pulvermuller, <xref ref-type="bibr" rid="B38">1999</xref>). For example, the concept of a phone consists of visual images of a phone shape and color, the memory of a phone sound as well as the tactile and motor memory of holding a phone (Allport, <xref ref-type="bibr" rid="B62">1985</xref>). In this framework understanding words and sentences that describe motion depends on simulation of prior experiences of observing motion within the same modality-specific cortical systems that originally encoded the experience (Barsalou, <xref ref-type="bibr" rid="B2">1999</xref>; Pulvermuller, <xref ref-type="bibr" rid="B38">1999</xref>; Gallese and Lakoff, <xref ref-type="bibr" rid="B14">2005</xref>; Speer et al., <xref ref-type="bibr" rid="B43">2009</xref>). This view predicts that comprehension of motion words (e.g., &#x0201c;to skip&#x0201d;) and motion sentences (e.g., &#x0201c;The girl skipped down the hill.&#x0201d;) should necessarily be accompanied by activity in visual motion circuits (Barsalou, <xref ref-type="bibr" rid="B2">1999</xref>; Pulvermuller, <xref ref-type="bibr" rid="B38">1999</xref>). Contrary to this prediction, participants in our experiment made semantic similarity judgments about motion words and plausibility judgments about motion sentences without activating most visual motion areas. Moreover, a review of the literature suggests that responses to motion language in perceptual regions are small, variable, and clearly distinct from responses to actual visual motion. The neuroimaging evidence on the relationship of motion language and visual motion is thus inconsistent with a strong embodiment position.</p><p>Instead, neuroimaging findings are more consistent with the view that language and vision are distinct systems that interact during online processing. According to this account, language comprehension can occur independent of perceptual systems. Perceptual responses to linguistic stimuli reflect top-down effects of language on perception. This view makes several interesting predictions. First, within this framework it should be possible to observe effects of language on higher-order perceptual areas without effects in low-level perception areas, but not vice versa. This view also predicts that responses to language in perceptual circuits generally follow responses in language areas. For example, we expect that any response to language in visual motion areas will follow responses in the pLMTG. Impairment of processing in the pLMTG by brain damage or TMS should also impair downstream processing in perceptual areas, but not vice versa. Third, this view suggests that interactions between perception and language are not privileged. Rather they reflect the more general phenomenon whereby linguistic and non-linguistic information interact rapidly during online comprehension (e.g., Trueswell et al., <xref ref-type="bibr" rid="B64">1994</xref>; McRae et al., <xref ref-type="bibr" rid="B63">1998</xref>; Altmann, <xref ref-type="bibr" rid="B65">1999</xref>).</p><p>In this paper we explore the relationship between language and perception by asking whether the same brain regions support these cognitive processes. What might be the limitations of such an approach? One possible objection is that neural and cognitive levels of analysis are entirely independent. On this view neural evidence cannot in principle speak to cognitive questions. A full discussion of this philosophical question is beyond the scope of the present article. We will merely point out that neuroscience has already provided considerable insights into the computations of the mind. Given the highly systematic relationship between neural function and cognition, it seems arbitrary to ignore biological evidence when considering issues of representation. A second version of this objection is particular to neuroimaging. The resolution of neuroimaging allows us to distinguish between neural areas and not between individual neurons. If the same area is discovered to support two different functions (e.g., syntax and semantics), it always remains possible that these functions would be separable at a higher level of resolution. However, when, as in the present case, despite the low spatial resolution of neuroimaging we find that two cognitive functions are supported by two different neural systems, it is not possible that they would appear to be supported by the same neural mechanism given higher spatial resolution. Despite these considerations it is important to point out that neuroimaging is only one kind of evidence for studying the relationship of language and perception. It is absolutely crucial to corroborate neuroimaging findings with complimentary techniques such as behavioral measures, brain stimulation, and temporally sensitive metrics (MEG, EEG).</p></sec><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ref-list><title>References</title><ref id="B62"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Allport</surname><given-names>D. A.</given-names></name></person-group> (<year>1985</year>). <article-title>Distributed memory, modular subsystems and dysphasia</article-title>, in <source>Current perspectives in dysphasia</source> eds <person-group person-group-type="editor"><name><surname>Newman</surname><given-names>S. K.</given-names></name><name><surname>Epstein</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Edinburgh</publisher-loc>: <publisher-name>Churchill Livingstone</publisher-name>), <fpage>207</fpage>&#x02013;<lpage>244</lpage></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altmann</surname><given-names>G.</given-names></name></person-group> (<year>1999</year>). <article-title>Thematic role assignment in context</article-title>. <source>J. Mem. Lang</source>. <volume>41</volume>, <fpage>124</fpage>&#x02013;<lpage>145</lpage>
<pub-id pub-id-type="doi">10.1006/jmla.1999.2640</pub-id></mixed-citation></ref><ref id="B1"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Baayen</surname><given-names>R. H.</given-names></name><name><surname>Piepenbrock</surname><given-names>R.</given-names></name><name><surname>Gulikers</surname><given-names>L.</given-names></name></person-group> (<year>1995</year>). <source>The CELEX Lexical Database (version release 2)</source> [CD-ROM]. <publisher-loc>Philadelphia, PA</publisher-loc>: <publisher-name>Linguistic Data Consortium, University of Pennsylvania</publisher-name></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>C. I.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Wald</surname><given-names>L. L.</given-names></name><name><surname>Kwong</surname><given-names>K. K.</given-names></name><name><surname>Benner</surname><given-names>T.</given-names></name><name><surname>Kanwisher</surname><given-names>N.</given-names></name></person-group> (<year>2007</year>). <article-title>Visual word processing and experiential origins of functional selectivity in human extrastriate cortex</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>104</volume>, <fpage>9087</fpage>&#x02013;<lpage>9092</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.0703300104</pub-id><?supplied-pmid 17502592?><pub-id pub-id-type="pmid">17502592</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barsalou</surname><given-names>L. W.</given-names></name></person-group> (<year>1999</year>). <article-title>Perceptual symbol systems</article-title>. <source>Behav. Brain Sci</source>. <volume>22</volume>, <fpage>577</fpage>&#x02013;<lpage>609</lpage>
<?supplied-pmid 11301525?><pub-id pub-id-type="pmid">11301525</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battelli</surname><given-names>L.</given-names></name><name><surname>Cavanagh</surname><given-names>P.</given-names></name><name><surname>Thornton</surname><given-names>I. M.</given-names></name></person-group> (<year>2003</year>). <article-title>Perception of biological motion in parietal patients</article-title>. <source>Neuropsychologia</source>
<volume>41</volume>, <fpage>1808</fpage>&#x02013;<lpage>1816</lpage>
<pub-id pub-id-type="doi">10.1016/S0028-3932(03)00182-9</pub-id><?supplied-pmid 14527544?><pub-id pub-id-type="pmid">14527544</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bedny</surname><given-names>M.</given-names></name><name><surname>Caramazza</surname><given-names>A.</given-names></name><name><surname>Grossman</surname><given-names>E.</given-names></name><name><surname>Pascual-Leone</surname><given-names>A.</given-names></name><name><surname>Saxe</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>Concepts are more than percepts: the case of action verbs</article-title>. <source>J. Neurosci</source>. <volume>28</volume>, <fpage>11347</fpage>&#x02013;<lpage>11353</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3039-08.2008</pub-id><?supplied-pmid 18971476?><pub-id pub-id-type="pmid">18971476</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>R. T.</given-names></name><name><surname>Bradley</surname><given-names>D. C.</given-names></name></person-group> (<year>2005</year>). <article-title>Structure and function of visual area MT</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>28</volume>, <fpage>157</fpage>&#x02013;<lpage>189</lpage>
<pub-id pub-id-type="doi">10.1146/annurev.neuro.26.041002.131052</pub-id><?supplied-pmid 16022593?><pub-id pub-id-type="pmid">16022593</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bremmer</surname><given-names>F.</given-names></name><name><surname>Schlack</surname><given-names>A.</given-names></name><name><surname>Shah</surname><given-names>N. J.</given-names></name><name><surname>Zafiris</surname><given-names>O.</given-names></name><name><surname>Kubischik</surname><given-names>M.</given-names></name><name><surname>Hoffmann</surname><given-names>K.-P.</given-names></name><etal/></person-group> (<year>2001</year>). <article-title>Polymodal motion processing in posterior parietal and premotor cortex: a human fMRI study strongly implies equivalencies between humans and monkeys</article-title>. <source>Neuron</source>
<volume>29</volume>, <fpage>287</fpage>&#x02013;<lpage>296</lpage>
<pub-id pub-id-type="doi">10.1016/S0896-6273(01)00198-2</pub-id><?supplied-pmid 11182099?><pub-id pub-id-type="pmid">11182099</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Catani</surname><given-names>M.</given-names></name><name><surname>Jones</surname><given-names>D. K.</given-names></name></person-group> (<year>2005</year>). <article-title>Perisylvian language networks of the human brain</article-title>. <source>Ann. Neurol</source>. <volume>57</volume>, <fpage>8</fpage>&#x02013;<lpage>16</lpage>
<pub-id pub-id-type="doi">10.1002/ana.20319</pub-id><?supplied-pmid 15597383?><pub-id pub-id-type="pmid">15597383</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname><given-names>X.</given-names></name><name><surname>Jeter</surname><given-names>C. B.</given-names></name><name><surname>Yang</surname><given-names>D.</given-names></name><name><surname>Montague</surname><given-names>P. R.</given-names></name><name><surname>Eagleman</surname><given-names>D. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Vividness of mental imagery: individual variability can be measured objectively</article-title>. <source>Vision Res</source>. <volume>47</volume>, <fpage>474</fpage>&#x02013;<lpage>478</lpage>
<pub-id pub-id-type="doi">10.1016/j.visres.2006.11.013</pub-id><?supplied-pmid 17239915?><pub-id pub-id-type="pmid">17239915</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damasio</surname><given-names>H.</given-names></name><name><surname>Grabowski</surname><given-names>T. J.</given-names></name><name><surname>Tranel</surname><given-names>D.</given-names></name><name><surname>Ponto</surname><given-names>L. L. B.</given-names></name><name><surname>Hichwa</surname><given-names>R. D.</given-names></name><name><surname>Damasio</surname><given-names>A. R.</given-names></name></person-group> (<year>2001</year>). <article-title>Neural correlates of naming actions and of naming spatial relations</article-title>. <source>Neuroimage</source>
<volume>13</volume>, <fpage>1053</fpage>&#x02013;<lpage>1064</lpage>
<pub-id pub-id-type="doi">10.1006/nimg.2001.0775</pub-id><?supplied-pmid 11352611?><pub-id pub-id-type="pmid">11352611</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deen</surname><given-names>B.</given-names></name><name><surname>McCarthy</surname><given-names>G.</given-names></name></person-group> (<year>2010</year>). <article-title>Reading about the actions of others: biological motion imagery and action congruency influence brain activity</article-title>. <source>Neuropsychologia</source>
<volume>48</volume>, <fpage>1607</fpage>&#x02013;<lpage>1615</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.01.028</pub-id><?supplied-pmid 20138900?><pub-id pub-id-type="pmid">20138900</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dils</surname><given-names>A. T.</given-names></name><name><surname>Boroditsky</surname><given-names>L.</given-names></name></person-group> (<year>2010</year>). <article-title>Visual motion aftereffects from understanding motion language</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>107</volume>, <fpage>16396</fpage>&#x02013;<lpage>16400</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.1009438107</pub-id><?supplied-pmid 20805483?><pub-id pub-id-type="pmid">20805483</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dubner</surname><given-names>R.</given-names></name><name><surname>Zeki</surname><given-names>S. M.</given-names></name></person-group> (<year>1971</year>). <article-title>Response properties and receptive fields of cells in an anatomically defined region of the superior temporal sulcus in the monkey</article-title>. <source>Brain Res</source>. <volume>35</volume>, <fpage>528</fpage>&#x02013;<lpage>532</lpage>
<pub-id pub-id-type="doi">10.1016/0006-8993(71)90494-X</pub-id><?supplied-pmid 5002708?><pub-id pub-id-type="pmid">5002708</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fodor</surname><given-names>J. A.</given-names></name></person-group> (<year>1983</year>). <source>The Modularity of Mind</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT press</publisher-name></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fogassi</surname><given-names>L.</given-names></name><name><surname>Ferrari</surname><given-names>P. F.</given-names></name><name><surname>Gesierich</surname><given-names>B.</given-names></name><name><surname>Rozzi</surname><given-names>S.</given-names></name><name><surname>Chersi</surname><given-names>F.</given-names></name><name><surname>Rizzolatti</surname><given-names>G.</given-names></name></person-group> (<year>2005</year>). <article-title>Parietal lobe: from action organization to intention understanding</article-title>. <source>Science</source>
<volume>308</volume>, <fpage>662</fpage>&#x02013;<lpage>667</lpage>
<pub-id pub-id-type="doi">10.1126/science.1106138</pub-id><?supplied-pmid 15860620?><pub-id pub-id-type="pmid">15860620</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallese</surname><given-names>V.</given-names></name><name><surname>Lakoff</surname><given-names>G.</given-names></name></person-group> (<year>2005</year>). <article-title>The brain concepts: the role of the sensorymotor system in conceptual structure</article-title>. <source>Cogn. Neuropsychol</source>. <volume>22</volume>, <fpage>455</fpage>&#x02013;<lpage>479</lpage>
<pub-id pub-id-type="doi">10.1080/02643290442000310</pub-id><?supplied-pmid 21038261?><pub-id pub-id-type="pmid">21038261</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilaie-Dotan</surname><given-names>S.</given-names></name><name><surname>Kanai</surname><given-names>R.</given-names></name><name><surname>Bahrami</surname><given-names>B.</given-names></name><name><surname>Rees</surname><given-names>G.</given-names></name><name><surname>Saygin</surname><given-names>A. P.</given-names></name></person-group> (<year>2013</year>). <article-title>Neuroanatomical correlates of biological motion detection</article-title>. <source>Neuropsychologia</source>
<volume>51</volume>, <fpage>457</fpage>&#x02013;<lpage>463</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2012.11.027</pub-id><?supplied-pmid 23211992?><pub-id pub-id-type="pmid">23211992</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>T. D.</given-names></name><name><surname>Rees</surname><given-names>G.</given-names></name><name><surname>Rees</surname><given-names>A.</given-names></name><name><surname>Green</surname><given-names>G. G.</given-names></name><name><surname>Witton</surname><given-names>C.</given-names></name><name><surname>Rowe</surname><given-names>D.</given-names></name><etal/></person-group> (<year>1998</year>). <article-title>Right parietal cortex is involved in the perception of sound movement in humans</article-title>. <source>Nat. Neurosci</source>. <volume>1</volume>, <fpage>74</fpage>&#x02013;<lpage>79</lpage>
<pub-id pub-id-type="doi">10.1038/276</pub-id><?supplied-pmid 10195113?><pub-id pub-id-type="pmid">10195113</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grosbras</surname><given-names>M. H.</given-names></name><name><surname>Beaton</surname><given-names>S.</given-names></name><name><surname>Eickhoff</surname><given-names>S. B.</given-names></name></person-group> (<year>2012</year>). <article-title>Brain regions involved in human movement perception: a quantitative voxel-based meta-analysis</article-title>. <source>Hum. Brain Mapp</source>. <volume>33</volume>, <fpage>431</fpage>&#x02013;<lpage>454</lpage>
<pub-id pub-id-type="doi">10.1002/hbm.21222</pub-id><?supplied-pmid 21391275?><pub-id pub-id-type="pmid">21391275</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossman</surname><given-names>E.</given-names></name><name><surname>Donnelly</surname><given-names>M.</given-names></name><name><surname>Price</surname><given-names>R.</given-names></name><name><surname>Pickens</surname><given-names>D.</given-names></name><name><surname>Morgan</surname><given-names>V.</given-names></name><name><surname>Neighbor</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2000</year>). <article-title>Brain areas involved in perception of biological motion</article-title>. <source>J. Cogn. Neurosci</source>. <volume>12</volume>, <fpage>711</fpage>&#x02013;<lpage>720</lpage>
<pub-id pub-id-type="doi">10.1162/089892900562417</pub-id><?supplied-pmid 11054914?><pub-id pub-id-type="pmid">11054914</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossman</surname><given-names>E. D.</given-names></name><name><surname>Blake</surname><given-names>R.</given-names></name></person-group> (<year>2002</year>). <article-title>Brain areas active during visual perception of biological motion</article-title>. <source>Neuron</source>
<volume>35</volume>, <fpage>1167</fpage>&#x02013;<lpage>1175</lpage>
<pub-id pub-id-type="doi">10.1016/S0896-6273(02)00897-8</pub-id><?supplied-pmid 12354405?><pub-id pub-id-type="pmid">12354405</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossman</surname><given-names>E. D.</given-names></name><name><surname>Battelli</surname><given-names>L.</given-names></name><name><surname>Pascual-Leone</surname><given-names>A.</given-names></name></person-group> (<year>2005</year>). <article-title>Repetitive, T.M.S over posterior STS disrupts perception of biological motion</article-title>. <source>Vision Res</source>. <volume>45</volume>, <fpage>2847</fpage>&#x02013;<lpage>2853</lpage>
<pub-id pub-id-type="doi">10.1016/j.visres.2005.05.027</pub-id><?supplied-pmid 16039692?><pub-id pub-id-type="pmid">16039692</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayasaka</surname><given-names>S.</given-names></name><name><surname>Nichols</surname><given-names>T. E.</given-names></name></person-group> (<year>2004</year>). <article-title>Combining voxel intensity and cluster extent with permutation test framework</article-title>. <source>Neuroimage</source>
<volume>23</volume>, <fpage>54</fpage>&#x02013;<lpage>63</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.04.035</pub-id><?supplied-pmid 15325352?><pub-id pub-id-type="pmid">15325352</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphreys</surname><given-names>G. F.</given-names></name><name><surname>Newling</surname><given-names>K.</given-names></name><name><surname>Jennings</surname><given-names>C.</given-names></name><name><surname>Gennari</surname><given-names>S. P.</given-names></name></person-group> (<year>2013</year>). <article-title>Motion and actions in language: semantic representations in occipito-temporal cortex</article-title>. <source>Brain Lang</source>. <volume>125</volume>, <fpage>94</fpage>&#x02013;<lpage>105</lpage>
<pub-id pub-id-type="doi">10.1016/j.bandl.2013.01.008</pub-id><?supplied-pmid 23454619?><pub-id pub-id-type="pmid">23454619</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kable</surname><given-names>J. W.</given-names></name><name><surname>Kan</surname><given-names>I. P.</given-names></name><name><surname>Wilson</surname><given-names>A.</given-names></name><name><surname>Thompson-Schill</surname><given-names>S. L.</given-names></name><name><surname>Chatterjee</surname><given-names>A.</given-names></name></person-group> (<year>2005</year>). <article-title>Conceptual representations of action in the lateral temporal cortex</article-title>. <source>J. Cogn. Neurosci</source>. <volume>17</volume>, <fpage>1855</fpage>&#x02013;<lpage>1870</lpage>
<pub-id pub-id-type="doi">10.1162/089892905775008625</pub-id><?supplied-pmid 16356324?><pub-id pub-id-type="pmid">16356324</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kable</surname><given-names>J. W.</given-names></name><name><surname>Lease-Spellmeyer</surname><given-names>J.</given-names></name><name><surname>Chatterjee</surname><given-names>A.</given-names></name></person-group> (<year>2002</year>). <article-title>Neural substrates of action event knowledge</article-title>. <source>J. Cogn. Neurosci</source>. <volume>14</volume>, <fpage>795</fpage>&#x02013;<lpage>805</lpage>
<pub-id pub-id-type="doi">10.1162/08989290260138681</pub-id><?supplied-pmid 12167263?><pub-id pub-id-type="pmid">12167263</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kosslyn</surname><given-names>S. M.</given-names></name><name><surname>Ganis</surname><given-names>G.</given-names></name><name><surname>Thompson</surname><given-names>W. L.</given-names></name></person-group> (<year>2001</year>). <article-title>Neural foundations of imagery</article-title>. <source>Nat. Rev. Neurosci</source>. <volume>2</volume>, <fpage>635</fpage>&#x02013;<lpage>642</lpage>
<pub-id pub-id-type="doi">10.1038/35090055</pub-id><?supplied-pmid 11533731?><pub-id pub-id-type="pmid">11533731</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreiman</surname><given-names>G.</given-names></name><name><surname>Koch</surname><given-names>C.</given-names></name><name><surname>Fried</surname><given-names>I.</given-names></name></person-group> (<year>2000</year>). <article-title>Imagery neurons in the human brain</article-title>. <source>Nature</source>
<volume>408</volume>, <fpage>357</fpage>&#x02013;<lpage>361</lpage>
<pub-id pub-id-type="doi">10.1038/35042575</pub-id><?supplied-pmid 11099042?><pub-id pub-id-type="pmid">11099042</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>J. W.</given-names></name><name><surname>Beauchamp</surname><given-names>M. S.</given-names></name><name><surname>DeYoe</surname><given-names>E. A.</given-names></name></person-group> (<year>2000</year>). <article-title>A comparison of visual and auditory motion processing in human cerebral cortex</article-title>. <source>Cereb. Cortex</source>
<volume>10</volume>, <fpage>873</fpage>&#x02013;<lpage>888</lpage>
<pub-id pub-id-type="doi">10.1093/cercor/10.9.873</pub-id><?supplied-pmid 10982748?><pub-id pub-id-type="pmid">10982748</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahon</surname><given-names>B. Z.</given-names></name><name><surname>Milleville</surname><given-names>S. C.</given-names></name><name><surname>Negri</surname><given-names>G. A. L.</given-names></name><name><surname>Rumiati</surname><given-names>R. I.</given-names></name><name><surname>Caramazza</surname><given-names>A.</given-names></name><name><surname>Martin</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>Action related properties shape object representations in the ventral stream</article-title>. <source>Neuron</source>
<volume>55</volume>, <fpage>507</fpage>&#x02013;<lpage>520</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuron.2007.07.011</pub-id><?supplied-pmid 17678861?><pub-id pub-id-type="pmid">17678861</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>A.</given-names></name><name><surname>Haxby</surname><given-names>J. V.</given-names></name><name><surname>Lalonde</surname><given-names>F. M.</given-names></name><name><surname>Wiggs</surname><given-names>C. L.</given-names></name><name><surname>Ungerleider</surname><given-names>L. G.</given-names></name></person-group> (<year>1995</year>). <article-title>Discrete cortical regions associated with knowledge of color and knowledge of action</article-title>. <source>Science</source>
<volume>270</volume>, <fpage>102</fpage>&#x02013;<lpage>105</lpage>
<pub-id pub-id-type="doi">10.1126/science.270.5233.102</pub-id><?supplied-pmid 7569934?><pub-id pub-id-type="pmid">7569934</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCullough</surname><given-names>S.</given-names></name><name><surname>Saygin</surname><given-names>A. P.</given-names></name><name><surname>Korpics</surname><given-names>F.</given-names></name><name><surname>Emmorey</surname><given-names>K.</given-names></name></person-group> (<year>2012</year>). <article-title>Motion-sensitive cortex and motion semantics in American Sign Language</article-title>. <source>Neuroimage</source>
<volume>63</volume>, <fpage>111</fpage>&#x02013;<lpage>118</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.06.029</pub-id><?supplied-pmid 22750056?><pub-id pub-id-type="pmid">22750056</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McRae</surname><given-names>K.</given-names></name><name><surname>Spivey-Knowlton</surname><given-names>M. J.</given-names></name><name><surname>Tanenhaus</surname><given-names>M. K.</given-names></name></person-group> (<year>1998</year>). <article-title>Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension</article-title>. <source>J. Mem. Lang</source>. <volume>38</volume>, <fpage>283</fpage>&#x02013;<lpage>312</lpage>
<pub-id pub-id-type="doi">10.1006/jmla.1997.2543</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meteyard</surname><given-names>L.</given-names></name><name><surname>Zokaei</surname><given-names>N.</given-names></name><name><surname>Bahrami</surname><given-names>B.</given-names></name><name><surname>Vigliocco</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Visual motion interferes with lexical decision on motion words</article-title>. <source>Curr. Biol</source>. <volume>18</volume>, <fpage>R732</fpage>&#x02013;<lpage>R733</lpage>
<pub-id pub-id-type="doi">10.1016/j.cub.2008.07.016</pub-id><?supplied-pmid 18786369?><pub-id pub-id-type="pmid">18786369</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nichols</surname><given-names>T. E.</given-names></name><name><surname>Holmes</surname><given-names>A. P.</given-names></name></person-group> (<year>2002</year>). <article-title>Nonparametric permutation tests for functional neuroimaging: a primer with examples</article-title>. <source>Hum. Brain Mapp</source>. <volume>15</volume>, <fpage>1</fpage>&#x02013;<lpage>25</lpage>
<pub-id pub-id-type="doi">10.1002/hbm.1058</pub-id><?supplied-pmid 11747097?><pub-id pub-id-type="pmid">11747097</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noppeney</surname><given-names>U.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Price</surname><given-names>C. J.</given-names></name></person-group> (<year>2003</year>). <article-title>Effects of visual deprivation on the organization of the semantic system</article-title>. <source>Brain</source>
<volume>126</volume>, <fpage>1620</fpage>&#x02013;<lpage>1627</lpage>
<pub-id pub-id-type="doi">10.1093/brain/awg152</pub-id><?supplied-pmid 12805112?><pub-id pub-id-type="pmid">12805112</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noppeney</surname><given-names>U.</given-names></name><name><surname>Josephs</surname><given-names>O.</given-names></name><name><surname>Kiebel</surname><given-names>S.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Price</surname><given-names>C. J.</given-names></name></person-group> (<year>2005</year>). <article-title>Action selectivity in parietal and temporal cortex</article-title>. <source>Brain Res. Cogn. Brain Res</source>. <volume>25</volume>, <fpage>641</fpage>&#x02013;<lpage>649</lpage>
<pub-id pub-id-type="doi">10.1016/j.cogbrainres.2005.08.017</pub-id><?supplied-pmid 16242924?><pub-id pub-id-type="pmid">16242924</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perani</surname><given-names>D.</given-names></name><name><surname>Cappa</surname><given-names>S. F.</given-names></name><name><surname>Schnur</surname><given-names>T.</given-names></name><name><surname>Tettamanti</surname><given-names>M.</given-names></name><name><surname>Collina</surname><given-names>S.</given-names></name><name><surname>Rosa</surname><given-names>M. M.</given-names></name><etal/></person-group> (<year>1999</year>). <article-title>The neural correlates of verb and noun processing: a PET study</article-title>. <source>Brain</source>
<volume>122</volume>, <fpage>2337</fpage>&#x02013;<lpage>2344</lpage>
<pub-id pub-id-type="doi">10.1093/brain/122.12.2337</pub-id><?supplied-pmid 10581226?><pub-id pub-id-type="pmid">10581226</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pobric</surname><given-names>G.</given-names></name><name><surname>Jefferies</surname><given-names>E.</given-names></name><name><surname>Lambon Ralph</surname><given-names>M. A.</given-names></name></person-group> (<year>2010</year>). <article-title>Category-specific versus category-general semantic impairment induced by transcranial magnetic stimulation</article-title>. <source>Curr. Biol</source>. <volume>20</volume>, <fpage>964</fpage>&#x02013;<lpage>968</lpage>
<pub-id pub-id-type="doi">10.1016/j.cub.2010.03.070</pub-id><?supplied-pmid 20451381?><pub-id pub-id-type="pmid">20451381</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pulvermuller</surname><given-names>F.</given-names></name></person-group> (<year>1999</year>). <article-title>Words in the brain's language</article-title>. <source>Behav. Brain Sci</source>. <volume>22</volume>, <fpage>253</fpage>&#x02013;<lpage>279</lpage>
<pub-id pub-id-type="doi">10.1017/S0140525X9900182X</pub-id><?supplied-pmid 11301524?><pub-id pub-id-type="pmid">11301524</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rueschemeyer</surname><given-names>S.</given-names></name><name><surname>Glenber</surname><given-names>A. M.</given-names></name><name><surname>Kaschak</surname><given-names>M. P.</given-names></name><name><surname>Mueller</surname><given-names>K.</given-names></name><name><surname>Friederici</surname><given-names>A. D.</given-names></name></person-group> (<year>2010</year>). <article-title>Top-down and bottom-up contributions to understanding sentences describing objects in motion</article-title>. <source>Front. Psychol</source>. <volume>1</volume>:<issue>183</issue>
<pub-id pub-id-type="doi">10.3389/fpsyg.2010.00183</pub-id><?supplied-pmid 21833244?><pub-id pub-id-type="pmid">21833244</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxe</surname><given-names>R.</given-names></name><name><surname>Moran</surname><given-names>J. M.</given-names></name><name><surname>Scholz</surname><given-names>J.</given-names></name><name><surname>Gabrieli</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>). <article-title>Overlapping and non-overlapping brain regions for theory of mind and self reflection in individual subjects</article-title>. <source>Soc. Cogn. Affect. Neurosci</source>. <volume>1</volume>, <fpage>229</fpage>&#x02013;<lpage>234</lpage>
<pub-id pub-id-type="doi">10.1093/scan/nsl034</pub-id><?supplied-pmid 18985110?><pub-id pub-id-type="pmid">18985110</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadaghiani</surname><given-names>S.</given-names></name><name><surname>Maier</surname><given-names>J. X.</given-names></name><name><surname>Noppeney</surname><given-names>U.</given-names></name></person-group> (<year>2009</year>). <article-title>Natural, metaphoric, and linguistic auditory direction signals have distinct influences on visual motion processing</article-title>. <source>J. Neurosci</source>. <volume>29</volume>, <fpage>6490</fpage>&#x02013;<lpage>6499</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5437-08.2009</pub-id><?supplied-pmid 19458220?><pub-id pub-id-type="pmid">19458220</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saygin</surname><given-names>A. P.</given-names></name></person-group> (<year>2007</year>). <article-title>Superior temporal and premotor brain areas necessary for biological motion perception</article-title>. <source>Brain</source>
<volume>130</volume>, <fpage>2452</fpage>&#x02013;<lpage>2461</lpage>
<pub-id pub-id-type="doi">10.1093/brain/awm162</pub-id><?supplied-pmid 17660183?><pub-id pub-id-type="pmid">17660183</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saygin</surname><given-names>A. P.</given-names></name><name><surname>McCullough</surname><given-names>S.</given-names></name><name><surname>Alac</surname><given-names>M.</given-names></name><name><surname>Emmorey</surname><given-names>K.</given-names></name></person-group> (<year>2009</year>). <article-title>Modulation of BOLD response in motion-sensitive lateral temporal cortex by real and fictive motion sentences</article-title>. <source>J. Cogn. Neurosci</source>. <volume>22</volume>, <fpage>2480</fpage>&#x02013;<lpage>2490</lpage>
<pub-id pub-id-type="doi">10.1162/jocn.2009.21388</pub-id><?supplied-pmid 19925197?><pub-id pub-id-type="pmid">19925197</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Speer</surname><given-names>N. K.</given-names></name><name><surname>Reynolds</surname><given-names>J. R.</given-names></name><name><surname>Swallow</surname><given-names>K. M.</given-names></name><name><surname>Zacks</surname><given-names>J. M.</given-names></name></person-group> (<year>2009</year>). <article-title>Reading stories activates neural respresentations of visual and motor experience</article-title>. <source>Psychol. Sci</source>. <volume>20</volume>, <fpage>989</fpage>&#x02013;<lpage>999</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02397.x</pub-id><?supplied-pmid 19572969?><pub-id pub-id-type="pmid">19572969</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stroop</surname><given-names>J. R.</given-names></name></person-group> (<year>1935</year>). <article-title>Studies of interference in serial verbal reactions</article-title>. <source>J. Exp. Psychol</source>. <volume>18</volume>, <fpage>643</fpage>&#x02013;<lpage>662</lpage>
<pub-id pub-id-type="doi">10.1037/h0054651</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tettamanti</surname><given-names>M.</given-names></name><name><surname>Buccino</surname><given-names>G.</given-names></name><name><surname>Saccuman</surname><given-names>M. C.</given-names></name><name><surname>Gallese</surname><given-names>V.</given-names></name><name><surname>Danna</surname><given-names>M.</given-names></name><name><surname>Scifo</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2005</year>). <article-title>Listening to action-related sentences activates fronto-parietal motor circuits</article-title>. <source>J. Cogn. Neurosci</source>. <volume>17</volume>, <fpage>273</fpage>&#x02013;<lpage>281</lpage>
<pub-id pub-id-type="doi">10.1162/0898929053124965</pub-id><?supplied-pmid 15811239?><pub-id pub-id-type="pmid">15811239</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>R. B.</given-names></name><name><surname>Reppas</surname><given-names>J. B.</given-names></name><name><surname>Kwong</surname><given-names>K. K.</given-names></name></person-group> (<year>1995</year>). <article-title>Functional analysis of human MT and related visual cortical areas using magnetic resonance imaging</article-title>. <source>J. Neurosci</source>. <volume>15</volume>, <fpage>3215</fpage>&#x02013;<lpage>3230</lpage>
<?supplied-pmid 7722658?><pub-id pub-id-type="pmid">7722658</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trueswell</surname><given-names>J. C.</given-names></name><name><surname>Tanenhaus</surname><given-names>M. K.</given-names></name><name><surname>Garnsey</surname><given-names>S. M.</given-names></name></person-group> (<year>1994</year>). <article-title>Semantic influences on parsing: use of thematic role information in syntactic ambiguity resolution</article-title>. <source>J. Mem. Lang</source>. <volume>33</volume>, <fpage>285</fpage>&#x02013;<lpage>318</lpage>
<pub-id pub-id-type="doi">10.1006/jmla.1994.1014</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Dam</surname><given-names>W. O.</given-names></name><name><surname>Rueschemeyer</surname><given-names>S. A.</given-names></name><name><surname>Bekkering</surname><given-names>H.</given-names></name></person-group> (<year>2010</year>). <article-title>How specifically are action verbs represented in the neural motor system: an fMRI study</article-title>. <source>Neuroimage</source>
<volume>53</volume>, <fpage>1318</fpage>&#x02013;<lpage>1325</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.06.071</pub-id><?supplied-pmid 20619347?><pub-id pub-id-type="pmid">20619347</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallentin</surname><given-names>M.</given-names></name><name><surname>Ellegaard Lund</surname><given-names>T.</given-names></name><name><surname>Ostergaard</surname><given-names>S.</given-names></name><name><surname>Ostergaard</surname><given-names>L.</given-names></name><name><surname>Roepstorff</surname><given-names>A.</given-names></name></person-group> (<year>2005</year>). <article-title>Motion verb sentences activate left posterior middle temporal cortex despite static context</article-title>. <source>Neuroreport</source>
<volume>16</volume>, <fpage>649</fpage>&#x02013;<lpage>652</lpage>
<pub-id pub-id-type="doi">10.1097/00001756-200504250-00027</pub-id><?supplied-pmid 15812326?><pub-id pub-id-type="pmid">15812326</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallentin</surname><given-names>M.</given-names></name><name><surname>Nielsen</surname><given-names>A. H.</given-names></name><name><surname>Vuust</surname><given-names>P.</given-names></name><name><surname>Dohn</surname><given-names>A.</given-names></name><name><surname>Roepstorff</surname><given-names>A.</given-names></name><name><surname>Lund</surname><given-names>T. E.</given-names></name></person-group> (<year>2011</year>). <article-title>BOLD response to motion verbs in left posterior middle temporal gyrus during story comprehension</article-title>. <source>Brain Lang</source>. <volume>119</volume>, <fpage>221</fpage>&#x02013;<lpage>225</lpage>
<pub-id pub-id-type="doi">10.1016/j.bandl.2011.04.006</pub-id><?supplied-pmid 21612817?><pub-id pub-id-type="pmid">21612817</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>Z. M.</given-names></name><name><surname>Elfar</surname><given-names>J. C.</given-names></name><name><surname>Eskandar</surname><given-names>E. N.</given-names></name><name><surname>Toth</surname><given-names>L. J.</given-names></name><name><surname>Assad</surname><given-names>J. A.</given-names></name></person-group> (<year>2003</year>). <article-title>Parietal activity and the perceived direction of ambiguous apparent motion</article-title>. <source>Nat. Neurosci</source>. <volume>6</volume>, <fpage>616</fpage>&#x02013;<lpage>623</lpage>
<pub-id pub-id-type="doi">10.1038/nn1055</pub-id><?supplied-pmid 12730699?><pub-id pub-id-type="pmid">12730699</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeki</surname><given-names>S.</given-names></name></person-group> (<year>1991</year>). <article-title>Cerebral akinetopsia (visual motion blindness). A review</article-title>. <source>Brain</source>
<volume>114(Pt 2)</volume>, <fpage>811</fpage>&#x02013;<lpage>824</lpage>
<pub-id pub-id-type="doi">10.1093/brain/114.2.811</pub-id><?supplied-pmid 2043951?><pub-id pub-id-type="pmid">2043951</pub-id></mixed-citation></ref></ref-list><app-group><app id="A1"><title>Appendix</title><sec><title>Visual motion survey instructions</title><p>In this survey we're going to ask you what you think about when you hear or read stories. For each of the stories below we'd like to know to what extent you imagine visual motion in your mind's eye. Please rate each story on a scale of 1 to 7. If you could clearly visualize motion while reading the story, choose a number closer to 7. If you could not clearly visualize movement, choose a number closer to 1.</p><p>1 2 3 4 5 6 7</p><p>Low Medium High</p><p>There are no correct answers in this survey. We're interested in your opinion. Please give us your best estimate in your judgment and use the full range of the scale during the experiment (using all of the different numbers from 1 through 7).</p><p>To give you a sense of the task below, here are some examples:</p><p>Joe was playing soccer, he slid in to steal the ball; he kicked the ball away from the opposing player, got to his feet and began dribbling down the field.</p><p>Most people rate the story above as a 6.</p><p>Ellen took an important exam yesterday. She needed to pass in order to graduate. She passed and was very happy.</p><p>Most people rate the story above as a 1.</p><p>The list of stories appears below. There are a total of 96 stories. Thank you for completing this survey.</p></sec></app></app-group></back></article>